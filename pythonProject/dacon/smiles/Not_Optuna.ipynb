{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24138289",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7236b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem, Descriptors\n",
    "import scipy\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "optuna_logger = logging.getLogger('optuna')\n",
    "optuna_logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ded55",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b65592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_affinities = {\n",
    "    'Br':324.6,\n",
    "    'Se':79.9,\n",
    "    'se':79.9,\n",
    "    'I':126.9,\n",
    "    'H': 72.8,\n",
    "    'Li': 59.6,\n",
    "    'Be': -48,\n",
    "    'B': 26.7,\n",
    "    'C': 121.8,\n",
    "    'c': 121.8,\n",
    "    'N': 7.0,\n",
    "    'O': 140.4,\n",
    "    'o': 140.4,\n",
    "    'F': 328.0,\n",
    "    'Na': 52.8,\n",
    "    'Mg': -40,\n",
    "    'Al': 42.5,\n",
    "    'Si': 134.1,\n",
    "    'P': 72.0,\n",
    "    'S': 200.0,\n",
    "    's': 200.0,\n",
    "    'Cl': 349.0\n",
    "}\n",
    "\n",
    "wtd_electron_affinities = {\n",
    "    'Br':324.6,\n",
    "    'Se':79.9,\n",
    "    'I':126.9,\n",
    "    'H': 72.8,\n",
    "    'Li': 59.6,\n",
    "    'Be': -48,\n",
    "    'B': 26.7,\n",
    "    'C': 121.8,\n",
    "    'N': 7.0,\n",
    "    'O': 140.4,\n",
    "    'F': 328.0,\n",
    "    'Na': 52.8,\n",
    "    'Mg': -40,\n",
    "    'Al': 42.5,\n",
    "    'Si': 134.1,\n",
    "    'P': 72.0 * 1.2,\n",
    "    'S': 200.0 * 1.5,\n",
    "    'Cl': 349.0\n",
    "}\n",
    "\n",
    "element_properties = {\n",
    "    'Br':{'Atomic_weight': 79.904, 'Natural_abundance': 50.69},\n",
    "    'Se':{'Atomic_weight': 78.96, 'Natural_abundance': 49.61},\n",
    "    'se':{'Atomic_weight': 78.96, 'Natural_abundance': 49.61},\n",
    "    'I':{'Atomic_weight': 126.904, 'Natural_abundance': 100},\n",
    "    'H': {'Atomic_weight': 1.008, 'Natural_abundance': 99.985},\n",
    "    'Li': {'Atomic_weight': 6.94, 'Natural_abundance': 92.58},\n",
    "    'Be': {'Atomic_weight': 9.012, 'Natural_abundance': 100},\n",
    "    'B': {'Atomic_weight': 10.81, 'Natural_abundance': 80.1},\n",
    "    'C': {'Atomic_weight': 12.011, 'Natural_abundance': 98.93},\n",
    "    'c': {'Atomic_weight': 12.011, 'Natural_abundance': 98.93},\n",
    "    'N': {'Atomic_weight': 14.007, 'Natural_abundance': 99.63},\n",
    "    'O': {'Atomic_weight': 15.999, 'Natural_abundance': 99.76},\n",
    "    'o': {'Atomic_weight': 15.999, 'Natural_abundance': 99.76},\n",
    "    'F': {'Atomic_weight': 18.998, 'Natural_abundance': 100},\n",
    "    'Na': {'Atomic_weight': 22.990, 'Natural_abundance': 100},\n",
    "    'Mg': {'Atomic_weight': 24.305, 'Natural_abundance': 78.99},\n",
    "    'Al': {'Atomic_weight': 26.982, 'Natural_abundance': 100},\n",
    "    'Si': {'Atomic_weight': 28.085, 'Natural_abundance': 92.23},\n",
    "    'P': {'Atomic_weight': 30.974, 'Natural_abundance': 100},\n",
    "    'S': {'Atomic_weight': 32.06, 'Natural_abundance': 95.02},\n",
    "    's': {'Atomic_weight': 32.06, 'Natural_abundance': 95.02},\n",
    "    'Cl': {'Atomic_weight': 35.45, 'Natural_abundance': 75.78},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ee953",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a30a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, 8, nBits=4096*2)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar\n",
    "\n",
    "seed_everything(42) # Seed 고정\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, target):\n",
    "        self.df = df\n",
    "        self.target = target # HLM or MLM\n",
    "\n",
    "        self.feature_select = transform\n",
    "        self.fp = self.feature_select.fit_transform(np.stack(df['FPs']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.fp[index]\n",
    "        return torch.tensor(fp).float() # feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "def HLM_make_train_val(train1, val1):\n",
    "    train1_y = train1[\"HLM\"]\n",
    "    train1_x = train1.iloc[:,4:]\n",
    "\n",
    "    val1_y = val1[\"HLM\"]\n",
    "    val1_x = val1.iloc[:,4:]\n",
    "    return train1_x, train1_y, val1_x, val1_y\n",
    "\n",
    "def MLM_make_train_val(train1, val1):\n",
    "    train1_y = train1[\"MLM\"]\n",
    "    train1_x = train1.iloc[:,4:]\n",
    "\n",
    "    val1_y = val1[\"MLM\"]\n",
    "    val1_x = val1.iloc[:,4:]\n",
    "    return train1_x, train1_y, val1_x, val1_y\n",
    "\n",
    "\n",
    "def calculate_gasteiger_charges(molecule):\n",
    "    AllChem.ComputeGasteigerCharges(molecule)\n",
    "    charges = [float(atom.GetProp('_GasteigerCharge')) for atom in molecule.GetAtoms()]\n",
    "    return charges\n",
    "\n",
    "def calculate_affinities(mol):\n",
    "    affinities = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        affinity = electron_affinities.get(symbol, None)\n",
    "        if affinity is not None:\n",
    "            affinities.append(affinity)\n",
    "    return affinities\n",
    "\n",
    "def wtd_calculate_affinities(mol):\n",
    "    affinities = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        affinity = wtd_electron_affinities.get(symbol, None)\n",
    "        if affinity is not None:\n",
    "            affinities.append(affinity)\n",
    "    return affinities\n",
    "\n",
    "def calculate_range(affinities):\n",
    "    return np.max(affinities) - np.min(affinities)\n",
    "\n",
    "def wtd_calculate_average_atomic_mass(mol):\n",
    "    average_atomic_mass = 0\n",
    "    total_abundance = 0\n",
    "    \n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        properties = element_properties.get(symbol, None)\n",
    "        if properties is not None:\n",
    "            atomic_weight = properties['Atomic_weight']\n",
    "            natural_abundance = properties['Natural_abundance']\n",
    "\n",
    "            average_atomic_mass += atomic_weight * (natural_abundance / 100)\n",
    "            total_abundance += natural_abundance / 100\n",
    "\n",
    "    if total_abundance != 0:\n",
    "        average_atomic_mass /= total_abundance\n",
    "        \n",
    "    return average_atomic_mass\n",
    "\n",
    "def make_feat(train):\n",
    "    PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "    train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "\n",
    "    train[\"addH\"] = train.Molecule.apply(AllChem.AddHs)\n",
    "    train['Charges'] = train['addH'].apply(calculate_gasteiger_charges)\n",
    "\n",
    "    train['affinities'] = train['Molecule'].apply(calculate_affinities)\n",
    "    train['wtd_affinities'] = train['Molecule'].apply(wtd_calculate_affinities)\n",
    "\n",
    "    train['mean_affinity'] = train['affinities'].apply(np.mean)\n",
    "    train['gmean_affinity'] = train['affinities'].apply(scipy.stats.gmean)\n",
    "    train[\"entropy_affinity\"] = train['affinities'].apply(scipy.stats.entropy)\n",
    "    train['range_affinity'] = train['affinities'].apply(calculate_range)\n",
    "    train['std_affinity'] = train['affinities'].apply(np.std)\n",
    "\n",
    "#     train['wtd_mean_affinity'] = train['wtd_affinities'].apply(np.mean)\n",
    "#     train['wtd_gmean_affinity'] = train['wtd_affinities'].apply(scipy.stats.gmean)\n",
    "#     train[\"wtd_entropy_affinity\"] = train['wtd_affinities'].apply(scipy.stats.entropy)\n",
    "#     train['wtd_range_affinity'] = train['wtd_affinities'].apply(calculate_range)\n",
    "#     train['wtd_std_affinity'] = train['wtd_affinities'].apply(np.std)\n",
    "\n",
    "    train['length'] = train['wtd_affinities'].apply(len)\n",
    "    train = train.drop(['affinities', 'wtd_affinities'], axis = 1)\n",
    "\n",
    "    train['GasteigerCharges'] = train['addH'].apply(calculate_gasteiger_charges)\n",
    "\n",
    "#     train['charge_mean'] = train['GasteigerCharges'].apply(np.mean)\n",
    "#     train['charge_gmean'] = train['GasteigerCharges'].apply(scipy.stats.gmean)\n",
    "#     train[\"charge_entropy\"] = train['GasteigerCharges'].apply(scipy.stats.entropy)\n",
    "#     train['charge_range'] = train['GasteigerCharges'].apply(calculate_range)\n",
    "#     train['charge_std'] = train['GasteigerCharges'].apply(np.std)\n",
    "\n",
    "#     train['avg_Molecular_weight'] = train['Molecular_Weight']/train['length']\n",
    "#     train['average_atomic_mass'] = train['Molecule'].apply(wtd_calculate_average_atomic_mass)\n",
    "\n",
    "    train = train.drop([\"addH\",'Molecule', 'FPs','Charges', 'GasteigerCharges'], axis = 1)\n",
    "    \n",
    "    return train\n",
    "\n",
    "def objective_xgb(trial,train1_x, train1_y, val1_x, val1_y,\n",
    "                 train2_x, train2_y, val2_x, val2_y,\n",
    "                 train3_x, train3_y, val3_x, val3_y,\n",
    "                 train4_x, train4_y, val4_x, val4_y,\n",
    "                 train5_x, train5_y, val5_x, val5_y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000), \n",
    "        'max_depth': trial.suggest_int('max_depth',1, 60), \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 60), \n",
    "        \"colsample_bytree\" : trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        \"learning_rate\" : trial.suggest_loguniform('learning_rate', 0.001, 0.99)            \n",
    "    }\n",
    "    model = XGBRegressor(**params,\n",
    "                         tree_method='gpu_hist',\n",
    "                         nthread=16, n_jobs=16,\n",
    "                         random_state=42)\n",
    "    scores = []\n",
    "    scores.append(get_score(model, train1_x, train1_y, val1_x, val1_y))\n",
    "    scores.append(get_score(model, train2_x, train2_y, val2_x, val2_y))\n",
    "    scores.append(get_score(model, train3_x, train3_y, val3_x, val3_y))\n",
    "    scores.append(get_score(model, train4_x, train4_y, val4_x, val4_y))\n",
    "    scores.append(get_score(model, train5_x, train5_y, val5_x, val5_y))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"RMSE_MEAN = {mean_score}\")\n",
    "    return mean_score\n",
    "\n",
    "def objective_rfc(trial,train1_x, train1_y, val1_x, val1_y,\n",
    "                 train2_x, train2_y, val2_x, val2_y,\n",
    "                 train3_x, train3_y, val3_x, val3_y,\n",
    "                 train4_x, train4_y, val4_x, val4_y,\n",
    "                 train5_x, train5_y, val5_x, val5_y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 500), \n",
    "        'max_depth': trial.suggest_int('max_depth',1, 50), \n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50), \n",
    "    }\n",
    "    model = RandomForestRegressor(**params,\n",
    "                              random_state=42)\n",
    "    scores = []\n",
    "    scores.append(get_score(model, train1_x, train1_y, val1_x, val1_y))\n",
    "    scores.append(get_score(model, train2_x, train2_y, val2_x, val2_y))\n",
    "    scores.append(get_score(model, train3_x, train3_y, val3_x, val3_y))\n",
    "    scores.append(get_score(model, train4_x, train4_y, val4_x, val4_y))\n",
    "    scores.append(get_score(model, train5_x, train5_y, val5_x, val5_y))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"RMSE_MEAN = {mean_score}\")\n",
    "    return mean_score\n",
    "\n",
    "def get_score(model, train1_x, train1_y, val1_x, val1_y):\n",
    "    model.fit(train1_x, train1_y)\n",
    "    y_pred_1 = model.predict(val1_x)\n",
    "    mse = mean_squared_error(val1_y, y_pred_1)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def count_s(real_train):\n",
    "    return real_train.count(\"@@\")\n",
    "def count_r(real_train):\n",
    "    return real_train.count(\"@\")\n",
    "def count_chiral(real_train):\n",
    "    return real_train['s_form'] + real_train['r_form']\n",
    "\n",
    "def cal_error(train1_x, train1_y, val1_x, val1_y, j, k):\n",
    "    model_MLM = XGBRegressor(# tree_method='gpu_hist',\n",
    "                             nthread=16, n_jobs=16,\n",
    "                             random_state=42)\n",
    "\n",
    "    model_MLM.fit(train1_x, train1_y)\n",
    "    predictions_MLM = model_MLM.predict(val1_x)\n",
    "\n",
    "    error = np.abs(predictions_MLM - val1_y)\n",
    "    high_error_indices = [i + (690*j) for i, e in enumerate(error) if e >= k]\n",
    "    \n",
    "    return high_error_indices\n",
    "\n",
    "def cal_robust_error(train1_x, train1_y, val1_x, val1_y, j, k):\n",
    "    model_xgb = XGBRegressor(# tree_method='gpu_hist',\n",
    "                             nthread=16, n_jobs=16,\n",
    "                             random_state=42)\n",
    "    model_lgb = LGBMRegressor(device = 'gpu',\n",
    "                              gpu_platform_id = 0,\n",
    "                              gpu_device_id = 0,\n",
    "                              n_jobs = 16,\n",
    "                              random_state=42)\n",
    "    model_cat = CatBoostRegressor(random_state=42, \n",
    "                                  logging_level='Silent')\n",
    "    model_rfc = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    error_xgb = get_error(model_xgb, train1_x, train1_y, val1_x, val1_y)\n",
    "#     error_lgb = get_error(model_lgb, train1_x, train1_y, val1_x, val1_y)\n",
    "    error_cat = get_error(model_cat, train1_x, train1_y, val1_x, val1_y)\n",
    "    error_rfc = get_error(model_rfc, train1_x, train1_y, val1_x, val1_y)\n",
    "    error = (error_xgb + error_cat + error_rfc)/3\n",
    "\n",
    "    high_error_indices = [i + (690*j) for i, e in enumerate(error) if e >= k]\n",
    "    \n",
    "    return high_error_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea415fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial,train1_x, train1_y, val1_x, val1_y,\n",
    "                 train2_x, train2_y, val2_x, val2_y,\n",
    "                 train3_x, train3_y, val3_x, val3_y,\n",
    "                 train4_x, train4_y, val4_x, val4_y,\n",
    "                 train5_x, train5_y, val5_x, val5_y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 500), \n",
    "        'max_depth': trial.suggest_int('max_depth',5, 15), \n",
    "        \"learning_rate\" : trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        \n",
    "    }\n",
    "    model = RandomForestRegressor(**params,\n",
    "                              random_state=42)\n",
    "    scores = []\n",
    "    scores.append(get_score(model, train1_x, train1_y, val1_x, val1_y))\n",
    "    scores.append(get_score(model, train2_x, train2_y, val2_x, val2_y))\n",
    "    scores.append(get_score(model, train3_x, train3_y, val3_x, val3_y))\n",
    "    scores.append(get_score(model, train4_x, train4_y, val4_x, val4_y))\n",
    "    scores.append(get_score(model, train5_x, train5_y, val5_x, val5_y))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"RMSE_MEAN = {mean_score}\")\n",
    "    return mean_score\n",
    "\n",
    "def objective_lgb(trial,train1_x, train1_y, val1_x, val1_y,\n",
    "                 train2_x, train2_y, val2_x, val2_y,\n",
    "                 train3_x, train3_y, val3_x, val3_y,\n",
    "                 train4_x, train4_y, val4_x, val4_y,\n",
    "                 train5_x, train5_y, val5_x, val5_y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1000), \n",
    "        'max_depth': trial.suggest_int('max_depth',5, 15), \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 60), \n",
    "        \"colsample_bytree\" : trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        \"learning_rate\" : trial.suggest_loguniform('learning_rate', 0.001, 0.1)            \n",
    "    }\n",
    "    model = LGBMRegressor(**params,\n",
    "                         #tree_method='gpu_hist',\n",
    "                         nthread=16, n_jobs=16,\n",
    "                         random_state=42)\n",
    "    scores = []\n",
    "    scores.append(get_score(model, train1_x, train1_y, val1_x, val1_y))\n",
    "    scores.append(get_score(model, train2_x, train2_y, val2_x, val2_y))\n",
    "    scores.append(get_score(model, train3_x, train3_y, val3_x, val3_y))\n",
    "    scores.append(get_score(model, train4_x, train4_y, val4_x, val4_y))\n",
    "    scores.append(get_score(model, train5_x, train5_y, val5_x, val5_y))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"RMSE_MEAN = {mean_score}\")\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eadfcb",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c920ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mlm_outlier_predict(k):\n",
    "    \n",
    "    real_train = pd.read_csv('./train.csv')\n",
    "    real_train = real_train.loc[real_train.groupby('SMILES', sort=False)['MLM'].idxmin()].reset_index(drop = True)\n",
    "    real_train['AlogP'][2778] = 4.774475\n",
    "    real_train['AlogP'][3361] = 4.568649\n",
    "    real_train['s_form'] = real_train['SMILES'].apply(count_s)\n",
    "    real_train['r_form'] = real_train['SMILES'].apply(count_r)\n",
    "    real_train['r_form'] = real_train['r_form'] - 2*real_train['s_form']\n",
    "    real_train['chirality'] = real_train['s_form'] + real_train['r_form']\n",
    "\n",
    "    real_train = real_train[real_train['MLM'] <= 100]\n",
    "    real_train = real_train[real_train['HLM'] <= 100]\n",
    "    real_train = real_train[real_train['LogD'] > -4]\n",
    "    real_train = real_train.reset_index(drop=True)    \n",
    "    \n",
    "    real_test = pd.read_csv('./test.csv')\n",
    "\n",
    "    real_test['s_form'] = real_test['SMILES'].apply(count_s)\n",
    "    real_test['r_form'] = real_test['SMILES'].apply(count_r)\n",
    "    real_test['r_form'] = real_test['r_form'] - 2*real_test['s_form']\n",
    "    real_test['chirality'] = real_test['s_form'] + real_test['r_form']\n",
    "\n",
    "    real_train = make_feat(real_train)\n",
    "    real_test = make_feat(real_test)\n",
    "\n",
    "    train = pd.read_csv('./train.csv')\n",
    "    \n",
    "    train = train[train['MLM'] <= 100]\n",
    "    train = train[train['HLM'] <= 100]\n",
    "    train = train[train['LogD'] > -4]\n",
    "    train = train.reset_index(drop=True)  \n",
    "    \n",
    "    train = train.loc[train.groupby('SMILES', sort=False)['MLM'].idxmin()].reset_index(drop = True)\n",
    "    test = pd.read_csv('./test.csv')\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "    PandasTools.AddMoleculeColumnToFrame(test,'SMILES','Molecule')\n",
    "\n",
    "    train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "    test[\"FPs\"] = test.Molecule.apply(mol2fp)\n",
    "\n",
    "    train = train[['FPs','MLM', 'HLM']]\n",
    "    test = test[['FPs']]\n",
    "\n",
    "    train_MLM = train[\"MLM\"]\n",
    "    train_HLM = train[\"HLM\"]\n",
    "\n",
    "    train = train.drop(['HLM','MLM'], axis = 1)\n",
    "\n",
    "    train_df = pd.concat([train, test]).reset_index(drop = True)\n",
    "    train_dataset = CustomDataset(df=train_df, target='MLM')\n",
    "    input_size = train_dataset.fp.shape[1]\n",
    "    print(\"input_size: \",input_size)\n",
    "    print(\"\")\n",
    "    feature_names = [f'feature_{i}' for i in range(input_size)]\n",
    "    df = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "    for i in tqdm(range(train_dataset.fp.shape[0])):\n",
    "        df_feature = pd.DataFrame([train_dataset.fp[i]], columns = feature_names)\n",
    "        df = df.append(df_feature, ignore_index = True)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('int64')\n",
    "\n",
    "    X = pd.concat([real_train, df[:-len(real_test)]], axis = 1)\n",
    "    X = X.sample(frac=1,random_state=77).reset_index(drop=True)\n",
    "\n",
    "    train1 = X[690:].reset_index(drop=True)\n",
    "    val1 = X[:690].reset_index(drop=True)\n",
    "\n",
    "    train2 = pd.concat([X[:690*1], X[690*2:]], ignore_index=True)\n",
    "    val2 = X[690*1:690*2].reset_index(drop=True)\n",
    "\n",
    "    train3 = pd.concat([X[:690*2], X[690*3:]], ignore_index=True)\n",
    "    val3 = X[690*2:690*3].reset_index(drop=True)\n",
    "\n",
    "    train4 = pd.concat([X[:690*3], X[690*4:]], ignore_index=True)\n",
    "    val4 = X[690*3:690*4].reset_index(drop=True)\n",
    "\n",
    "    train5 = pd.concat([X[:690*4], X[690*5:]], ignore_index=True)\n",
    "    val5 = X[690*4:690*5].reset_index(drop=True)\n",
    "\n",
    "    train1_x, train1_y, val1_x, val1_y = MLM_make_train_val(train1, val1)\n",
    "    train2_x, train2_y, val2_x, val2_y = MLM_make_train_val(train2, val2)\n",
    "    train3_x, train3_y, val3_x, val3_y = MLM_make_train_val(train3, val3)\n",
    "    train4_x, train4_y, val4_x, val4_y = MLM_make_train_val(train4, val4)\n",
    "    train5_x, train5_y, val5_x, val5_y = MLM_make_train_val(train5, val5)\n",
    "\n",
    "    he_indices1 = cal_error(train1_x, train1_y, val1_x, val1_y, 0, k)\n",
    "    he_indices2 = cal_error(train2_x, train2_y, val2_x, val2_y, 1, k)\n",
    "    he_indices3 = cal_error(train3_x, train3_y, val3_x, val3_y, 2, k)\n",
    "    he_indices4 = cal_error(train4_x, train4_y, val4_x, val4_y, 3, k)\n",
    "    he_indices5 = cal_error(train5_x, train5_y, val5_x, val5_y, 4, k)\n",
    "\n",
    "    final_error = he_indices1 + he_indices2 + he_indices3 + he_indices4 + he_indices5\n",
    "    print(f'final_error: {len(final_error)}')\n",
    "    print(\"\")\n",
    "    df_x = X.drop(index =final_error).reset_index(drop = True)\n",
    "    \n",
    "    return df_x, real_test, df\n",
    "\n",
    "def remove_hlm_outlier_predict(k):\n",
    "\n",
    "    real_train = pd.read_csv('./train.csv')\n",
    "    real_train = real_train.loc[real_train.groupby('SMILES', sort=False)['HLM'].idxmin()].reset_index(drop = True)\n",
    "    real_train['AlogP'][2778] = 4.774475\n",
    "    real_train['AlogP'][3361] = 4.568649\n",
    "    real_train['s_form'] = real_train['SMILES'].apply(count_s)\n",
    "    real_train['r_form'] = real_train['SMILES'].apply(count_r)\n",
    "    real_train['r_form'] = real_train['r_form'] - 2*real_train['s_form']\n",
    "    real_train['chirality'] = real_train['s_form'] + real_train['r_form']\n",
    "\n",
    "    real_train = real_train[real_train['MLM'] <= 100]\n",
    "    real_train = real_train[real_train['HLM'] <= 100]\n",
    "    real_train = real_train[real_train['LogD'] > -4]\n",
    "    real_train = real_train.reset_index(drop=True)\n",
    "    \n",
    "    real_test = pd.read_csv('./test.csv')\n",
    "\n",
    "    real_test['s_form'] = real_test['SMILES'].apply(count_s)\n",
    "    real_test['r_form'] = real_test['SMILES'].apply(count_r)\n",
    "    real_test['r_form'] = real_test['r_form'] - 2*real_test['s_form']\n",
    "    real_test['chirality'] = real_test['s_form'] + real_test['r_form']\n",
    "\n",
    "    real_train = make_feat(real_train)\n",
    "    real_test = make_feat(real_test)\n",
    "\n",
    "    train = pd.read_csv('./train.csv')\n",
    "    \n",
    "    train = train[train['MLM'] <= 100]\n",
    "    train = train[train['HLM'] <= 100]\n",
    "    train = train[train['LogD'] > -4]\n",
    "    train = train.reset_index(drop=True)  \n",
    "    \n",
    "    train = train.loc[train.groupby('SMILES', sort=False)['HLM'].idxmin()].reset_index(drop = True)\n",
    "    test = pd.read_csv('./test.csv')\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "    PandasTools.AddMoleculeColumnToFrame(test,'SMILES','Molecule')\n",
    "\n",
    "    train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "    test[\"FPs\"] = test.Molecule.apply(mol2fp)\n",
    "\n",
    "    train = train[['FPs','MLM', 'HLM']]\n",
    "    test = test[['FPs']]\n",
    "\n",
    "    train_MLM = train[\"MLM\"]\n",
    "    train_HLM = train[\"HLM\"]\n",
    "\n",
    "    train = train.drop(['HLM','MLM'], axis = 1)\n",
    "\n",
    "    train_df = pd.concat([train, test]).reset_index(drop = True)\n",
    "    train_dataset = CustomDataset(df=train_df, target='HLM')\n",
    "    input_size = train_dataset.fp.shape[1]\n",
    "    print(\"input_size: \",input_size)\n",
    "\n",
    "    feature_names = [f'feature_{i}' for i in range(input_size)]\n",
    "    df = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "    for i in tqdm(range(train_dataset.fp.shape[0])):\n",
    "        df_feature = pd.DataFrame([train_dataset.fp[i]], columns = feature_names)\n",
    "        df = df.append(df_feature, ignore_index = True)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('int64')\n",
    "            \n",
    "    X = pd.concat([real_train, df[:-len(real_test)]], axis = 1)\n",
    "    X = X.sample(frac=1,random_state=77).reset_index(drop=True)\n",
    "    \n",
    "    train1 = X[690:].reset_index(drop=True)\n",
    "    val1 = X[:690].reset_index(drop=True)\n",
    "\n",
    "    train2 = pd.concat([X[:690*1], X[690*2:]], ignore_index=True)\n",
    "    val2 = X[690*1:690*2].reset_index(drop=True)\n",
    "\n",
    "    train3 = pd.concat([X[:690*2], X[690*3:]], ignore_index=True)\n",
    "    val3 = X[690*2:690*3].reset_index(drop=True)\n",
    "\n",
    "    train4 = pd.concat([X[:690*3], X[690*4:]], ignore_index=True)\n",
    "    val4 = X[690*3:690*4].reset_index(drop=True)\n",
    "\n",
    "    train5 = pd.concat([X[:690*4], X[690*5:]], ignore_index=True)\n",
    "    val5 = X[690*4:690*5].reset_index(drop=True)\n",
    "\n",
    "    train1_x, train1_y, val1_x, val1_y = HLM_make_train_val(train1, val1)\n",
    "    train2_x, train2_y, val2_x, val2_y = HLM_make_train_val(train2, val2)\n",
    "    train3_x, train3_y, val3_x, val3_y = HLM_make_train_val(train3, val3)\n",
    "    train4_x, train4_y, val4_x, val4_y = HLM_make_train_val(train4, val4)\n",
    "    train5_x, train5_y, val5_x, val5_y = HLM_make_train_val(train5, val5)\n",
    "\n",
    "    he_indices1 = cal_error(train1_x, train1_y, val1_x, val1_y, 0, k)\n",
    "    he_indices2 = cal_error(train2_x, train2_y, val2_x, val2_y, 1, k)\n",
    "    he_indices3 = cal_error(train3_x, train3_y, val3_x, val3_y, 2, k)\n",
    "    he_indices4 = cal_error(train4_x, train4_y, val4_x, val4_y, 3, k)\n",
    "    he_indices5 = cal_error(train5_x, train5_y, val5_x, val5_y, 4, k)\n",
    "\n",
    "    final_error = he_indices1 + he_indices2 + he_indices3 + he_indices4 + he_indices5\n",
    "    print(f'final_error: {len(final_error)}')\n",
    "\n",
    "    print(f'X.shape: {X.shape}')\n",
    "    df_x = X.drop(index =final_error).reset_index(drop = True)\n",
    "    print(f'df_x.shape: {df_x.shape}')\n",
    "    print('')\n",
    "\n",
    "    return df_x, real_test, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be4a64",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c138983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:  217\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f553b648b8c43e7bb3c7b15090e823f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_error: 427\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m      3\u001b[0m transform \u001b[38;5;241m=\u001b[39m VarianceThreshold(threshold\u001b[38;5;241m=\u001b[39mthresh)\n\u001b[1;32m----> 4\u001b[0m df_x_mlm, real_test, df, best_params_MLM \u001b[38;5;241m=\u001b[39m remove_mlm_outlier_predict(\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      5\u001b[0m df_x_mlm, real_test, df, best_params_HLM \u001b[38;5;241m=\u001b[39m remove_hlm_outlier_predict(\u001b[38;5;241m44\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "thresh = 0.05\n",
    "\n",
    "transform = VarianceThreshold(threshold=thresh)\n",
    "df_x_mlm, real_test, df, best_params_MLM = remove_mlm_outlier_predict(50)\n",
    "df_x_mlm, real_test, df, best_params_HLM = remove_hlm_outlier_predict(44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4005c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:  217\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784b8779242a4b429f7bd1f5e1c991f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_error: 427\n",
      "\n",
      "input_size:  217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faebabce9d2a46be8d8e92949db14704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_error: 650\n",
      "X.shape: (3471, 237)\n",
      "df_x.shape: (2821, 237)\n",
      "\n",
      "Load model_MLM & HLM\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "thresh = 0.05\n",
    "transform = VarianceThreshold(threshold=thresh)\n",
    "\n",
    "df_x_mlm, test_mlm, data_mlm = remove_mlm_outlier_predict(50)\n",
    "df_x_hlm, test_hlm, data_hlm = remove_hlm_outlier_predict(45)\n",
    "\n",
    "test_x_mlm = pd.concat([test_mlm.iloc[:,2:], data_mlm[-len(test_mlm):].reset_index(drop=True)], axis = 1)\n",
    "test_x_hlm = pd.concat([test_hlm.iloc[:,2:], data_hlm[-len(test_hlm):].reset_index(drop=True)], axis = 1)\n",
    "\n",
    "test_mlm['AlogP'][10] = 3.9987388\n",
    "test_hlm['AlogP'][10] = 3.9987388\n",
    "\n",
    "y_MLM = df_x_mlm[\"MLM\"]\n",
    "y_HLM = df_x_hlm[\"HLM\"]\n",
    "\n",
    "train_x_mlm = df_x_mlm.iloc[:,4:]\n",
    "train_x_hlm = df_x_hlm.iloc[:,4:]\n",
    "\n",
    "print(\"Load model_MLM & HLM\")\n",
    "\n",
    "parms = {'n_estimators': 552, 'max_depth': 60, 'min_child_weight': 14, 'colsample_bytree': 0.6819785996978678, 'learning_rate': 0.021656431222090825}\n",
    "\n",
    "model_MLM = XGBRegressor(**params,random_state=42)\n",
    "# n_estimators= 756, \n",
    "#                          max_depth = 7, \n",
    "#                          min_child_weight = 8,\n",
    "#                          colsample_bytree = 0.5035082618401603, \n",
    "#                          learning_rate = 0.024932301512215357,\n",
    "#                          # tree_method='gpu_hist',\n",
    "#                          nthread=16, n_jobs=16,\n",
    "#                          random_state=42\n",
    "model_MLM.fit(train_x_mlm, y_MLM)\n",
    "predictions_MLM = model_MLM.predict(test_x_mlm)\n",
    "\n",
    "parms = {'n_estimators': 465, 'max_depth': 59, 'min_child_weight': 33, 'colsample_bytree': 0.8345329738771153, 'learning_rate': 0.02159090758801776}\n",
    "model_HLM = XGBRegressor(**params,random_state=42)\n",
    "# n_estimators = 847, \n",
    "#                          max_depth = 24, \n",
    "#                          min_child_weight = 17, \n",
    "#                          colsample_bytree = 0.69988348771691,\n",
    "#                          learning_rate = 0.01753401553854092,\n",
    "#                          # tree_method='gpu_hist',\n",
    "#                          nthread=16, n_jobs=16,\n",
    "#                          random_state=42\n",
    "model_HLM.fit(train_x_hlm, y_HLM)\n",
    "predictions_HLM = model_HLM.predict(test_x_hlm)\n",
    "\n",
    "submission['MLM'] = predictions_MLM\n",
    "submission['HLM'] = predictions_HLM\n",
    "\n",
    "submission.to_csv('Not_Optuna_mlm_50_hlm_45_shuffle.csv', index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2091408d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>22.400703</td>\n",
       "      <td>59.715847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>69.234825</td>\n",
       "      <td>86.809350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>23.208012</td>\n",
       "      <td>49.993103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>49.073162</td>\n",
       "      <td>87.068980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>61.268320</td>\n",
       "      <td>84.295140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>4.676309</td>\n",
       "      <td>7.380814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>84.797300</td>\n",
       "      <td>97.483070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>31.146442</td>\n",
       "      <td>73.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>43.287956</td>\n",
       "      <td>74.245255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>25.261356</td>\n",
       "      <td>65.273384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        MLM        HLM\n",
       "0    TEST_000  22.400703  59.715847\n",
       "1    TEST_001  69.234825  86.809350\n",
       "2    TEST_002  23.208012  49.993103\n",
       "3    TEST_003  49.073162  87.068980\n",
       "4    TEST_004  61.268320  84.295140\n",
       "..        ...        ...        ...\n",
       "478  TEST_478   4.676309   7.380814\n",
       "479  TEST_479  84.797300  97.483070\n",
       "480  TEST_480  31.146442  73.004135\n",
       "481  TEST_481  43.287956  74.245255\n",
       "482  TEST_482  25.261356  65.273384\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_ = pd.read_csv('./Not_Optuna_mlm_50_hlm_44_.csv')\n",
    "hi = pd.read_csv('./Not_Optuna_mlm_50_hlm_44.csv')\n",
    "hi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f46fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
