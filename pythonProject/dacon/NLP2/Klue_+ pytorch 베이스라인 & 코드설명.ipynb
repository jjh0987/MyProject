{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"모든 참가자의 '제출'을 목표로 합니다\"를 기반으로 하여 만든 klue/roberta를 이용한 베이스라인입니다. \n",
    "\n",
    "pytorch를 처음 접하시는 분들을 위해 라인마다 아는대로 설명을 써놨으나 \n",
    "\n",
    "저도 배운지 얼마 안되어서 부족한 면도 있으니 양해부탁드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 필요한 패키지들을 import합니다. 처음 보실법한 패키지들을 설명드리면\n",
    "\n",
    "1. transformers : Huggingface에 등록된 pretrained model/tokenizer를 불러올 수 있는 패키지\n",
    "2. torch : 머신러닝 패키지\n",
    "3. tqdm : batch별로 프로세스할 때 진행상황을 바로 보여주는 패키지\n",
    "\n",
    "나머지는 아실거라 짐작하고 넘어가겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dacon.io/en/competitions/official/236037/overview/description\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 데이터를 불러와야겠죠?\n",
    "\n",
    "예측하는데 ID는 필요없기 때문에 drop 해줬습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('data/train.csv')\n",
    "train_original.drop(columns=['ID'], inplace=True)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test.drop(columns=['ID'], inplace=True)\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 reproducibility를 위한 설정들이고 데이콘에서 제공한 베이스라인 코드에서 따왔습니다.\n",
    "\n",
    "자세한 설명은 : https://tempdev.tistory.com/28\n",
    "\n",
    "m1 reproducibility 추가\n",
    "\n",
    "CFG안에 key, value에 대해서 설명하자면\n",
    "1. epochs\n",
    "    - 총 트레이닝을 몇번 반복할지\n",
    "    - training set를 처음부터 끝까지 도는걸 몇번할지\n",
    "2. learning_rate\n",
    "    - 트레이닝 속도 \n",
    "    - 높으면 optimize 값으로 빨리 접근할 수는 있지만 지나칠 수 있다.\n",
    "    - 낮으면 optimizer 값으로 느리게 접근하지만 지나치지는 않는다. --> training에 소요되는 시간 증가\n",
    "3. batch_size\n",
    "    - 한번에 몇개의 training items를 가지고 neural network의 weight를 조정할 것인가\n",
    "    - 예를 들어 1000개의 items를 training할 때 batch_size가 32라고 하면 1000개를 32개씩 쪼개서 한번에 32개의 item만을 가지고 training하고 weights를 업데이트하고 다음 32개로 넘어간다. 이때 마지막 그룹은 32개보다 적다. \n",
    "    - batch_size가 작으면 weights를 자주 업데이트하고 크면 weights를 덜 자주 업데이트 한다 --> batch_size가 작으면 sample size가 작은거랑 비슷하므로 그룹마다 차이가 크다 / batch_size가 크면 sample size가 큰거랑 비슷하므로 그룹마다 차이가 작다.\n",
    "\n",
    "\n",
    "이 코드를 돌린 디바이스가 m1 mac이므로 torch.device('mps')를 썼지만 맥이 아닌 gpu를 쓸때는 'cuda'를 쓰면 된다. gpu가 없다면 'cpu'로 설정하면 되는데 그러면 속도가 많이 느려질 것이다. gpu가 있는지 알아보기 위해서는 torch.cuda.is_available()를 돌려보면 true 아니면 false가 나올 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 train_test_split를 이용해서 train와 val을 나눠줍니다. \n",
    "\n",
    "유형(type), 극성(polarity), 시제(tense), 확실성(certainty) 중에서 imbalanced한 label도 있기때문에\n",
    "\n",
    "stratify를 추가해주는게 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(train_original, train_original['label'], test_size=0.2, random_state=CFG['SEED'])\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 언급했듯이 transformers 패키지를 통해서 pretrained된 모델을 불러올 수 있다.\n",
    "\n",
    "불러오는 방법은 https://huggingface.co/models 여기서 model 이름을 검색하고 \n",
    "\n",
    "모델은 AutoModel.from_pretrained()을 통해서, 토크나이저는 AutoTokenizer.from_pretrained()을 통해서 \n",
    "\n",
    "모델이름을 파라미터로 넣어주면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_nm = 'klue/roberta-small'\n",
    "base_model = AutoModel.from_pretrained(model_nm)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저의 역할은 문장을 토큰이라고 하는 작은 단위 (더이상 나눌 수 없는 가장 작은 단위)로 나누어주고 pretrained tokenizer에 그 토큰이 어디에 저장되어 있는지 input_ids로 되돌려준다.\n",
    "\n",
    "밑 코드는 그 input_ids 길이가 어떤지 histogram으로 그려본 것이다.\n",
    "\n",
    "(저도 이 분야는 신생아라 틀린 부분이 있을 수 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 90.4092368060602\n"
     ]
    }
   ],
   "source": [
    "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n",
    "sns.histplot(tokenizer_len)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, log를 취해주면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 4.8974082584991345\n",
      "original value : 133.94218592094492\n"
     ]
    }
   ],
   "source": [
    "tokenizer_log = np.log(tokenizer_len)\n",
    "sns.histplot(tokenizer_log)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n",
    "print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, 적정선은 90에서 134 사이가 아닐까 생각된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 값은 잠깐 뒤로하고 아래 코드를 위부터 설명하자면,\n",
    "\n",
    "torch.utils.data의 Dataset의 child class인 SentenceTypeDataset을 만들어준다. 이는 pytorch neural network에 내 맘대로 \n",
    "x가 뭔지 y가 뭔지 정한 dataset을 제공하기 위한 클래스이다. 만드는데 꼭 필요한 function은 총 3가지이다.\n",
    "\n",
    "_ _ init _ _()\n",
    "- x랑 y가 뭔지 저장해줘야 한다. \n",
    "- 이때 이번에는 텍스트 데이터를 다뤄주기때문에 dataframe, tokenizer, labels를 parameter로 넣어줬고 dataframe의 문장을 tokenizer로 토큰화 시킨다음 self.texts에 저장해주고 입력받은 labels는 그대로 self.labels에 저장해줬다. \n",
    "- batch에 들어가는 입력들은 input size가 다 같아야 한다. 따라서 tokenizer로 나온 값들을 그대로 넣어버리면 오류가 난다. 위 히스토그램에서 볼 수 있듯이 문장마다 다르기 때문. 따라서 위 값(90)으로 tokenizer의 max_length를 정해주고 max_length보다 작은 길이들은 padding으로 채워주고 긴 길이들은 truncation으로 잘라준다. 이때 max_length는 길면 길수록 training time이 늘어난다.\n",
    "- tokenizer안에 return_tensors의 pt는 tensor로 tokenizer값을 리턴해준다는 뜻이다.\n",
    "\n",
    "_ _ len _ _()\n",
    "- self.texts의 길이는 리턴해줍니다.\n",
    "\n",
    "_ _ getitem _ _()\n",
    "- idx에 해당되는 x와 y를 리턴해줍니다.\n",
    "- x는 self.texts에서 가져오고 y는 그 텍스트(x)에 해당되는 type, polarity, tense, certainty를 리턴하면 됩니다.\n",
    "- 나중 코드에서 나오겠지만 미리 설명을 하자면 labels는 train, val set에서만 dictionary형태로 주어진다. 이때 type, polarity, tense, certainty가 key고 해당 레이블에 해당되는 값을 one-hot encoding한게 value다. \n",
    "- dictionary에 저장된 형태는 list고 pytorch에는 tensor 형태로 넣어줘야하기 때문에 torch.Tensor()로 형태를 바꾸어준다.\n",
    "- test set의 경우 labels이 주어지지 않기 때문에 똑같은 길이지만 -1로 채워놓은 tensor를 리턴해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTypeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, labels=None):\n",
    "        texts = dataframe['문장'].values.tolist()\n",
    "\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        if self.labels is not None:\n",
    "            type_tmp = self.labels['type'][idx]\n",
    "            polarity_tmp = self.labels['polarity'][idx]\n",
    "            tense_tmp = self.labels['tense'][idx]\n",
    "            certainty_tmp = self.labels['certainty'][idx]\n",
    "            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
    "        else:\n",
    "            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로는 Classifier class를 만드는 것이다.\n",
    "\n",
    "\\__init__()\n",
    "- 우선 nn.Module의 child class이기 때문에 \\__init__() 안에 super().\\__init__()을 불러주고 base_model을 통해서 받을 pretrained_model을 self.klue에 저장한다.\n",
    "이때 klue의 output features는 768이다. 확인방법은 base_model을 셀에 쳐보면 된다. (더 쉬운 방법이 있으면 알려주세요)\n",
    "\n",
    "- transfer learning의 기본적인 방법은 중간에 hidden layer는 pretrained_model의 것을 이용하고 output layer를 내가 원하는 방향으로 만들어서 training 하는 것이다. 따라서, self.fc1, self.type_clf, self.softmax 등등 다양한 레이어들을 추가해줬다. 이때 self.fc1에는 nn.Linear(768, 32)를 저장해줬는데, 이는 in_feature로 768, out_feature로는 32를 내보낸다는 뜻이다. 일반적으로 알고 있는 dense layer의 역할을 한다. 그 다음으로는 self.relu에 nn.ReLU()를 저장해서 activation function으로 사용해줬다. 그 다음으로는 multilabel classification 문제이기 때문에 각 label마다 nn.Linear(32, # of types)으로 레이어를 만들어줬다. 이때 # of types만큼의 out_feature가 필요한 이유는 types들을 one-hot encoding을 해줬기 때문이다. 그 다음으로는 classification에 많이 사용되는 nn.Softmax(dim=1)을 넣어줬다. softmax에서 나온 값들의 합은 1로써 어느 type에 해당되는지 확률들을 리턴해준다. 이때 합해져야되는 값들이 dim=1에 있기때문에 dim=1이라는 파라미터를 넣어주었다.\n",
    "\n",
    "\\__forward__()\n",
    "- 그 다음으로 꼭 작성해줘야 하는 function은 forward다. (backward는 필요없음) 여기서는 위에서 작성한 레이어들을 어느 순서로 지나칠지 순서를 정해주는 단계이다. 우선, pretrained_model을 지나고 나온 output을 fc1과 relu에 넘겨주고 그 다음으로는 각 label의 clf-softmax 페어를 지나쳐준다. 그리고 나온 4개의 output을 리턴해주면 된다. \n",
    "- multilabel이기 때문에 4개의 값을 리턴해주는거지 단순하게 binary 또는 multiclassification이면 보통 1개의 output만을 리턴해주면 된다.\n",
    "- 아래 코드에 써있듯이 input_ids는 토큰에 해당되는 ids들, attention_mask는 어느 토큰에 집중해야되는지 알려주는 역할을 한다. 이는 왜 필요하나 하면 padding 단계에서 추가된 padding token에 대한 접근을 막기위해 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.klue = base_model # from transformers package\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.type_clf = nn.Linear(32,4)\n",
    "        self.polarity_clf = nn.Linear(32,3)\n",
    "        self.tense_clf = nn.Linear(32,3)\n",
    "        self.certainty_clf = nn.Linear(32,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # input_ids : token's id / attention_mask : make a model to focus on which token\n",
    "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n",
    "\n",
    "        x = self.fc1(klue_out)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        type_output = self.type_clf(x)\n",
    "        type_output = self.softmax(type_output)\n",
    "        polarity_output = self.polarity_clf(x)\n",
    "        polarity_output = self.softmax(polarity_output)\n",
    "        tense_output = self.tense_clf(x)\n",
    "        tense_output = self.softmax(tense_output)\n",
    "        certainty_output = self.certainty_clf(x)\n",
    "        certainty_output = self.softmax(certainty_output)\n",
    "\n",
    "        return type_output, polarity_output, tense_output, certainty_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로는! training 단계이다.\n",
    "\n",
    "우선 val_loss를 기준으로 early_stop을 할건지 말건지 정하기 때문에 best_val_loss를 설정해주었고, crossentropyloss를 이용할건데 작아질수록 좋은 값이기 때문에 최초값은 높은 값으로 설정해주었다. \n",
    "\n",
    "그 다음으로는 criterion인데 이는 loss function이다. 4개의 다른 label들이 있기 때문에 dictionary에 4개를 넣어주었다. 나중 단계에서 criterion에 있는 CrossEntropyLoss를 통해서 true값과 pred값의 차이를 구하고 어떤 방향으로 weights를 조정해야되는지 정한다.\n",
    "\n",
    "optimizer는 어떤 방식으로 최적화를 한걸지 정해주는 변수인데, 일반적으로 많이 쓰이는 Adam을 써줬다. Adam 안에는 모델의 파라미터(model.parameters())와 learning_rate를 넣어주었다. 위에서 언급했듯이 이때 learning_rate가 큰지 작은지에 따라 training 속도가 결정난다. 그 다음으로는 모델을 gpu로 보내주었다. 이 코드가 있어야 gpu를 사용해서 training 한다.\n",
    "- mac m칩 유저의 경우 “PYTORCH_ENABLE_MPS_FALLBACK=1”를 설정해줘야 mps가 안되는 코드는 cpu로 계산을 해준다. (2022/12/16 cumsum은 mps로 계산이 안됨)\n",
    "\n",
    "그리고 주어진 epochs만큰 for loop을 돌리는데 그 밑에 있는 total_acc_train은 total_f1_train으로 바뀌어야 맞다. 이 부분은 중간에 f1 계산하는 코드 넣는거를 까먹고 못하고 코드를 그대로 돌려서 남은 것이니 만약 이 코드 그대로 돌린다고 하면 바꾸어주길 바란다. 그 밑에 total_loss_train은 epoch별로 loss 값이 어땠는지 기록해주기 위해 만든 변수다.\n",
    "\n",
    "그 다음으로는 model.train()이 있는데 이는 model을 training 모드로 만들어주는거다. 이렇게 해야 weight들이 업데이트된다. 이와 반대로 나중에 val이나 test set을 모델에 넘겨줄때는 model.eval()을 불러줘야한다. 이래야 weights들이 업데이트 되지 않는다.\n",
    "\n",
    "그 다음으로는 train_dataloader를 for loop으로 돌려주는데 뒤에 나오겠지만 dataloader는 지정해준 batch_size만큼 item의 x와 y를 넘겨준다. 이때 쓰이는 것이 위에서 만들어준 SentenceTypeDataset의 getitem()이다. 따라서, 5개의 변수 (train_input, type_label, polarity_label, tense_label, certainty_label)로 받아야한다. 그 다음으로는 train_input에 있는 attention_mask와 input_ids와 label들을 device로 넘겨준다.\n",
    "\n",
    "그리고 training을 시작하기 전에 optimizer.grad()를 설정해줘서 매 epoch마다 전에 썼던 값들을 기억하는 것이 아니라 0 베이스에서 시작하게 해준다. epoch를 통한 값들의 정확한 업데이트를 위해서는 꼭 필요한 코드다.\n",
    "\n",
    "그리고 나서 model에 input_ids와 attention_mask를 넣어서 얻은 4개의 값들을 저장해준다. 이때 이 값들은 각 label마다 one-hot encoding된 컬럼에 해당될 확률들이다. 바로 다음에 이 값들은 criterion에 있는 CrossEntropyLoss()로 들어가서 실제와 얼마나 유사한지 계산되고 그 계산된 값을 total_loss_train에 저장해준다.\n",
    "\n",
    "그 다음으로는 계산된 loss 값을 바탕으로 backpropagation(loss.backward()과 optimizer.step()을 통해서)을 진행하여 weights들을 업데이트해준다.\n",
    "\n",
    "이렇게 training data를 다 거쳤다면 그 다음은 validation data 차례다. 우선 with torch.no_grad()과 model.eval()을 불러주어서 weights들을 업데이트하는게 아니라는 것을 선언해준다. 그 후에는 training data에서 했던 방식이랑 다 같지만 optimizer.zero_grad(), loss.backward(), optimier.step()만 빠진다. weights들을 업데이트하지 않기 때문.\n",
    "\n",
    "그 다음으로는 지금까지 저장한 loss와 metric을 프린트해주고, val_loss가 좋아졌는지 여부에 따라서 모델을 저장할 것인지 early stop 할 것인지 정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
    "    best_val_loss = 99999999999999 # setting max (act as infinity)\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    criterion = {\n",
    "        'type' : nn.CrossEntropyLoss().to(device),\n",
    "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        model.train() # sets into the training mode\n",
    "        \n",
    "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "            \n",
    "            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n",
    "                   0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n",
    "                   0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n",
    "                   0.25*criterion['certainty'](certainty_output, certainty_label.float())\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # since we should not change gradient for validation \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            model.eval() # deactivate training\n",
    "            \n",
    "            # same process as the above\n",
    "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                vtype_label = vtype_label.to(device)\n",
    "                vpolarity_label = vpolarity_label.to(device)\n",
    "                vtense_label = vtense_label.to(device)\n",
    "                vcertainty_label = vcertainty_label.to(device)\n",
    "                \n",
    "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n",
    "                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n",
    "                        0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n",
    "                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n",
    "\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "            \n",
    "            print(f'Epochs: {epoch + 1} '\n",
    "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
    "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
    "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
    "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
    "            \n",
    "            if best_val_loss > total_loss_val:\n",
    "                best_val_loss = total_loss_val # saving only the best one\n",
    "                torch.save(model, f\"model/{model_nm}.pt\")\n",
    "                print(\"Saved model\")\n",
    "                early_stopping_threshold_count = 0\n",
    "            else:\n",
    "                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
    "                \n",
    "            if early_stopping_threshold_count >= 3: # ==> patience=1\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 class, function들은 다 적었으니 이제 dataset들을 준비할 차례다.\n",
    "\n",
    "우선 train에서 label을 제외한 나머지 컬럼들만 킵해주고 그중에서도 유형,극성,시제,확실성을 pd.get_dummies로 one-hot encoding해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형_대화형</th>\n",
       "      <th>유형_사실형</th>\n",
       "      <th>유형_예측형</th>\n",
       "      <th>유형_추론형</th>\n",
       "      <th>극성_긍정</th>\n",
       "      <th>극성_미정</th>\n",
       "      <th>극성_부정</th>\n",
       "      <th>시제_과거</th>\n",
       "      <th>시제_미래</th>\n",
       "      <th>시제_현재</th>\n",
       "      <th>확실성_불확실</th>\n",
       "      <th>확실성_확실</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>우리가 익히 아는 대로 임꺽정은 신출귀몰했다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13232 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장  유형_대화형  유형_사실형  \\\n",
       "0      용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...       0       1   \n",
       "1      부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...       0       1   \n",
       "2      그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...       0       1   \n",
       "3                          탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.       0       0   \n",
       "4      이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...       0       1   \n",
       "...                                                  ...     ...     ...   \n",
       "13227                          우리가 익히 아는 대로 임꺽정은 신출귀몰했다.       0       1   \n",
       "13228  김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...       0       1   \n",
       "13229  ＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...       1       0   \n",
       "13230  1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...       0       1   \n",
       "13231               차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.       0       1   \n",
       "\n",
       "       유형_예측형  유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  \\\n",
       "0           0       0      1      0      0      1      0      0        0   \n",
       "1           0       0      1      0      0      1      0      0        0   \n",
       "2           0       0      1      0      0      0      0      1        0   \n",
       "3           0       1      1      0      0      0      0      1        0   \n",
       "4           0       0      1      0      0      0      0      1        0   \n",
       "...       ...     ...    ...    ...    ...    ...    ...    ...      ...   \n",
       "13227       0       0      1      0      0      1      0      0        0   \n",
       "13228       0       0      1      0      0      1      0      0        0   \n",
       "13229       0       0      1      0      0      0      0      1        0   \n",
       "13230       0       0      1      0      0      1      0      0        0   \n",
       "13231       0       0      1      0      0      0      0      1        0   \n",
       "\n",
       "       확실성_확실  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "13227       1  \n",
       "13228       1  \n",
       "13229       1  \n",
       "13230       1  \n",
       "13231       1  \n",
       "\n",
       "[13232 rows x 13 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
    "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "train_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 각 label별로 뽑아서 train_labels에 dictionary형태로 저장해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = train_tmp.iloc[:,1:5].values.tolist()\n",
    "train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n",
    "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
    "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
    "train_labels = {\n",
    "    'type': train_type,\n",
    "    'polarity': train_polarity,\n",
    "    'tense': train_tense,\n",
    "    'certainty': train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "똑같은 방식으로 validation data도 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
    "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "\n",
    "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
    "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
    "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
    "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
    "val_labels = {\n",
    "    'type': val_type,\n",
    "    'polarity': val_polarity,\n",
    "    'tense': val_tense,\n",
    "    'certainty': val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, val set가 준비되었다면 위에서 만든 SetenceTypeDataset에 dataframe, tokenizer, labels들을 넣어주고 SentenceTypeDataset, batch_size는 필수적으로 값을 정해서 DataLoader에 넣어준다. 위에서 잠깐 언급했듯이 DataLoader는 지정된 batch_size만큼 item들을 모델에 넘겨주어서 training 할 수 있게 해준다. \n",
    "\n",
    "여기서 shuffle는 item들을 랜덤하게 고른다는 의미고 num_workers는 설명을 봐도 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading  \n",
    "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 base_model (klue를 이용한 pretrained_model)을 기반으로해서 SentenceClassifier를 불러준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceClassifier(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 이제서야 training을 할 수 있는 상태에 온 것이다. \n",
    "\n",
    "위에서 만든 sentence_train function에 필요한 파라미터들을 보내주어서 training을 시작해준다.\n",
    "\n",
    "(위에서 말했듯이 f1을 계산 안하고 accuracy를 그대로 남겨주었기 때문에 accuracy는 계속 0이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:15<00:00,  1.20s/it]\n",
      "100%|██████████| 104/104 [00:41<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.838 | Train Accuracy:  0.000 | Val Loss:  0.765 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:13<00:00,  1.34s/it]\n",
      "100%|██████████| 104/104 [00:40<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.727 | Train Accuracy:  0.000 | Val Loss:  0.696 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:37<00:00,  1.25s/it]\n",
      "100%|██████████| 104/104 [00:43<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.672 | Train Accuracy:  0.000 | Val Loss:  0.662 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:58<00:00,  1.30s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.641 | Train Accuracy:  0.000 | Val Loss:  0.644 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:54<00:00,  1.29s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.624 | Train Accuracy:  0.000 | Val Loss:  0.635 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:05<00:00,  1.32s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.613 | Train Accuracy:  0.000 | Val Loss:  0.628 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:01<00:00,  1.31s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.604 | Train Accuracy:  0.000 | Val Loss:  0.625 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:07<00:00,  1.32s/it]\n",
      "100%|██████████| 104/104 [00:45<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.597 | Train Accuracy:  0.000 | Val Loss:  0.624 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [10:03<00:00,  1.46s/it]\n",
      "100%|██████████| 104/104 [00:52<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.593 | Train Accuracy:  0.000 | Val Loss:  0.622 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:40<00:00,  1.40s/it]\n",
      "100%|██████████| 104/104 [00:43<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.589 | Train Accuracy:  0.000 | Val Loss:  0.623 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:56<00:00,  1.30s/it]\n",
      "100%|██████████| 104/104 [00:42<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss:  0.585 | Train Accuracy:  0.000 | Val Loss:  0.619 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:00<00:00,  1.31s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 | Train Loss:  0.582 | Train Accuracy:  0.000 | Val Loss:  0.621 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:52<00:00,  1.29s/it]\n",
      "100%|██████████| 104/104 [00:43<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 | Train Loss:  0.580 | Train Accuracy:  0.000 | Val Loss:  0.618 | Val Accuracy:  0.000\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:51<00:00,  1.28s/it]\n",
      "100%|██████████| 104/104 [00:41<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 14 | Train Loss:  0.577 | Train Accuracy:  0.000 | Val Loss:  0.619 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [09:15<00:00,  1.34s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 | Train Loss:  0.575 | Train Accuracy:  0.000 | Val Loss:  0.620 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414/414 [08:58<00:00,  1.30s/it]\n",
      "100%|██████████| 104/104 [00:44<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 16 | Train Loss:  0.573 | Train Accuracy:  0.000 | Val Loss:  0.621 | Val Accuracy:  0.000\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'kclue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training이 끝났으면 test data를 이용해 예측을 해야되는데 이때 방법은 validation때와 비슷하다. 따라서, 설명은 생략하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_predictions(model, loader):\n",
    "\n",
    "    device = torch.device('mps')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_input, _, _, _, _ in tqdm(loader):\n",
    "            attention_mask = data_input['attention_mask'].to(device)\n",
    "            input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "\n",
    "            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n",
    "            type_probs.append(type_output)\n",
    "            polarity_probs.append(polarity_output)\n",
    "            tense_probs.append(tense_output)\n",
    "            clarity_probs.append(clarity_output)\n",
    "    \n",
    "    return torch.cat(type_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(tense_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(clarity_probs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model/kclue.pt\")\n",
    "test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_pred_type, val_pred_polarity, val_pred_tense, val_pred_certainty = get_type_predictions(model, val_dataloader)\n",
    "\n",
    "#val_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in val_pred_type]]\n",
    "#val_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in val_pred_polarity]]\n",
    "#val_type = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in val_pred_tense]]\n",
    "#val_type = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in val_pred_certainty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [01:22<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 test_pred_tense가 어떻게 생겼는지 살펴보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4494439e-03, 6.3607551e-04, 9.9791449e-01],\n",
       "       [1.2099826e-03, 5.7527551e-04, 9.9821484e-01],\n",
       "       [9.9835777e-01, 3.6566349e-04, 1.2766798e-03],\n",
       "       ...,\n",
       "       [6.3049151e-03, 9.8560274e-01, 8.0923596e-03],\n",
       "       [2.1634096e-01, 6.3935834e-01, 1.4430077e-01],\n",
       "       [9.9855858e-01, 4.0949532e-04, 1.0319587e-03]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_tense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에 보이는 것과 같이 tense에는 3개의 타입이 있으므로 3개의 컬럼들을 볼 수 있다. 그리고 각 컬럼에 해당될 확률이 어느정도인지 저장되어 있는 형태이다. 이때 같은 row에 위치한 값들을 더해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000124564394"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_pred_tense[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1인것을 알 수 있다. 위에 softmax에서 설명한 그대로이다.\n",
    "\n",
    "따라서, 이제 이 값들을 np.argmax()를 통해서 어느 인덱스에 최고 값이 있는지 알아보고 그 인덱스에 맞춰서 맞는 label로 변형해줘야 한다.\n",
    "그 후 저장하면 제출할 수 있는 파일이 만들어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n",
    "test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n",
    "test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n",
    "test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sum = []\n",
    "for i in range(len(test_type)):\n",
    "    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n",
    "\n",
    "submission['label'] = label_sum\n",
    "submission.to_csv('submission/klue1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>TEST_7085</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>TEST_7086</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>TEST_7088</td>\n",
       "      <td>추론형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>TEST_7089</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID         label\n",
       "0     TEST_0000  사실형-긍정-현재-확실\n",
       "1     TEST_0001  사실형-긍정-현재-확실\n",
       "2     TEST_0002  사실형-긍정-과거-확실\n",
       "3     TEST_0003  사실형-긍정-과거-확실\n",
       "4     TEST_0004  사실형-긍정-과거-확실\n",
       "...         ...           ...\n",
       "7085  TEST_7085  사실형-긍정-현재-확실\n",
       "7086  TEST_7086  추론형-긍정-현재-확실\n",
       "7087  TEST_7087  사실형-긍정-미래-확실\n",
       "7088  TEST_7088  추론형-긍정-미래-확실\n",
       "7089  TEST_7089  사실형-긍정-과거-확실\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 부분이나 조언이 있다면 댓글에 남겨주세요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1201aed7278f566d08684214e947d9aa97ba318061e22672851b23b6bee3a7a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
