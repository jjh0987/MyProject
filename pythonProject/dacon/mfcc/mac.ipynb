{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7d5ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import librosa\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5116fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5001 non-null   object\n",
      " 1   path    5001 non-null   object\n",
      " 2   label   5001 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "train_df.info()\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "# valid_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56f59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':64, # Melspectrogram 벡터를 추출할 개수\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248c9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eb416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5001 non-null   object\n",
      " 1   path    5001 non-null   object\n",
      " 2   label   5001 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010677099227905273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074db9cfd345494a899206dfa855dbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004724979400634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48de70b59a8c4871ad4b05c5cc4d6b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "train_df.info()\n",
    "# train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=CFG['SEED'])\n",
    "\n",
    "def speech_file_to_array_fn(df):\n",
    "    feature = []\n",
    "    for path in tqdm(df['path']):\n",
    "        # path = '/content/drive/MyDrive/hi/sound01' + path[1:] \n",
    "        speech_array, _ = librosa.load(path, sr=CFG['SR'])\n",
    "        feature.append(1000*speech_array**3)\n",
    "    return feature\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# valid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_x = speech_file_to_array_fn(train_df)\n",
    "test_x = speech_file_to_array_fn(test_df)\n",
    "# valid_x = speech_file_to_array_fn(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1000*librosa.load(train_df['path'][1020], sr=CFG['SR'])[0]**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1893dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, processor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_values = self.processor(self.x[idx], sampling_rate=CFG['SR'], return_tensors=\"pt\", padding=True).input_values\n",
    "        if self.y is not None:\n",
    "            return input_values.squeeze(), self.y[idx]\n",
    "        else:\n",
    "            return input_values.squeeze()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence([torch.tensor(xi) for xi in x], batch_first=True)\n",
    "    y = pad_sequence([torch.tensor([yi]) for yi in y], batch_first=True)  # Convert scalar targets to 1D tensors\n",
    "    return x, y\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=collate_fn,\n",
    "                      num_workers=num_workers\n",
    "                      )\n",
    "\n",
    "train_dataset = CustomDataSet(train_x, train_df['label'], processor)\n",
    "test_dataset = CustomDataSet(test_x, y=None, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()\n",
    "\n",
    "# 0: angry\n",
    "# 1: fear\n",
    "# 2: sad\n",
    "# 3: disgust\n",
    "# 4: neutral\n",
    "# 5: happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df33ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# path = train_df['path'][0]\n",
    "        \n",
    "# y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "# y = list(y)\n",
    "# y.extend([0 for _ in range(80000-len(y))])\n",
    "# features.append(y)\n",
    "\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8d67353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016438007354736328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f094d599c664de7a79e072b34eb6be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325d43073bd74718b294ff3994f7ad8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_mel(df):\n",
    "    features = []\n",
    "    for i in tqdm(df['path']):\n",
    "        # i = '/content/drive/MyDrive/hi/sound01'+i[1:]\n",
    "        data, sr = librosa.load(i, sr=CFG['SR'])\n",
    "        data = 1000*data**3\n",
    "        n_fft = 2048\n",
    "        win_length = 2048\n",
    "        hop_length = 1024\n",
    "        n_mels = 64\n",
    " \n",
    "        D = np.abs(librosa.stft(data, n_fft=n_fft, win_length = win_length, hop_length=hop_length))\n",
    "        mel = librosa.feature.melspectrogram(S=D, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "        m_mel = mel.mean(axis=1)\n",
    "        features.append(m_mel)\n",
    "    return np.array(features)\n",
    "\n",
    "train_mel = get_feature_mel(train_df)\n",
    "# valid_mel = get_feature_mel(valid_df)\n",
    "test_mel = get_feature_mel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fca1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90945173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_mel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dad8418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54c2aefdf1f40cba67449d16873f61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4240b6608c45d49ae897e4efd43b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mfcc_feature(df):\n",
    "    features = []\n",
    "#     for path in tqdm(df['path']):\n",
    "        \n",
    "#         y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "#         y = list(y)\n",
    "#         y.extend([0 for _ in range(80100-len(y))])\n",
    "#         features.append(y)\n",
    "    for path in tqdm(df['path']):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "        y = 1000*y**3\n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "        y_feature = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature.append(np.mean(e))\n",
    "        features.append(y_feature)\n",
    "    return features\n",
    "    # return pd.DataFrame(features,columns=['freq'])\n",
    "\n",
    "vector = get_mfcc_feature(train_df)\n",
    "test_mfcc = get_mfcc_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['label'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca \n",
    "\n",
    "# pd.DataFrameFrame(vector.iloc[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=600)\n",
    "# pca.fit(vector)\n",
    "# target = pd.DataFrame(pca.transform(vector))\n",
    "# target.to_csv('./origin_600_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# max([len(i) for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(pca.transform(test))\n",
    "# test.to_csv('./test_600_pca.csv')\n",
    "\n",
    "# print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./origin_600_pca.csv')\n",
    "conc = pd.DataFrame([list(reversed(list(target.iloc[i,:]))) for i in range(len(target))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5006ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = conc.rename(columns={i:f'pca_{i}' for i in range(600)})\n",
    "target = target.rename(columns={f'{i}':f'pca_{i}' for i in range(600)}).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat([target,conc])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec09ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_0</th>\n",
       "      <th>mel_1</th>\n",
       "      <th>mel_2</th>\n",
       "      <th>mel_3</th>\n",
       "      <th>mel_4</th>\n",
       "      <th>mel_5</th>\n",
       "      <th>mel_6</th>\n",
       "      <th>mel_7</th>\n",
       "      <th>mel_8</th>\n",
       "      <th>mel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_54</th>\n",
       "      <th>mfcc_55</th>\n",
       "      <th>mfcc_56</th>\n",
       "      <th>mfcc_57</th>\n",
       "      <th>mfcc_58</th>\n",
       "      <th>mfcc_59</th>\n",
       "      <th>mfcc_60</th>\n",
       "      <th>mfcc_61</th>\n",
       "      <th>mfcc_62</th>\n",
       "      <th>mfcc_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.092294</td>\n",
       "      <td>0.091007</td>\n",
       "      <td>0.116941</td>\n",
       "      <td>0.114948</td>\n",
       "      <td>0.047119</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>0.044752</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.829365</td>\n",
       "      <td>2.442121</td>\n",
       "      <td>1.998708</td>\n",
       "      <td>1.402770</td>\n",
       "      <td>-0.094236</td>\n",
       "      <td>-0.041829</td>\n",
       "      <td>0.312695</td>\n",
       "      <td>0.695733</td>\n",
       "      <td>1.466756</td>\n",
       "      <td>0.969668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065149</td>\n",
       "      <td>0.065050</td>\n",
       "      <td>0.107233</td>\n",
       "      <td>0.123646</td>\n",
       "      <td>0.114991</td>\n",
       "      <td>0.061604</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.038930</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248797</td>\n",
       "      <td>2.043477</td>\n",
       "      <td>3.339698</td>\n",
       "      <td>3.270855</td>\n",
       "      <td>1.894282</td>\n",
       "      <td>0.698431</td>\n",
       "      <td>-0.590722</td>\n",
       "      <td>1.163717</td>\n",
       "      <td>0.133544</td>\n",
       "      <td>-0.628808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.073673</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.146078</td>\n",
       "      <td>0.145183</td>\n",
       "      <td>0.163153</td>\n",
       "      <td>0.099334</td>\n",
       "      <td>0.128659</td>\n",
       "      <td>0.131680</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076275</td>\n",
       "      <td>1.072367</td>\n",
       "      <td>0.156450</td>\n",
       "      <td>0.628312</td>\n",
       "      <td>0.578373</td>\n",
       "      <td>0.755597</td>\n",
       "      <td>-0.668103</td>\n",
       "      <td>-1.502379</td>\n",
       "      <td>-0.518559</td>\n",
       "      <td>0.458713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054856</td>\n",
       "      <td>0.118854</td>\n",
       "      <td>0.109508</td>\n",
       "      <td>0.102888</td>\n",
       "      <td>0.123376</td>\n",
       "      <td>0.117094</td>\n",
       "      <td>0.163167</td>\n",
       "      <td>0.286029</td>\n",
       "      <td>0.296922</td>\n",
       "      <td>0.189185</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.546709</td>\n",
       "      <td>0.944595</td>\n",
       "      <td>1.389473</td>\n",
       "      <td>2.566277</td>\n",
       "      <td>0.567485</td>\n",
       "      <td>-0.663395</td>\n",
       "      <td>0.149160</td>\n",
       "      <td>-1.530205</td>\n",
       "      <td>0.713372</td>\n",
       "      <td>-0.100580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056592</td>\n",
       "      <td>0.100303</td>\n",
       "      <td>0.163865</td>\n",
       "      <td>0.159117</td>\n",
       "      <td>0.221757</td>\n",
       "      <td>0.183503</td>\n",
       "      <td>0.211223</td>\n",
       "      <td>0.207461</td>\n",
       "      <td>0.158711</td>\n",
       "      <td>0.262129</td>\n",
       "      <td>...</td>\n",
       "      <td>2.906172</td>\n",
       "      <td>2.612946</td>\n",
       "      <td>0.658167</td>\n",
       "      <td>-0.804220</td>\n",
       "      <td>0.620701</td>\n",
       "      <td>1.512230</td>\n",
       "      <td>1.035760</td>\n",
       "      <td>0.305853</td>\n",
       "      <td>-0.400905</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.061863</td>\n",
       "      <td>0.113238</td>\n",
       "      <td>0.093037</td>\n",
       "      <td>0.124667</td>\n",
       "      <td>0.120672</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>0.111071</td>\n",
       "      <td>0.111648</td>\n",
       "      <td>0.077524</td>\n",
       "      <td>0.047587</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.681391</td>\n",
       "      <td>-1.243550</td>\n",
       "      <td>-0.895665</td>\n",
       "      <td>-1.086830</td>\n",
       "      <td>0.505544</td>\n",
       "      <td>0.290336</td>\n",
       "      <td>-0.582048</td>\n",
       "      <td>-0.138738</td>\n",
       "      <td>-0.930851</td>\n",
       "      <td>-1.878463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.071962</td>\n",
       "      <td>0.093476</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>0.156054</td>\n",
       "      <td>0.251519</td>\n",
       "      <td>0.664855</td>\n",
       "      <td>0.508591</td>\n",
       "      <td>0.141399</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.604691</td>\n",
       "      <td>1.926490</td>\n",
       "      <td>1.580529</td>\n",
       "      <td>1.010258</td>\n",
       "      <td>0.817413</td>\n",
       "      <td>0.841381</td>\n",
       "      <td>0.145495</td>\n",
       "      <td>0.760276</td>\n",
       "      <td>0.284756</td>\n",
       "      <td>1.317319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.078089</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.131051</td>\n",
       "      <td>0.110353</td>\n",
       "      <td>0.145028</td>\n",
       "      <td>0.195545</td>\n",
       "      <td>0.088464</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>0.100964</td>\n",
       "      <td>0.073463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431391</td>\n",
       "      <td>0.913676</td>\n",
       "      <td>1.849735</td>\n",
       "      <td>1.892341</td>\n",
       "      <td>1.709681</td>\n",
       "      <td>2.131955</td>\n",
       "      <td>-0.813240</td>\n",
       "      <td>-0.233484</td>\n",
       "      <td>0.330278</td>\n",
       "      <td>0.528793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.061680</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>0.125978</td>\n",
       "      <td>0.058736</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>0.075699</td>\n",
       "      <td>0.035021</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081796</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>1.881899</td>\n",
       "      <td>2.106781</td>\n",
       "      <td>1.572352</td>\n",
       "      <td>1.599251</td>\n",
       "      <td>-0.203526</td>\n",
       "      <td>0.769150</td>\n",
       "      <td>-0.163830</td>\n",
       "      <td>0.241779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.072534</td>\n",
       "      <td>0.112990</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>0.125570</td>\n",
       "      <td>0.096479</td>\n",
       "      <td>0.073061</td>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.100913</td>\n",
       "      <td>0.056151</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.127362</td>\n",
       "      <td>0.601312</td>\n",
       "      <td>0.093229</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>-0.061977</td>\n",
       "      <td>0.932147</td>\n",
       "      <td>-0.432104</td>\n",
       "      <td>2.207381</td>\n",
       "      <td>0.992438</td>\n",
       "      <td>0.613909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mel_0     mel_1     mel_2     mel_3     mel_4     mel_5     mel_6  \\\n",
       "0     0.066779  0.092294  0.091007  0.116941  0.114948  0.047119  0.037005   \n",
       "1     0.065149  0.065050  0.107233  0.123646  0.114991  0.061604  0.078864   \n",
       "2     0.063477  0.073673  0.124614  0.146078  0.145183  0.163153  0.099334   \n",
       "3     0.054856  0.118854  0.109508  0.102888  0.123376  0.117094  0.163167   \n",
       "4     0.056592  0.100303  0.163865  0.159117  0.221757  0.183503  0.211223   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996  0.061863  0.113238  0.093037  0.124667  0.120672  0.108512  0.111071   \n",
       "4997  0.071962  0.093476  0.087518  0.099995  0.156054  0.251519  0.664855   \n",
       "4998  0.078089  0.068359  0.131051  0.110353  0.145028  0.195545  0.088464   \n",
       "4999  0.061680  0.089095  0.080302  0.098390  0.125978  0.058736  0.040418   \n",
       "5000  0.023546  0.072534  0.112990  0.109893  0.125570  0.096479  0.073061   \n",
       "\n",
       "         mel_7     mel_8     mel_9  ...   mfcc_54   mfcc_55   mfcc_56  \\\n",
       "0     0.045050  0.044752  0.021855  ...  2.829365  2.442121  1.998708   \n",
       "1     0.038930  0.025847  0.036424  ...  0.248797  2.043477  3.339698   \n",
       "2     0.128659  0.131680  0.215220  ...  1.076275  1.072367  0.156450   \n",
       "3     0.286029  0.296922  0.189185  ... -1.546709  0.944595  1.389473   \n",
       "4     0.207461  0.158711  0.262129  ...  2.906172  2.612946  0.658167   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4996  0.111648  0.077524  0.047587  ... -1.681391 -1.243550 -0.895665   \n",
       "4997  0.508591  0.141399  0.073500  ...  3.604691  1.926490  1.580529   \n",
       "4998  0.054596  0.100964  0.073463  ...  0.431391  0.913676  1.849735   \n",
       "4999  0.075699  0.035021  0.036867  ... -0.081796  1.222345  1.881899   \n",
       "5000  0.078165  0.100913  0.056151  ... -1.127362  0.601312  0.093229   \n",
       "\n",
       "       mfcc_57   mfcc_58   mfcc_59   mfcc_60   mfcc_61   mfcc_62   mfcc_63  \n",
       "0     1.402770 -0.094236 -0.041829  0.312695  0.695733  1.466756  0.969668  \n",
       "1     3.270855  1.894282  0.698431 -0.590722  1.163717  0.133544 -0.628808  \n",
       "2     0.628312  0.578373  0.755597 -0.668103 -1.502379 -0.518559  0.458713  \n",
       "3     2.566277  0.567485 -0.663395  0.149160 -1.530205  0.713372 -0.100580  \n",
       "4    -0.804220  0.620701  1.512230  1.035760  0.305853 -0.400905  0.693600  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4996 -1.086830  0.505544  0.290336 -0.582048 -0.138738 -0.930851 -1.878463  \n",
       "4997  1.010258  0.817413  0.841381  0.145495  0.760276  0.284756  1.317319  \n",
       "4998  1.892341  1.709681  2.131955 -0.813240 -0.233484  0.330278  0.528793  \n",
       "4999  2.106781  1.572352  1.599251 -0.203526  0.769150 -0.163830  0.241779  \n",
       "5000  0.010488 -0.061977  0.932147 -0.432104  2.207381  0.992438  0.613909  \n",
       "\n",
       "[5001 rows x 128 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = pd.DataFrame(vector,columns=[f'mfcc_{i}' for i in range(64)])\n",
    "train = pd.DataFrame(train_mel,columns=[f'mel_{i}' for i in range(64)])\n",
    "# train = train.rename(columns={f'{i}':f'mel_{i}' for i in range(128)})\n",
    "train = pd.concat([train,vector],axis=1)\n",
    "# train = pd.concat([train,tp],axis=1)\n",
    "# del(tp)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b57fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02bfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=[len(train.keys())]),\n",
    "        # layers.MaxPooling1D(pool_size=2,strides=1, padding='valid'),\n",
    "        layers.Dense(512),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(6,activation='softmax')\n",
    "        ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a8ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,686\n",
      "Trainable params: 167,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6964f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# skf = sklearn.model_selection.StratifiedKFold(n_splits=10)\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "383d4efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0901 - accuracy: 0.5605 - val_loss: 1.2498 - val_accuracy: 0.5130\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0435 - accuracy: 0.5857 - val_loss: 1.1464 - val_accuracy: 0.5550\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0224 - accuracy: 0.5932 - val_loss: 1.0994 - val_accuracy: 0.5790\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0018 - accuracy: 0.6060 - val_loss: 1.0659 - val_accuracy: 0.5850\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9878 - accuracy: 0.5987 - val_loss: 1.0489 - val_accuracy: 0.5810\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9558 - accuracy: 0.6263 - val_loss: 1.0118 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9567 - accuracy: 0.6248 - val_loss: 1.0452 - val_accuracy: 0.6040\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9434 - accuracy: 0.6285 - val_loss: 0.9663 - val_accuracy: 0.6110\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9123 - accuracy: 0.6430 - val_loss: 0.9311 - val_accuracy: 0.6270\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9094 - accuracy: 0.6405 - val_loss: 0.9407 - val_accuracy: 0.6210\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9018 - accuracy: 0.6453 - val_loss: 0.9864 - val_accuracy: 0.6150\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8908 - accuracy: 0.6530 - val_loss: 0.8676 - val_accuracy: 0.6640\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8880 - accuracy: 0.6485 - val_loss: 0.9293 - val_accuracy: 0.6170\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8841 - accuracy: 0.6593 - val_loss: 0.8813 - val_accuracy: 0.6610\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8598 - accuracy: 0.6658 - val_loss: 0.9555 - val_accuracy: 0.6330\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8502 - accuracy: 0.6665 - val_loss: 0.8342 - val_accuracy: 0.6710\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8287 - accuracy: 0.6825 - val_loss: 0.9172 - val_accuracy: 0.6480\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8403 - accuracy: 0.6700 - val_loss: 0.9175 - val_accuracy: 0.6520\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8429 - accuracy: 0.6660 - val_loss: 0.9489 - val_accuracy: 0.6420\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8358 - accuracy: 0.6733 - val_loss: 0.8231 - val_accuracy: 0.6750\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8075 - accuracy: 0.6913 - val_loss: 0.7835 - val_accuracy: 0.7020\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8158 - accuracy: 0.6867 - val_loss: 0.8206 - val_accuracy: 0.6740\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8081 - accuracy: 0.6810 - val_loss: 0.7961 - val_accuracy: 0.6920\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7922 - accuracy: 0.6913 - val_loss: 0.7902 - val_accuracy: 0.6880\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7755 - accuracy: 0.7078 - val_loss: 0.8004 - val_accuracy: 0.6820\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7499 - accuracy: 0.7100 - val_loss: 0.7582 - val_accuracy: 0.7190\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7685 - accuracy: 0.7028 - val_loss: 0.7554 - val_accuracy: 0.6950\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7241 - accuracy: 0.7128 - val_loss: 0.7520 - val_accuracy: 0.7010\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7531 - accuracy: 0.7082 - val_loss: 0.7651 - val_accuracy: 0.6920\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7574 - accuracy: 0.7082 - val_loss: 0.7625 - val_accuracy: 0.6990\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7383 - accuracy: 0.7157 - val_loss: 0.7012 - val_accuracy: 0.7250\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6956 - accuracy: 0.7350 - val_loss: 0.6567 - val_accuracy: 0.7450\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7075 - accuracy: 0.7262 - val_loss: 0.7350 - val_accuracy: 0.7210\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7035 - accuracy: 0.7303 - val_loss: 0.8147 - val_accuracy: 0.6960\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7163 - accuracy: 0.7218 - val_loss: 0.7676 - val_accuracy: 0.7030\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6884 - accuracy: 0.7385 - val_loss: 0.7305 - val_accuracy: 0.7120\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6896 - accuracy: 0.7380 - val_loss: 0.6143 - val_accuracy: 0.7570\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7023 - accuracy: 0.7375 - val_loss: 0.6249 - val_accuracy: 0.7560\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6663 - accuracy: 0.7470 - val_loss: 0.7662 - val_accuracy: 0.7100\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6504 - accuracy: 0.7483 - val_loss: 0.6185 - val_accuracy: 0.7570\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6481 - accuracy: 0.7465 - val_loss: 0.6491 - val_accuracy: 0.7530\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6646 - accuracy: 0.7450 - val_loss: 0.6061 - val_accuracy: 0.7750\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6264 - accuracy: 0.7588 - val_loss: 0.6417 - val_accuracy: 0.7470\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6145 - accuracy: 0.7613 - val_loss: 0.5836 - val_accuracy: 0.7610\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6283 - accuracy: 0.7550 - val_loss: 0.6348 - val_accuracy: 0.7520\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6222 - accuracy: 0.7598 - val_loss: 0.6325 - val_accuracy: 0.7550\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6273 - accuracy: 0.7600 - val_loss: 0.6442 - val_accuracy: 0.7560\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5968 - accuracy: 0.7657 - val_loss: 0.5653 - val_accuracy: 0.7860\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5729 - accuracy: 0.7872 - val_loss: 0.5217 - val_accuracy: 0.8170\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5903 - accuracy: 0.7747 - val_loss: 0.6017 - val_accuracy: 0.7800\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.9805 - accuracy: 0.6651 - val_loss: 0.7412 - val_accuracy: 0.7010\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.8867 - accuracy: 0.6708 - val_loss: 0.7495 - val_accuracy: 0.7010\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7875 - accuracy: 0.7031 - val_loss: 0.7742 - val_accuracy: 0.7080\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7811 - accuracy: 0.7043 - val_loss: 0.7707 - val_accuracy: 0.7090\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7626 - accuracy: 0.7163 - val_loss: 0.8315 - val_accuracy: 0.6830\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7838 - accuracy: 0.7023 - val_loss: 0.7472 - val_accuracy: 0.7120\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7414 - accuracy: 0.7173 - val_loss: 0.8300 - val_accuracy: 0.6830\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7396 - accuracy: 0.7203 - val_loss: 0.8950 - val_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7339 - accuracy: 0.7206 - val_loss: 0.9338 - val_accuracy: 0.6550\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7822 - accuracy: 0.7058 - val_loss: 0.8906 - val_accuracy: 0.6640\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8064 - accuracy: 0.7031 - val_loss: 0.9265 - val_accuracy: 0.6650\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7050 - accuracy: 0.7296 - val_loss: 1.1705 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7965 - accuracy: 0.6886 - val_loss: 1.0095 - val_accuracy: 0.6210\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7254 - accuracy: 0.7233 - val_loss: 0.9375 - val_accuracy: 0.6460\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7170 - accuracy: 0.7246 - val_loss: 1.0334 - val_accuracy: 0.6310\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6640 - accuracy: 0.7513 - val_loss: 1.0197 - val_accuracy: 0.6290\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7075 - accuracy: 0.7251 - val_loss: 1.0091 - val_accuracy: 0.6390\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6587 - accuracy: 0.7388 - val_loss: 1.0006 - val_accuracy: 0.6270\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7341 - val_loss: 1.1065 - val_accuracy: 0.6280\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6336 - accuracy: 0.7561 - val_loss: 1.2683 - val_accuracy: 0.5950\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6771 - accuracy: 0.7436 - val_loss: 1.1988 - val_accuracy: 0.5700\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7580 - accuracy: 0.7133 - val_loss: 1.2056 - val_accuracy: 0.6070\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6353 - accuracy: 0.7633 - val_loss: 1.0729 - val_accuracy: 0.6110\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6628 - accuracy: 0.7448 - val_loss: 1.0951 - val_accuracy: 0.6170\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6059 - accuracy: 0.7713 - val_loss: 1.1377 - val_accuracy: 0.6070\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6111 - accuracy: 0.7646 - val_loss: 1.1562 - val_accuracy: 0.6130\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7623 - accuracy: 0.7136 - val_loss: 1.1350 - val_accuracy: 0.5930\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6161 - accuracy: 0.7648 - val_loss: 1.1816 - val_accuracy: 0.6180\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.7556 - val_loss: 1.1256 - val_accuracy: 0.6180\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5631 - accuracy: 0.7838 - val_loss: 1.2405 - val_accuracy: 0.6170\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6595 - accuracy: 0.7488 - val_loss: 1.2384 - val_accuracy: 0.6030\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6541 - accuracy: 0.7566 - val_loss: 1.1640 - val_accuracy: 0.6080\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.7653 - val_loss: 1.3048 - val_accuracy: 0.5840\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5748 - accuracy: 0.7786 - val_loss: 1.2398 - val_accuracy: 0.6030\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7793 - val_loss: 1.1935 - val_accuracy: 0.5920\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.7713 - val_loss: 1.3523 - val_accuracy: 0.5900\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5708 - accuracy: 0.7798 - val_loss: 1.2424 - val_accuracy: 0.5940\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7873 - val_loss: 1.4270 - val_accuracy: 0.5660\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5622 - accuracy: 0.7856 - val_loss: 1.4214 - val_accuracy: 0.5860\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5403 - accuracy: 0.7886 - val_loss: 1.3275 - val_accuracy: 0.5880\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6554 - accuracy: 0.7533 - val_loss: 1.3751 - val_accuracy: 0.5840\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7198 - accuracy: 0.7213 - val_loss: 1.3806 - val_accuracy: 0.5610\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6888 - accuracy: 0.7356 - val_loss: 1.3499 - val_accuracy: 0.5480\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6991 - accuracy: 0.7318 - val_loss: 1.2806 - val_accuracy: 0.5920\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6228 - accuracy: 0.7613 - val_loss: 1.6215 - val_accuracy: 0.5530\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7508 - val_loss: 1.2982 - val_accuracy: 0.5800\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6837 - accuracy: 0.7341 - val_loss: 1.3980 - val_accuracy: 0.5650\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6110 - accuracy: 0.7641 - val_loss: 1.3559 - val_accuracy: 0.5670\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7246 - accuracy: 0.7118 - val_loss: 1.5381 - val_accuracy: 0.5470\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6448 - accuracy: 0.7483 - val_loss: 1.4578 - val_accuracy: 0.5590\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.9207 - accuracy: 0.6556 - val_loss: 0.6536 - val_accuracy: 0.7560\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8325 - accuracy: 0.6956 - val_loss: 0.6701 - val_accuracy: 0.7540\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7506 - accuracy: 0.7093 - val_loss: 0.6648 - val_accuracy: 0.7420\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7451 - accuracy: 0.7108 - val_loss: 0.6764 - val_accuracy: 0.7370\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7009 - accuracy: 0.7281 - val_loss: 0.7351 - val_accuracy: 0.7140\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7215 - accuracy: 0.7266 - val_loss: 0.7110 - val_accuracy: 0.7210\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6537 - accuracy: 0.7526 - val_loss: 0.6797 - val_accuracy: 0.7450\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6533 - accuracy: 0.7541 - val_loss: 0.7202 - val_accuracy: 0.7360\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6674 - accuracy: 0.7456 - val_loss: 0.7246 - val_accuracy: 0.7230\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6397 - accuracy: 0.7556 - val_loss: 0.7952 - val_accuracy: 0.7070\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.7473 - val_loss: 0.8376 - val_accuracy: 0.6990\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6162 - accuracy: 0.7698 - val_loss: 0.7935 - val_accuracy: 0.6880\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6874 - accuracy: 0.7376 - val_loss: 0.7880 - val_accuracy: 0.7010\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6624 - accuracy: 0.7421 - val_loss: 0.7766 - val_accuracy: 0.7130\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.7688 - val_loss: 0.7954 - val_accuracy: 0.7070\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6625 - accuracy: 0.7463 - val_loss: 0.8624 - val_accuracy: 0.6760\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6042 - accuracy: 0.7683 - val_loss: 0.7802 - val_accuracy: 0.7090\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6076 - accuracy: 0.7671 - val_loss: 0.9227 - val_accuracy: 0.6750\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5731 - accuracy: 0.7833 - val_loss: 1.0199 - val_accuracy: 0.6580\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5965 - accuracy: 0.7646 - val_loss: 0.8645 - val_accuracy: 0.6890\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5684 - accuracy: 0.7791 - val_loss: 0.9467 - val_accuracy: 0.6760\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5875 - accuracy: 0.7701 - val_loss: 0.9926 - val_accuracy: 0.6590\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.7966 - val_loss: 0.9981 - val_accuracy: 0.6770\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5771 - accuracy: 0.7793 - val_loss: 0.9604 - val_accuracy: 0.6790\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.8025 - val_loss: 0.9267 - val_accuracy: 0.6930\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5823 - accuracy: 0.7763 - val_loss: 0.9789 - val_accuracy: 0.6470\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5785 - accuracy: 0.7761 - val_loss: 1.0372 - val_accuracy: 0.6650\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5245 - accuracy: 0.8003 - val_loss: 1.0137 - val_accuracy: 0.6710\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7848 - val_loss: 1.1387 - val_accuracy: 0.6610\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5436 - accuracy: 0.7893 - val_loss: 1.1647 - val_accuracy: 0.6380\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6772 - accuracy: 0.7468 - val_loss: 1.1348 - val_accuracy: 0.6240\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5876 - accuracy: 0.7718 - val_loss: 1.0491 - val_accuracy: 0.6620\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.8013 - val_loss: 1.1099 - val_accuracy: 0.6500\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5098 - accuracy: 0.8078 - val_loss: 1.0618 - val_accuracy: 0.6340\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.7661 - val_loss: 1.1738 - val_accuracy: 0.6220\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5569 - accuracy: 0.7833 - val_loss: 1.1398 - val_accuracy: 0.6240\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7711 - accuracy: 0.7198 - val_loss: 1.1331 - val_accuracy: 0.6010\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7843 - val_loss: 1.1049 - val_accuracy: 0.6460\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5335 - accuracy: 0.7946 - val_loss: 1.2180 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7968 - val_loss: 1.2144 - val_accuracy: 0.5970\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7958 - val_loss: 1.2890 - val_accuracy: 0.6150\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7866 - val_loss: 1.2786 - val_accuracy: 0.6090\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6251 - accuracy: 0.7708 - val_loss: 1.2586 - val_accuracy: 0.5950\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7886 - val_loss: 1.1763 - val_accuracy: 0.6260\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.7918 - val_loss: 1.1354 - val_accuracy: 0.6400\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4965 - accuracy: 0.8065 - val_loss: 1.2303 - val_accuracy: 0.6300\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7823 - val_loss: 1.6357 - val_accuracy: 0.5900\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5610 - accuracy: 0.7843 - val_loss: 1.2767 - val_accuracy: 0.6130\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5438 - accuracy: 0.7963 - val_loss: 1.2784 - val_accuracy: 0.6300\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.8133 - val_loss: 1.6022 - val_accuracy: 0.6130\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8062 - accuracy: 0.7198 - val_loss: 0.5388 - val_accuracy: 0.8010\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6758 - accuracy: 0.7511 - val_loss: 0.5359 - val_accuracy: 0.7890\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6103 - accuracy: 0.7701 - val_loss: 0.4967 - val_accuracy: 0.8010\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5766 - accuracy: 0.7843 - val_loss: 0.5576 - val_accuracy: 0.7950\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.7831 - val_loss: 0.6734 - val_accuracy: 0.7410\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6698 - accuracy: 0.7483 - val_loss: 0.5853 - val_accuracy: 0.7820\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5993 - accuracy: 0.7676 - val_loss: 0.6141 - val_accuracy: 0.7650\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6631 - accuracy: 0.7448 - val_loss: 0.5808 - val_accuracy: 0.7850\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5531 - accuracy: 0.7898 - val_loss: 0.6461 - val_accuracy: 0.7450\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5605 - accuracy: 0.7871 - val_loss: 0.5821 - val_accuracy: 0.7780\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5695 - accuracy: 0.7878 - val_loss: 0.7450 - val_accuracy: 0.7390\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.7408 - val_loss: 0.6723 - val_accuracy: 0.7540\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7888 - val_loss: 0.6923 - val_accuracy: 0.7580\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5924 - accuracy: 0.7781 - val_loss: 0.6189 - val_accuracy: 0.7560\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7916 - val_loss: 0.6660 - val_accuracy: 0.7590\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7858 - val_loss: 0.7369 - val_accuracy: 0.7250\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6948 - accuracy: 0.7373 - val_loss: 0.7327 - val_accuracy: 0.7210\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7686 - val_loss: 0.7365 - val_accuracy: 0.7320\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5568 - accuracy: 0.7843 - val_loss: 0.7422 - val_accuracy: 0.7210\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5536 - accuracy: 0.7798 - val_loss: 0.7660 - val_accuracy: 0.7300\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5503 - accuracy: 0.7856 - val_loss: 0.8213 - val_accuracy: 0.7030\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.8542 - accuracy: 0.7086 - val_loss: 0.9053 - val_accuracy: 0.6690\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8077 - accuracy: 0.7056 - val_loss: 0.8547 - val_accuracy: 0.7060\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6245 - accuracy: 0.7568 - val_loss: 0.8497 - val_accuracy: 0.7040\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5853 - accuracy: 0.7758 - val_loss: 0.8874 - val_accuracy: 0.6770\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5685 - accuracy: 0.7776 - val_loss: 0.8863 - val_accuracy: 0.6830\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6004 - accuracy: 0.7633 - val_loss: 0.9161 - val_accuracy: 0.6820\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5811 - accuracy: 0.7731 - val_loss: 0.9825 - val_accuracy: 0.6750\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5722 - accuracy: 0.7766 - val_loss: 0.9348 - val_accuracy: 0.6810\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7873 - val_loss: 0.8803 - val_accuracy: 0.7100\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7921 - val_loss: 0.9202 - val_accuracy: 0.6800\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5542 - accuracy: 0.7863 - val_loss: 1.0157 - val_accuracy: 0.6820\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7773 - val_loss: 0.9528 - val_accuracy: 0.6870\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.8070 - val_loss: 0.9685 - val_accuracy: 0.6850\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5169 - accuracy: 0.7983 - val_loss: 0.9595 - val_accuracy: 0.6860\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5164 - accuracy: 0.8043 - val_loss: 1.0065 - val_accuracy: 0.6700\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6159 - accuracy: 0.7658 - val_loss: 1.0092 - val_accuracy: 0.6700\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7921 - val_loss: 1.1062 - val_accuracy: 0.6710\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4835 - accuracy: 0.8145 - val_loss: 0.9691 - val_accuracy: 0.6800\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.8075 - val_loss: 1.1080 - val_accuracy: 0.6690\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.7993 - val_loss: 1.1756 - val_accuracy: 0.6640\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5702 - accuracy: 0.7776 - val_loss: 0.9696 - val_accuracy: 0.6870\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4798 - accuracy: 0.8160 - val_loss: 1.0888 - val_accuracy: 0.6670\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.8000 - val_loss: 1.0469 - val_accuracy: 0.6770\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4831 - accuracy: 0.8075 - val_loss: 1.0629 - val_accuracy: 0.6850\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.8260 - val_loss: 1.0054 - val_accuracy: 0.6880\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.8085 - val_loss: 1.1592 - val_accuracy: 0.6730\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7991 - val_loss: 1.0784 - val_accuracy: 0.6700\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.8088 - val_loss: 1.1535 - val_accuracy: 0.6500\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6023 - accuracy: 0.7751 - val_loss: 1.1231 - val_accuracy: 0.6580\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6931 - accuracy: 0.7516 - val_loss: 0.6080 - val_accuracy: 0.7810\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6255 - accuracy: 0.7641 - val_loss: 0.5462 - val_accuracy: 0.7850\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.5705 - accuracy: 0.7816 - val_loss: 0.4570 - val_accuracy: 0.8240\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5596 - accuracy: 0.7898 - val_loss: 0.4386 - val_accuracy: 0.8300\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7943 - val_loss: 0.5443 - val_accuracy: 0.7870\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7990\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7976 - val_loss: 0.5358 - val_accuracy: 0.7970\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5057 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.8063 - val_loss: 0.5351 - val_accuracy: 0.7880\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.8020 - val_loss: 0.6104 - val_accuracy: 0.7550\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.8088 - val_loss: 0.5215 - val_accuracy: 0.8080\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.8158 - val_loss: 0.6194 - val_accuracy: 0.7670\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5186 - accuracy: 0.7938 - val_loss: 0.6875 - val_accuracy: 0.7470\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5176 - accuracy: 0.8003 - val_loss: 0.5809 - val_accuracy: 0.7750\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.8195 - val_loss: 0.5908 - val_accuracy: 0.7690\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4519 - accuracy: 0.8250 - val_loss: 0.6021 - val_accuracy: 0.7750\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.8358 - val_loss: 0.6449 - val_accuracy: 0.7600\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4816 - accuracy: 0.8095 - val_loss: 0.7051 - val_accuracy: 0.7380\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7961 - val_loss: 0.6664 - val_accuracy: 0.7560\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5572 - accuracy: 0.7866 - val_loss: 0.6338 - val_accuracy: 0.7450\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4964 - accuracy: 0.8075 - val_loss: 0.7250 - val_accuracy: 0.7250\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.8243 - val_loss: 0.6919 - val_accuracy: 0.7360\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.8013 - val_loss: 0.7310 - val_accuracy: 0.7350\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4695 - accuracy: 0.8178 - val_loss: 0.7615 - val_accuracy: 0.7290\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4773 - accuracy: 0.8188 - val_loss: 0.7888 - val_accuracy: 0.7380\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4469 - accuracy: 0.8290 - val_loss: 0.7976 - val_accuracy: 0.7170\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6152 - accuracy: 0.7631 - val_loss: 0.9987 - val_accuracy: 0.6640\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4903 - accuracy: 0.8068 - val_loss: 0.8086 - val_accuracy: 0.7170\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5132 - accuracy: 0.7966 - val_loss: 0.8142 - val_accuracy: 0.7260\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4725 - accuracy: 0.8158 - val_loss: 0.8000 - val_accuracy: 0.7170\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8303 - val_loss: 0.8817 - val_accuracy: 0.6970\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4719 - accuracy: 0.8128 - val_loss: 1.0356 - val_accuracy: 0.6890\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.8103 - val_loss: 0.8894 - val_accuracy: 0.7240\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5145 - accuracy: 0.8063 - val_loss: 0.9601 - val_accuracy: 0.6970\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.8338 - val_loss: 0.9760 - val_accuracy: 0.6910\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8015 - val_loss: 0.9735 - val_accuracy: 0.6870\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.8165 - val_loss: 0.9677 - val_accuracy: 0.6840\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.8268 - val_loss: 1.0111 - val_accuracy: 0.6950\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.8318 - val_loss: 0.9392 - val_accuracy: 0.6980\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8425 - val_loss: 0.9035 - val_accuracy: 0.7220\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8288 - val_loss: 1.0180 - val_accuracy: 0.6780\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.8300 - val_loss: 1.1343 - val_accuracy: 0.6710\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.8268 - val_loss: 1.0443 - val_accuracy: 0.7050\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4307 - accuracy: 0.8290 - val_loss: 1.1087 - val_accuracy: 0.6800\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8408 - val_loss: 1.1208 - val_accuracy: 0.6880\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6118 - accuracy: 0.7848 - val_loss: 1.0902 - val_accuracy: 0.6700\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5562 - accuracy: 0.8038 - val_loss: 1.0572 - val_accuracy: 0.6890\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8385 - val_loss: 1.0898 - val_accuracy: 0.6780\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.3912 - accuracy: 0.8410 - val_loss: 1.1022 - val_accuracy: 0.6860\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8370 - val_loss: 1.1324 - val_accuracy: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# class PrintDot(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         if epoch % 100 == 0: print('')\n",
    "#         print('.', end='')\n",
    "\n",
    "# EPOCHS = 1000\n",
    "\n",
    "# history = model.fit(\n",
    "#   train, train_df['label'],\n",
    "#   epochs=EPOCHS, validation_split = 0.1, verbose=0,\n",
    "#   callbacks=[PrintDot()])\n",
    "\n",
    "\n",
    "\n",
    "skf = sklearn.model_selection.KFold(n_splits=5)\n",
    "models = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "    model.fit(train.loc[train_index,:]\n",
    "              , train_df.loc[train_index,'label']\n",
    "              , epochs=50\n",
    "              , validation_data=(train.loc[test_index,:],train_df.loc[test_index,'label'])) # validation_split=0.1,\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc27c46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification\n\u001b[1;32m      2\u001b[0m classification\u001b[38;5;241m.\u001b[39msetup(data\u001b[38;5;241m=\u001b[39mtrain,target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from pycaret import classification\n",
    "# classification.setup(data=train,target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deaf394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_mel,columns=[f'mel_{i}' for i in range(64)])\n",
    "vector = pd.DataFrame(test_mfcc,columns=[f'mfcc_{i}' for i in range(64)])\n",
    "test = pd.concat([test,vector],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eed601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb0cecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step\n",
      "59/59 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "59/59 [==============================] - 1s 9ms/step\n",
      "59/59 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = [i.predict(test) for i in models]\n",
    "preds = [np.argmax(i) for i in np.array(preds).mean(axis=0)]\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2cd30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['label'] = preds # 0,2,3\n",
    "submission.to_csv('./baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
