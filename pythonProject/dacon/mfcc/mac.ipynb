{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7d5ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import librosa\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f56f59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':256, # Melspectrogram 벡터를 추출할 개수\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "248c9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46e0185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5001 non-null   object\n",
      " 1   path    5001 non-null   object\n",
      " 2   label   5001 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010677099227905273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074db9cfd345494a899206dfa855dbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004724979400634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48de70b59a8c4871ad4b05c5cc4d6b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "train_df.info()\n",
    "# train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=CFG['SEED'])\n",
    "\n",
    "def speech_file_to_array_fn(df):\n",
    "    feature = []\n",
    "    for path in tqdm(df['path']):\n",
    "        # path = '/content/drive/MyDrive/hi/sound01' + path[1:] \n",
    "        speech_array, _ = librosa.load(path, sr=CFG['SR'])\n",
    "        feature.append(1000*speech_array**3)\n",
    "    return feature\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# valid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_x = speech_file_to_array_fn(train_df)\n",
    "test_x = speech_file_to_array_fn(test_df)\n",
    "# valid_x = speech_file_to_array_fn(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccfcd38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13cefd280>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1000*librosa.load(train_df['path'][1020], sr=CFG['SR'])[0]**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1893dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, processor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_values = self.processor(self.x[idx], sampling_rate=CFG['SR'], return_tensors=\"pt\", padding=True).input_values\n",
    "        if self.y is not None:\n",
    "            return input_values.squeeze(), self.y[idx]\n",
    "        else:\n",
    "            return input_values.squeeze()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence([torch.tensor(xi) for xi in x], batch_first=True)\n",
    "    y = pad_sequence([torch.tensor([yi]) for yi in y], batch_first=True)  # Convert scalar targets to 1D tensors\n",
    "    return x, y\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=collate_fn,\n",
    "                      num_workers=num_workers\n",
    "                      )\n",
    "\n",
    "train_dataset = CustomDataSet(train_x, train_df['label'], processor)\n",
    "test_dataset = CustomDataSet(test_x, y=None, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140c883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    867\n",
       "2    859\n",
       "5    853\n",
       "3    852\n",
       "1    848\n",
       "4    722\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()\n",
    "\n",
    "# 0: angry\n",
    "# 1: fear\n",
    "# 2: sad\n",
    "# 3: disgust\n",
    "# 4: neutral\n",
    "# 5: happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df33ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# path = train_df['path'][0]\n",
    "        \n",
    "# y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "# y = list(y)\n",
    "# y.extend([0 for _ in range(80000-len(y))])\n",
    "# features.append(y)\n",
    "\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8d67353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016438007354736328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e89fc8eaf87436199abb7b264254888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004730701446533203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ede4b27ebe42238dfcba3c4dc76b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_mel(df):\n",
    "    features = []\n",
    "    for i in tqdm(df['path']):\n",
    "        # i = '/content/drive/MyDrive/hi/sound01'+i[1:]\n",
    "        data, sr = librosa.load(i, sr=CFG['SR'])\n",
    "        data = 1000*data**3\n",
    "        n_fft = 2048\n",
    "        win_length = 2048\n",
    "        hop_length = 1024\n",
    "        n_mels = 512-128\n",
    " \n",
    "        D = np.abs(librosa.stft(data, n_fft=n_fft, win_length = win_length, hop_length=hop_length))\n",
    "        mel = librosa.feature.melspectrogram(S=D, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "        m_mel = mel.mean(axis=1)\n",
    "        features.append(m_mel)\n",
    "    return np.array(features)\n",
    "\n",
    "train_mel = get_feature_mel(train_df)\n",
    "# valid_mel = get_feature_mel(valid_df)\n",
    "test_mel = get_feature_mel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575ac43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90945173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x132ea9a00>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_mel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dad8418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014815807342529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82d49e429f74b1996d68b8f7171ed30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004728794097900391,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36da887683864b35a51b0acc2283d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mfcc_feature(df):\n",
    "    features = []\n",
    "#     for path in tqdm(df['path']):\n",
    "        \n",
    "#         y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "#         y = list(y)\n",
    "#         y.extend([0 for _ in range(80100-len(y))])\n",
    "#         features.append(y)\n",
    "    for path in tqdm(df['path']):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "        y = 1000*y**3\n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "        y_feature = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature.append(np.mean(e))\n",
    "        features.append(y_feature)\n",
    "    return features\n",
    "    # return pd.DataFrame(features,columns=['freq'])\n",
    "\n",
    "vector = get_mfcc_feature(train_df)\n",
    "test = get_mfcc_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f62b3828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 128)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vector).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd74880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1302b0fa0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['label'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fb978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca \n",
    "\n",
    "# pd.DataFrameFrame(vector.iloc[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f8dc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=600)\n",
    "# pca.fit(vector)\n",
    "# target = pd.DataFrame(pca.transform(vector))\n",
    "# target.to_csv('./origin_600_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# max([len(i) for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aadd0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(pca.transform(test))\n",
    "# test.to_csv('./test_600_pca.csv')\n",
    "\n",
    "# print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df0f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./origin_600_pca.csv')\n",
    "conc = pd.DataFrame([list(reversed(list(target.iloc[i,:]))) for i in range(len(target))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf5006ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = conc.rename(columns={i:f'pca_{i}' for i in range(600)})\n",
    "target = target.rename(columns={f'{i}':f'pca_{i}' for i in range(600)}).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2413eeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_591</th>\n",
       "      <th>pca_592</th>\n",
       "      <th>pca_593</th>\n",
       "      <th>pca_594</th>\n",
       "      <th>pca_595</th>\n",
       "      <th>pca_596</th>\n",
       "      <th>pca_597</th>\n",
       "      <th>pca_598</th>\n",
       "      <th>pca_599</th>\n",
       "      <th>600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021385</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>-0.011877</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>-0.033308</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.014967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021627</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>-0.011496</td>\n",
       "      <td>-0.020011</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>-0.015379</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000776</td>\n",
       "      <td>-0.021042</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>-0.016736</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>-0.008290</td>\n",
       "      <td>-0.016119</td>\n",
       "      <td>-0.025994</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>-0.003917</td>\n",
       "      <td>-0.002894</td>\n",
       "      <td>-0.017801</td>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-0.012204</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>-0.011025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052751</td>\n",
       "      <td>-0.054740</td>\n",
       "      <td>0.227633</td>\n",
       "      <td>0.128646</td>\n",
       "      <td>0.051232</td>\n",
       "      <td>0.086255</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>-0.093411</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>-0.141729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227377</td>\n",
       "      <td>0.047490</td>\n",
       "      <td>-0.014826</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.098491</td>\n",
       "      <td>-0.055566</td>\n",
       "      <td>-0.131283</td>\n",
       "      <td>0.103348</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002264</td>\n",
       "      <td>-0.053758</td>\n",
       "      <td>-0.065805</td>\n",
       "      <td>0.123830</td>\n",
       "      <td>-0.039335</td>\n",
       "      <td>-0.074199</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>-0.034714</td>\n",
       "      <td>-0.094504</td>\n",
       "      <td>0.037295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246421</td>\n",
       "      <td>-0.030732</td>\n",
       "      <td>-0.010940</td>\n",
       "      <td>-0.126216</td>\n",
       "      <td>-0.159515</td>\n",
       "      <td>-0.083252</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>0.230066</td>\n",
       "      <td>-0.048657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012149</td>\n",
       "      <td>-0.100497</td>\n",
       "      <td>-0.033590</td>\n",
       "      <td>-0.113659</td>\n",
       "      <td>-0.128520</td>\n",
       "      <td>0.049028</td>\n",
       "      <td>-0.172694</td>\n",
       "      <td>-0.074595</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>-0.125284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055523</td>\n",
       "      <td>-0.011672</td>\n",
       "      <td>-0.177221</td>\n",
       "      <td>-0.020595</td>\n",
       "      <td>-0.111046</td>\n",
       "      <td>0.211206</td>\n",
       "      <td>0.203578</td>\n",
       "      <td>0.103752</td>\n",
       "      <td>-0.055185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.042877</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>-0.053777</td>\n",
       "      <td>-0.060315</td>\n",
       "      <td>-0.113231</td>\n",
       "      <td>0.025670</td>\n",
       "      <td>-0.042992</td>\n",
       "      <td>-0.027823</td>\n",
       "      <td>0.031745</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062950</td>\n",
       "      <td>0.028914</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>-0.033432</td>\n",
       "      <td>-0.003941</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>4996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-0.110533</td>\n",
       "      <td>0.090996</td>\n",
       "      <td>0.126189</td>\n",
       "      <td>-0.044549</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>-0.038362</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.098096</td>\n",
       "      <td>0.214015</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044811</td>\n",
       "      <td>0.535062</td>\n",
       "      <td>-0.007586</td>\n",
       "      <td>-1.326804</td>\n",
       "      <td>-1.387200</td>\n",
       "      <td>-0.482458</td>\n",
       "      <td>-0.340060</td>\n",
       "      <td>-0.451134</td>\n",
       "      <td>-0.048009</td>\n",
       "      <td>4997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.166486</td>\n",
       "      <td>0.070321</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.022319</td>\n",
       "      <td>-0.027345</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>-0.003661</td>\n",
       "      <td>0.055641</td>\n",
       "      <td>-0.104162</td>\n",
       "      <td>-0.005171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>-0.079840</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.177551</td>\n",
       "      <td>-0.074893</td>\n",
       "      <td>-0.156975</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>-0.082456</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>4998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.052966</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>0.057982</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.082762</td>\n",
       "      <td>-0.037150</td>\n",
       "      <td>0.041298</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.048188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>-0.027867</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>-0.044363</td>\n",
       "      <td>-0.007708</td>\n",
       "      <td>-0.009071</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.049939</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>4999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>-0.019396</td>\n",
       "      <td>-0.001428</td>\n",
       "      <td>-0.053526</td>\n",
       "      <td>0.040077</td>\n",
       "      <td>0.073554</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.043152</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>0.118389</td>\n",
       "      <td>-0.035884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>-0.053323</td>\n",
       "      <td>0.045613</td>\n",
       "      <td>0.070347</td>\n",
       "      <td>0.009716</td>\n",
       "      <td>-0.026420</td>\n",
       "      <td>-0.037480</td>\n",
       "      <td>-0.027611</td>\n",
       "      <td>-0.028148</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10002 rows × 601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pca_0     pca_1     pca_2     pca_3     pca_4     pca_5     pca_6  \\\n",
       "0    -0.021385 -0.012949 -0.015279 -0.011877 -0.025111  0.009895 -0.004037   \n",
       "1     0.000776 -0.021042 -0.005029 -0.016736 -0.010840  0.002814 -0.008290   \n",
       "2     0.052751 -0.054740  0.227633  0.128646  0.051232  0.086255  0.112322   \n",
       "3    -0.002264 -0.053758 -0.065805  0.123830 -0.039335 -0.074199  0.080589   \n",
       "4     0.012149 -0.100497 -0.033590 -0.113659 -0.128520  0.049028 -0.172694   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996 -0.042877 -0.006561 -0.053777 -0.060315 -0.113231  0.025670 -0.042992   \n",
       "4997 -0.110533  0.090996  0.126189 -0.044549  0.112800 -0.046879 -0.038362   \n",
       "4998 -0.166486  0.070321  0.038598 -0.022319 -0.027345  0.090069 -0.003661   \n",
       "4999 -0.052966  0.044866  0.057982  0.035652  0.082762 -0.037150  0.041298   \n",
       "5000 -0.019396 -0.001428 -0.053526  0.040077  0.073554  0.037859  0.043152   \n",
       "\n",
       "         pca_7     pca_8     pca_9  ...   pca_591   pca_592   pca_593  \\\n",
       "0    -0.033308  0.008773 -0.014967  ... -0.021627  0.009855  0.002213   \n",
       "1    -0.016119 -0.025994 -0.004446  ... -0.002577  0.012465 -0.003917   \n",
       "2    -0.093411 -0.011321 -0.141729  ... -0.227377  0.047490 -0.014826   \n",
       "3    -0.034714 -0.094504  0.037295  ...  0.246421 -0.030732 -0.010940   \n",
       "4    -0.074595  0.006177 -0.125284  ... -0.055523 -0.011672 -0.177221   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4996 -0.027823  0.031745  0.033578  ... -0.062950  0.028914  0.007278   \n",
       "4997 -0.013591 -0.098096  0.214015  ... -1.044811  0.535062 -0.007586   \n",
       "4998  0.055641 -0.104162 -0.005171  ...  0.005387 -0.079840  0.028089   \n",
       "4999 -0.040216 -0.000206 -0.048188  ...  0.010496 -0.027867  0.025754   \n",
       "5000 -0.070610  0.118389 -0.035884  ...  0.016385 -0.053323  0.045613   \n",
       "\n",
       "       pca_594   pca_595   pca_596   pca_597   pca_598   pca_599     600  \n",
       "0    -0.011496 -0.020011  0.005312 -0.015379 -0.011613 -0.010847     NaN  \n",
       "1    -0.002894 -0.017801 -0.007558 -0.012204  0.038600 -0.011025     NaN  \n",
       "2     0.002115  0.098491 -0.055566 -0.131283  0.103348  0.003722     NaN  \n",
       "3    -0.126216 -0.159515 -0.083252 -0.060753  0.230066 -0.048657     NaN  \n",
       "4    -0.020595 -0.111046  0.211206  0.203578  0.103752 -0.055185     NaN  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "4996  0.021489  0.004603  0.027164 -0.033432 -0.003941  0.004596  4996.0  \n",
       "4997 -1.326804 -1.387200 -0.482458 -0.340060 -0.451134 -0.048009  4997.0  \n",
       "4998  0.177551 -0.074893 -0.156975  0.098310 -0.082456  0.011474  4998.0  \n",
       "4999 -0.044363 -0.007708 -0.009071 -0.006900 -0.049939 -0.021732  4999.0  \n",
       "5000  0.070347  0.009716 -0.026420 -0.037480 -0.027611 -0.028148  5000.0  \n",
       "\n",
       "[10002 rows x 601 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.concat([target,conc])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7291b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77935</th>\n",
       "      <th>77936</th>\n",
       "      <th>77937</th>\n",
       "      <th>77938</th>\n",
       "      <th>77939</th>\n",
       "      <th>77940</th>\n",
       "      <th>77941</th>\n",
       "      <th>77942</th>\n",
       "      <th>77943</th>\n",
       "      <th>77944</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 77945 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     0.000423  0.000553  0.000500  0.000566  0.000752  0.000760  0.000855   \n",
       "1    -0.000100 -0.000145 -0.000186 -0.000238 -0.000275 -0.000248 -0.000214   \n",
       "2     0.000460  0.000337  0.000303  0.000248  0.000204  0.000128  0.000128   \n",
       "3     0.000201  0.000201  0.000224  0.000241  0.000198  0.000195  0.000192   \n",
       "4    -0.000299 -0.000234 -0.000123 -0.000112 -0.000104 -0.000040 -0.000040   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996  0.000137  0.000112  0.000116  0.000135  0.000088  0.000112  0.000137   \n",
       "4997  0.000651  0.000745  0.000604  0.000517  0.000686  0.000604  0.000482   \n",
       "4998 -0.000053 -0.000054 -0.000100 -0.000058 -0.000053 -0.000078 -0.000087   \n",
       "4999 -0.000152 -0.000227 -0.000155 -0.000315 -0.000378 -0.000398 -0.000529   \n",
       "5000  0.000137  0.000128  0.000150  0.000238  0.000130  0.000132  0.000110   \n",
       "\n",
       "         7         8         9      ...  77935  77936  77937  77938  77939  \\\n",
       "0     0.000923  0.000783  0.001147  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1    -0.000177 -0.000121 -0.000070  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2     0.000116  0.000075  0.000128  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3     0.000160  0.000169  0.000092  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4    -0.000032 -0.000013 -0.000009  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "4996  0.000163  0.000208  0.000189  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4997  0.000449  0.000267  0.000307  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4998 -0.000125 -0.000078 -0.000112  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4999 -0.000591 -0.000715 -0.000806  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5000  0.000108  0.000145  0.000211  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      77940  77941  77942  77943  77944  \n",
       "0       0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...  \n",
       "4996    0.0    0.0    0.0    0.0    0.0  \n",
       "4997    0.0    0.0    0.0    0.0    0.0  \n",
       "4998    0.0    0.0    0.0    0.0    0.0  \n",
       "4999    0.0    0.0    0.0    0.0    0.0  \n",
       "5000    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5001 rows x 77945 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = pd.DataFrame(train_x)\n",
    "tp.fillna(0,inplace=True)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ec09ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_0</th>\n",
       "      <th>mel_1</th>\n",
       "      <th>mel_2</th>\n",
       "      <th>mel_3</th>\n",
       "      <th>mel_4</th>\n",
       "      <th>mel_5</th>\n",
       "      <th>mel_6</th>\n",
       "      <th>mel_7</th>\n",
       "      <th>mel_8</th>\n",
       "      <th>mel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_118</th>\n",
       "      <th>mfcc_119</th>\n",
       "      <th>mfcc_120</th>\n",
       "      <th>mfcc_121</th>\n",
       "      <th>mfcc_122</th>\n",
       "      <th>mfcc_123</th>\n",
       "      <th>mfcc_124</th>\n",
       "      <th>mfcc_125</th>\n",
       "      <th>mfcc_126</th>\n",
       "      <th>mfcc_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012796</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060094</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>-0.229225</td>\n",
       "      <td>-0.269986</td>\n",
       "      <td>-0.328177</td>\n",
       "      <td>-0.262188</td>\n",
       "      <td>-0.136601</td>\n",
       "      <td>-0.070472</td>\n",
       "      <td>-0.207806</td>\n",
       "      <td>-0.110601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>0.030566</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.014943</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247597</td>\n",
       "      <td>-0.042381</td>\n",
       "      <td>-0.238468</td>\n",
       "      <td>0.056018</td>\n",
       "      <td>-0.331646</td>\n",
       "      <td>-0.205095</td>\n",
       "      <td>0.070585</td>\n",
       "      <td>0.259338</td>\n",
       "      <td>-0.146463</td>\n",
       "      <td>-0.073543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914811</td>\n",
       "      <td>0.673310</td>\n",
       "      <td>0.495818</td>\n",
       "      <td>0.474627</td>\n",
       "      <td>0.397485</td>\n",
       "      <td>0.323601</td>\n",
       "      <td>0.368434</td>\n",
       "      <td>0.452021</td>\n",
       "      <td>0.424618</td>\n",
       "      <td>0.403028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388673</td>\n",
       "      <td>-0.307896</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>-0.229335</td>\n",
       "      <td>-0.279900</td>\n",
       "      <td>-0.205933</td>\n",
       "      <td>-0.085337</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>-0.005942</td>\n",
       "      <td>-0.396504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.934052</td>\n",
       "      <td>0.717046</td>\n",
       "      <td>0.531865</td>\n",
       "      <td>0.535355</td>\n",
       "      <td>0.562599</td>\n",
       "      <td>0.445513</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.334588</td>\n",
       "      <td>0.363534</td>\n",
       "      <td>0.333056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318791</td>\n",
       "      <td>0.462187</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>-0.073279</td>\n",
       "      <td>-0.178724</td>\n",
       "      <td>-0.249766</td>\n",
       "      <td>-0.479437</td>\n",
       "      <td>-0.163453</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.186423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.668504</td>\n",
       "      <td>4.186213</td>\n",
       "      <td>2.524818</td>\n",
       "      <td>2.119392</td>\n",
       "      <td>3.103342</td>\n",
       "      <td>3.642209</td>\n",
       "      <td>3.444093</td>\n",
       "      <td>3.635113</td>\n",
       "      <td>4.294995</td>\n",
       "      <td>4.536525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165995</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>-0.274354</td>\n",
       "      <td>-0.182354</td>\n",
       "      <td>0.279230</td>\n",
       "      <td>0.096126</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.071157</td>\n",
       "      <td>-0.057014</td>\n",
       "      <td>-0.173333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.111645</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.051493</td>\n",
       "      <td>0.041220</td>\n",
       "      <td>0.047255</td>\n",
       "      <td>0.058171</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0.071075</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109059</td>\n",
       "      <td>0.138545</td>\n",
       "      <td>0.248872</td>\n",
       "      <td>-0.028358</td>\n",
       "      <td>-0.062060</td>\n",
       "      <td>-0.209703</td>\n",
       "      <td>-0.077951</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>-0.069983</td>\n",
       "      <td>-0.212266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>188.221848</td>\n",
       "      <td>130.635345</td>\n",
       "      <td>87.615967</td>\n",
       "      <td>78.403038</td>\n",
       "      <td>68.234230</td>\n",
       "      <td>58.615822</td>\n",
       "      <td>44.839027</td>\n",
       "      <td>37.347416</td>\n",
       "      <td>29.456903</td>\n",
       "      <td>31.133081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098748</td>\n",
       "      <td>-0.187932</td>\n",
       "      <td>0.291289</td>\n",
       "      <td>-0.049687</td>\n",
       "      <td>-0.140961</td>\n",
       "      <td>-0.032705</td>\n",
       "      <td>0.198065</td>\n",
       "      <td>0.154536</td>\n",
       "      <td>-0.160352</td>\n",
       "      <td>-0.067534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.201011</td>\n",
       "      <td>0.239809</td>\n",
       "      <td>0.296275</td>\n",
       "      <td>0.243934</td>\n",
       "      <td>0.187679</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.203905</td>\n",
       "      <td>0.150936</td>\n",
       "      <td>0.112104</td>\n",
       "      <td>0.119830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150995</td>\n",
       "      <td>0.338122</td>\n",
       "      <td>0.237909</td>\n",
       "      <td>-0.166271</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>-0.093311</td>\n",
       "      <td>0.052778</td>\n",
       "      <td>-0.023698</td>\n",
       "      <td>-0.429928</td>\n",
       "      <td>-0.333629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.030886</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.027360</td>\n",
       "      <td>0.019477</td>\n",
       "      <td>0.019061</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>-0.051417</td>\n",
       "      <td>-0.153954</td>\n",
       "      <td>-0.746408</td>\n",
       "      <td>-0.587373</td>\n",
       "      <td>-0.364398</td>\n",
       "      <td>-0.215958</td>\n",
       "      <td>-0.213623</td>\n",
       "      <td>-0.093826</td>\n",
       "      <td>-0.284880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.314438</td>\n",
       "      <td>0.219916</td>\n",
       "      <td>0.151942</td>\n",
       "      <td>0.133253</td>\n",
       "      <td>0.152520</td>\n",
       "      <td>0.164869</td>\n",
       "      <td>0.122870</td>\n",
       "      <td>0.112791</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106392</td>\n",
       "      <td>0.157691</td>\n",
       "      <td>-0.121411</td>\n",
       "      <td>-0.260269</td>\n",
       "      <td>-0.063502</td>\n",
       "      <td>-0.065124</td>\n",
       "      <td>-0.184772</td>\n",
       "      <td>-0.095995</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.022630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mel_0       mel_1      mel_2      mel_3      mel_4      mel_5  \\\n",
       "0       0.012796    0.017139   0.013971   0.011996   0.010280   0.010591   \n",
       "1       0.018538    0.027314   0.030566   0.019357   0.018290   0.017026   \n",
       "2       0.914811    0.673310   0.495818   0.474627   0.397485   0.323601   \n",
       "3       0.934052    0.717046   0.531865   0.535355   0.562599   0.445513   \n",
       "4       5.668504    4.186213   2.524818   2.119392   3.103342   3.642209   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "4996    0.111645    0.093070   0.066315   0.051493   0.041220   0.047255   \n",
       "4997  188.221848  130.635345  87.615967  78.403038  68.234230  58.615822   \n",
       "4998    0.201011    0.239809   0.296275   0.243934   0.187679   0.167938   \n",
       "4999    0.030886    0.031448   0.032928   0.027360   0.019477   0.019061   \n",
       "5000    0.314438    0.219916   0.151942   0.133253   0.152520   0.164869   \n",
       "\n",
       "          mel_6      mel_7      mel_8      mel_9  ...  mfcc_118  mfcc_119  \\\n",
       "0      0.010656   0.009577   0.012072   0.011043  ... -0.060094  0.018266   \n",
       "1      0.016035   0.014943   0.014594   0.015915  ...  0.247597 -0.042381   \n",
       "2      0.368434   0.452021   0.424618   0.403028  ... -0.388673 -0.307896   \n",
       "3      0.290852   0.334588   0.363534   0.333056  ...  0.318791  0.462187   \n",
       "4      3.444093   3.635113   4.294995   4.536525  ... -0.165995  0.025326   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "4996   0.058171   0.069464   0.071075   0.084309  ...  0.109059  0.138545   \n",
       "4997  44.839027  37.347416  29.456903  31.133081  ... -0.098748 -0.187932   \n",
       "4998   0.203905   0.150936   0.112104   0.119830  ...  0.150995  0.338122   \n",
       "4999   0.025755   0.027535   0.021783   0.021801  ...  0.052324 -0.051417   \n",
       "5000   0.122870   0.112791   0.130098   0.149188  ... -0.106392  0.157691   \n",
       "\n",
       "      mfcc_120  mfcc_121  mfcc_122  mfcc_123  mfcc_124  mfcc_125  mfcc_126  \\\n",
       "0    -0.229225 -0.269986 -0.328177 -0.262188 -0.136601 -0.070472 -0.207806   \n",
       "1    -0.238468  0.056018 -0.331646 -0.205095  0.070585  0.259338 -0.146463   \n",
       "2     0.075124 -0.229335 -0.279900 -0.205933 -0.085337  0.012471 -0.005942   \n",
       "3     0.019130 -0.073279 -0.178724 -0.249766 -0.479437 -0.163453 -0.003095   \n",
       "4    -0.274354 -0.182354  0.279230  0.096126 -0.148470 -0.071157 -0.057014   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996  0.248872 -0.028358 -0.062060 -0.209703 -0.077951  0.011387 -0.069983   \n",
       "4997  0.291289 -0.049687 -0.140961 -0.032705  0.198065  0.154536 -0.160352   \n",
       "4998  0.237909 -0.166271  0.063727 -0.093311  0.052778 -0.023698 -0.429928   \n",
       "4999 -0.153954 -0.746408 -0.587373 -0.364398 -0.215958 -0.213623 -0.093826   \n",
       "5000 -0.121411 -0.260269 -0.063502 -0.065124 -0.184772 -0.095995  0.001943   \n",
       "\n",
       "      mfcc_127  \n",
       "0    -0.110601  \n",
       "1    -0.073543  \n",
       "2    -0.396504  \n",
       "3    -0.186423  \n",
       "4    -0.173333  \n",
       "...        ...  \n",
       "4996 -0.212266  \n",
       "4997 -0.067534  \n",
       "4998 -0.333629  \n",
       "4999 -0.284880  \n",
       "5000  0.022630  \n",
       "\n",
       "[5001 rows x 512 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = pd.DataFrame(vector,columns=[f'mfcc_{i}' for i in range(128)])\n",
    "train = pd.DataFrame(train_mel,columns=[f'mel_{i}' for i in range(512-128)])\n",
    "train = train.rename(columns={f'{i}':f'mel_{i}' for i in range(128)})\n",
    "train = pd.concat([train,vector],axis=1)\n",
    "# train = pd.concat([train,tp],axis=1)\n",
    "# del(tp)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868db62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b57fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02bfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        #layers.MaxPooling1D(),\n",
    "        layers.Dense(1024, activation='relu', input_shape=[len(train.keys())]),\n",
    "        # layers.Dense(1024, activation='relu'),\n",
    "        # layers.MaxPooling1D(),\n",
    "        # layers.Dense(512, activation='relu'),\n",
    "        # layers.Dropout(0.1),\n",
    "        layers.Dense(6,activation='softmax')\n",
    "        ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3a8ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 531,462\n",
      "Trainable params: 531,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6964f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "383d4efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.6233 - val_loss: 0.8814 - val_accuracy: 0.6643\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9295 - accuracy: 0.6515 - val_loss: 0.8769 - val_accuracy: 0.6733\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8903 - accuracy: 0.6492 - val_loss: 0.8606 - val_accuracy: 0.6613\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.9144 - accuracy: 0.6622 - val_loss: 0.9010 - val_accuracy: 0.6593\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8579 - accuracy: 0.6710 - val_loss: 0.9594 - val_accuracy: 0.6434\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8685 - accuracy: 0.6870 - val_loss: 1.0358 - val_accuracy: 0.6264\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8414 - accuracy: 0.6855 - val_loss: 0.9958 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.7055 - val_loss: 0.9454 - val_accuracy: 0.6454\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.7258 - val_loss: 0.9799 - val_accuracy: 0.6304\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7311 - accuracy: 0.7235 - val_loss: 0.9394 - val_accuracy: 0.6533\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8740 - accuracy: 0.7035 - val_loss: 1.0212 - val_accuracy: 0.6264\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.7160 - val_loss: 1.0025 - val_accuracy: 0.6523\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8226 - accuracy: 0.7075 - val_loss: 1.1204 - val_accuracy: 0.6294\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7448 - accuracy: 0.7320 - val_loss: 1.1444 - val_accuracy: 0.6244\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.7467 - val_loss: 1.0648 - val_accuracy: 0.6234\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.7383 - val_loss: 1.2759 - val_accuracy: 0.6054\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.7347 - val_loss: 1.1899 - val_accuracy: 0.6034\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.7383 - val_loss: 1.2380 - val_accuracy: 0.5864\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.7508 - val_loss: 1.1729 - val_accuracy: 0.6024\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.7573 - val_loss: 1.3047 - val_accuracy: 0.5604\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7735 - val_loss: 1.1785 - val_accuracy: 0.6004\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.8005 - val_loss: 1.1729 - val_accuracy: 0.5824\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7937 - val_loss: 1.2883 - val_accuracy: 0.6094\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7968 - val_loss: 1.2070 - val_accuracy: 0.5994\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8130 - val_loss: 1.2404 - val_accuracy: 0.6194\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8170 - val_loss: 1.3190 - val_accuracy: 0.5934\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7997 - val_loss: 1.6354 - val_accuracy: 0.5864\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7910 - val_loss: 1.4208 - val_accuracy: 0.6014\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8073 - val_loss: 1.3167 - val_accuracy: 0.6084\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8380 - val_loss: 1.4341 - val_accuracy: 0.5944\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8330 - val_loss: 1.9550 - val_accuracy: 0.5465\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.8092 - val_loss: 1.4292 - val_accuracy: 0.5754\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8285 - val_loss: 1.4627 - val_accuracy: 0.5974\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8533 - val_loss: 1.5773 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8317 - val_loss: 1.5238 - val_accuracy: 0.5804\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8388 - val_loss: 1.5506 - val_accuracy: 0.5804\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.8188 - val_loss: 1.5591 - val_accuracy: 0.5834\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8410 - val_loss: 1.6199 - val_accuracy: 0.5984\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8755 - val_loss: 1.7462 - val_accuracy: 0.5564\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8745 - val_loss: 1.8151 - val_accuracy: 0.5954\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8585 - val_loss: 1.9496 - val_accuracy: 0.5644\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8960 - val_loss: 1.5471 - val_accuracy: 0.5884\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8842 - val_loss: 1.7618 - val_accuracy: 0.5634\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8800 - val_loss: 1.7441 - val_accuracy: 0.5644\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8710 - val_loss: 1.7473 - val_accuracy: 0.5594\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8932 - val_loss: 1.7116 - val_accuracy: 0.5814\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8827 - val_loss: 1.6976 - val_accuracy: 0.5624\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.9057 - val_loss: 1.8233 - val_accuracy: 0.5684\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9225 - val_loss: 1.8139 - val_accuracy: 0.5904\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9205 - val_loss: 1.8212 - val_accuracy: 0.5744\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9153 - val_loss: 2.0290 - val_accuracy: 0.5664\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9175 - val_loss: 2.0344 - val_accuracy: 0.5744\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9180 - val_loss: 2.2139 - val_accuracy: 0.5445\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9210 - val_loss: 1.9794 - val_accuracy: 0.5584\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.9193 - val_loss: 2.1583 - val_accuracy: 0.5634\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9208 - val_loss: 2.4552 - val_accuracy: 0.5544\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9273 - val_loss: 1.9326 - val_accuracy: 0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9433 - val_loss: 2.2415 - val_accuracy: 0.5604\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9435 - val_loss: 2.2537 - val_accuracy: 0.5504\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.9305 - val_loss: 3.2180 - val_accuracy: 0.5435\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8907 - val_loss: 2.4102 - val_accuracy: 0.5684\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.9000 - val_loss: 2.9833 - val_accuracy: 0.5245\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8800 - val_loss: 2.4984 - val_accuracy: 0.5395\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9323 - val_loss: 2.9293 - val_accuracy: 0.5365\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9323 - val_loss: 2.6214 - val_accuracy: 0.5564\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9330 - val_loss: 2.3845 - val_accuracy: 0.5544\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9388 - val_loss: 2.2844 - val_accuracy: 0.5435\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9333 - val_loss: 3.0211 - val_accuracy: 0.5624\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.9258 - val_loss: 2.3365 - val_accuracy: 0.5485\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9305 - val_loss: 2.5666 - val_accuracy: 0.5554\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9417 - val_loss: 2.5380 - val_accuracy: 0.5694\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9430 - val_loss: 2.5920 - val_accuracy: 0.5215\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9622 - val_loss: 2.5229 - val_accuracy: 0.5594\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.9300 - val_loss: 2.4409 - val_accuracy: 0.5504\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9240 - val_loss: 2.5112 - val_accuracy: 0.5375\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9452 - val_loss: 3.0805 - val_accuracy: 0.5574\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.9205 - val_loss: 2.6792 - val_accuracy: 0.5425\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9262 - val_loss: 3.1168 - val_accuracy: 0.5425\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9308 - val_loss: 2.6456 - val_accuracy: 0.5504\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9560 - val_loss: 2.7577 - val_accuracy: 0.5514\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9760 - val_loss: 3.2301 - val_accuracy: 0.5564\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 2.9674 - val_accuracy: 0.5634\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9860 - val_loss: 2.9919 - val_accuracy: 0.5475\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9735 - val_loss: 3.0893 - val_accuracy: 0.5395\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9762 - val_loss: 3.2065 - val_accuracy: 0.5594\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9700 - val_loss: 3.0130 - val_accuracy: 0.5614\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9675 - val_loss: 3.9405 - val_accuracy: 0.5295\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.9218 - val_loss: 2.8912 - val_accuracy: 0.5325\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8885 - val_loss: 3.5584 - val_accuracy: 0.5195\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.9085 - val_loss: 3.8548 - val_accuracy: 0.5435\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9287 - val_loss: 3.3762 - val_accuracy: 0.5095\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9607 - val_loss: 3.0910 - val_accuracy: 0.5644\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9697 - val_loss: 3.0473 - val_accuracy: 0.5514\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9762 - val_loss: 3.1719 - val_accuracy: 0.5485\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9827 - val_loss: 3.4587 - val_accuracy: 0.5445\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9860 - val_loss: 3.5147 - val_accuracy: 0.5594\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9822 - val_loss: 3.6142 - val_accuracy: 0.5395\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9855 - val_loss: 3.7584 - val_accuracy: 0.5355\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9507 - val_loss: 3.7632 - val_accuracy: 0.5245\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.9195 - val_loss: 3.1765 - val_accuracy: 0.5295\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.4695 - accuracy: 0.7006 - val_loss: 1.3690 - val_accuracy: 0.7440\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.7904 - accuracy: 0.7531 - val_loss: 0.5553 - val_accuracy: 0.8220\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.7911 - val_loss: 0.5218 - val_accuracy: 0.8060\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.7961 - val_loss: 0.4879 - val_accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8338 - val_loss: 0.4288 - val_accuracy: 0.8640\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.8475 - val_loss: 0.4609 - val_accuracy: 0.8360\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8500 - val_loss: 0.5154 - val_accuracy: 0.8190\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.8148 - val_loss: 0.5441 - val_accuracy: 0.8190\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.8475 - val_loss: 0.4974 - val_accuracy: 0.8490\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8503 - val_loss: 0.4793 - val_accuracy: 0.8490\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8815 - val_loss: 0.3192 - val_accuracy: 0.8860\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8873 - val_loss: 0.4658 - val_accuracy: 0.8590\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8933 - val_loss: 0.4650 - val_accuracy: 0.8540\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.9088 - val_loss: 0.6188 - val_accuracy: 0.8110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8558 - val_loss: 0.4790 - val_accuracy: 0.8590\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9145 - val_loss: 0.4656 - val_accuracy: 0.8300\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8818 - val_loss: 0.6532 - val_accuracy: 0.8080\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9135 - val_loss: 0.4200 - val_accuracy: 0.8790\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9283 - val_loss: 0.4303 - val_accuracy: 0.8610\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9443 - val_loss: 0.4952 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9513 - val_loss: 0.3996 - val_accuracy: 0.8830\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9548 - val_loss: 0.4599 - val_accuracy: 0.8570\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9423 - val_loss: 0.5127 - val_accuracy: 0.8290\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9280 - val_loss: 0.5042 - val_accuracy: 0.8380\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9230 - val_loss: 0.6962 - val_accuracy: 0.8060\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9245 - val_loss: 0.5340 - val_accuracy: 0.8520\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9318 - val_loss: 0.7565 - val_accuracy: 0.8010\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.9183 - val_loss: 0.5802 - val_accuracy: 0.8260\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9430 - val_loss: 0.4842 - val_accuracy: 0.8410\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9485 - val_loss: 0.5325 - val_accuracy: 0.8470\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9533 - val_loss: 0.5028 - val_accuracy: 0.8280\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.9053 - val_loss: 0.6176 - val_accuracy: 0.8250\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9318 - val_loss: 0.6558 - val_accuracy: 0.8230\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9438 - val_loss: 0.5208 - val_accuracy: 0.8360\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9530 - val_loss: 0.5133 - val_accuracy: 0.8390\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9605 - val_loss: 0.5748 - val_accuracy: 0.8190\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9685 - val_loss: 0.5397 - val_accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9653 - val_loss: 0.5715 - val_accuracy: 0.8240\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9615 - val_loss: 0.7739 - val_accuracy: 0.8150\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9545 - val_loss: 0.6355 - val_accuracy: 0.8030\n",
      "Epoch 41/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9653 - val_loss: 0.5662 - val_accuracy: 0.8210\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9740 - val_loss: 0.5362 - val_accuracy: 0.8420\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9710 - val_loss: 0.5900 - val_accuracy: 0.8320\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9728 - val_loss: 0.7210 - val_accuracy: 0.7980\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9440 - val_loss: 1.0030 - val_accuracy: 0.7780\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.9133 - val_loss: 0.9053 - val_accuracy: 0.7620\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8915 - val_loss: 0.9792 - val_accuracy: 0.7400\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9388 - val_loss: 0.6349 - val_accuracy: 0.8020\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9455 - val_loss: 0.7251 - val_accuracy: 0.7910\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9603 - val_loss: 0.6489 - val_accuracy: 0.8010\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9628 - val_loss: 0.8221 - val_accuracy: 0.7870\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9663 - val_loss: 0.7619 - val_accuracy: 0.7860\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9610 - val_loss: 0.7453 - val_accuracy: 0.7830\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9628 - val_loss: 0.6884 - val_accuracy: 0.7880\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9830 - val_loss: 0.6800 - val_accuracy: 0.8020\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9743 - val_loss: 0.9087 - val_accuracy: 0.7600\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9125 - val_loss: 0.9606 - val_accuracy: 0.7840\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.9358 - val_loss: 0.8751 - val_accuracy: 0.7630\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9660 - val_loss: 0.7932 - val_accuracy: 0.7670\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9673 - val_loss: 0.7945 - val_accuracy: 0.7920\n",
      "Epoch 61/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9758 - val_loss: 0.8278 - val_accuracy: 0.7790\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9598 - val_loss: 0.9720 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9690 - val_loss: 0.8270 - val_accuracy: 0.7810\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9868 - val_loss: 0.8394 - val_accuracy: 0.7760\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9895 - val_loss: 0.8223 - val_accuracy: 0.7860\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 0.9102 - val_accuracy: 0.8040\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.7720 - val_accuracy: 0.8040\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.8292 - val_accuracy: 0.8010\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9905 - val_loss: 0.8366 - val_accuracy: 0.8030\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9868 - val_loss: 0.8343 - val_accuracy: 0.7870\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9560 - val_loss: 1.7879 - val_accuracy: 0.6580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.8385 - val_loss: 1.9439 - val_accuracy: 0.6960\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8790 - val_loss: 1.2243 - val_accuracy: 0.7290\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9483 - val_loss: 0.9292 - val_accuracy: 0.7820\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9663 - val_loss: 1.0620 - val_accuracy: 0.7620\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9733 - val_loss: 0.9004 - val_accuracy: 0.7830\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9850 - val_loss: 0.9133 - val_accuracy: 0.7860\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.8836 - val_accuracy: 0.7930\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.9580 - val_accuracy: 0.7790\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9838 - val_loss: 0.9505 - val_accuracy: 0.7700\n",
      "Epoch 81/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9633 - val_loss: 0.9972 - val_accuracy: 0.7610\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9625 - val_loss: 1.0545 - val_accuracy: 0.7560\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9265 - val_loss: 1.2381 - val_accuracy: 0.7210\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9525 - val_loss: 1.1331 - val_accuracy: 0.7400\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9695 - val_loss: 0.9253 - val_accuracy: 0.7690\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.9143 - val_accuracy: 0.7750\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.9067 - val_accuracy: 0.7720\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.9649 - val_accuracy: 0.7780\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9955 - val_loss: 0.8919 - val_accuracy: 0.7810\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 0.9630 - val_accuracy: 0.7810\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.9327 - val_accuracy: 0.7880\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 1.0198 - val_accuracy: 0.7720\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9908 - val_loss: 1.1862 - val_accuracy: 0.7790\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9915 - val_loss: 1.0648 - val_accuracy: 0.7770\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9800 - val_loss: 1.0828 - val_accuracy: 0.7550\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.8423 - val_loss: 1.4562 - val_accuracy: 0.6810\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.8298 - val_loss: 1.5333 - val_accuracy: 0.6880\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8893 - val_loss: 1.4413 - val_accuracy: 0.6920\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9480 - val_loss: 1.2112 - val_accuracy: 0.7260\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.9550 - val_loss: 1.7736 - val_accuracy: 0.7190\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.8480 - val_loss: 0.3438 - val_accuracy: 0.8850\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.8510 - val_loss: 0.3666 - val_accuracy: 0.8660\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8860 - val_loss: 0.2599 - val_accuracy: 0.8960\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.8620 - val_loss: 0.3927 - val_accuracy: 0.9030\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8858 - val_loss: 0.3184 - val_accuracy: 0.9050\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9135 - val_loss: 0.2654 - val_accuracy: 0.9240\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9200 - val_loss: 0.2235 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9290 - val_loss: 0.2098 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9380 - val_loss: 0.2380 - val_accuracy: 0.9290\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9408 - val_loss: 0.2248 - val_accuracy: 0.9340\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9445 - val_loss: 0.1969 - val_accuracy: 0.9430\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9413 - val_loss: 0.2721 - val_accuracy: 0.9290\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9483 - val_loss: 0.3773 - val_accuracy: 0.9260\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9460 - val_loss: 0.2089 - val_accuracy: 0.9480\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9600 - val_loss: 0.2158 - val_accuracy: 0.9250\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9523 - val_loss: 0.2432 - val_accuracy: 0.9440\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9658 - val_loss: 0.2174 - val_accuracy: 0.9530\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9543 - val_loss: 0.2699 - val_accuracy: 0.9400\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9458 - val_loss: 0.3427 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9435 - val_loss: 0.4345 - val_accuracy: 0.9160\n",
      "Epoch 21/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9433 - val_loss: 0.3520 - val_accuracy: 0.9190\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.9053 - val_loss: 0.4542 - val_accuracy: 0.8920\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9408 - val_loss: 0.3267 - val_accuracy: 0.9180\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9560 - val_loss: 0.1809 - val_accuracy: 0.9410\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9685 - val_loss: 0.2611 - val_accuracy: 0.9370\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9600 - val_loss: 0.3395 - val_accuracy: 0.9390\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9703 - val_loss: 0.2169 - val_accuracy: 0.9490\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9750 - val_loss: 0.1722 - val_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9755 - val_loss: 0.1680 - val_accuracy: 0.9470\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9748 - val_loss: 0.2280 - val_accuracy: 0.9360\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9593 - val_loss: 0.3883 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9303 - val_loss: 0.4072 - val_accuracy: 0.8720\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9220 - val_loss: 0.4873 - val_accuracy: 0.8650\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9440 - val_loss: 2.2399 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.9573 - val_loss: 0.2731 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9603 - val_loss: 0.2900 - val_accuracy: 0.9190\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9678 - val_loss: 0.2713 - val_accuracy: 0.9330\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 0.2172 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9760 - val_loss: 0.1912 - val_accuracy: 0.9340\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9785 - val_loss: 0.1942 - val_accuracy: 0.9410\n",
      "Epoch 41/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9613 - val_loss: 0.3110 - val_accuracy: 0.9120\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9368 - val_loss: 0.4293 - val_accuracy: 0.8890\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.9053 - val_loss: 0.4516 - val_accuracy: 0.8580\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.9120 - val_loss: 0.6021 - val_accuracy: 0.8470\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8770 - val_loss: 0.4706 - val_accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.9250 - val_loss: 0.3952 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9395 - val_loss: 0.4150 - val_accuracy: 0.8730\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9563 - val_loss: 0.4242 - val_accuracy: 0.8920\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9593 - val_loss: 0.3848 - val_accuracy: 0.8820\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9468 - val_loss: 0.4771 - val_accuracy: 0.8790\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9685 - val_loss: 0.3667 - val_accuracy: 0.8960\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9760 - val_loss: 0.3174 - val_accuracy: 0.9090\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9733 - val_loss: 0.6045 - val_accuracy: 0.8960\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9710 - val_loss: 0.3269 - val_accuracy: 0.9070\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9720 - val_loss: 0.2803 - val_accuracy: 0.9150\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9713 - val_loss: 0.3544 - val_accuracy: 0.9070\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9705 - val_loss: 0.3171 - val_accuracy: 0.9150\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9698 - val_loss: 0.3818 - val_accuracy: 0.9050\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9738 - val_loss: 0.3916 - val_accuracy: 0.8880\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9583 - val_loss: 1.1574 - val_accuracy: 0.7990\n",
      "Epoch 61/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8870 - val_loss: 0.6080 - val_accuracy: 0.8370\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9455 - val_loss: 0.6693 - val_accuracy: 0.8710\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9603 - val_loss: 0.5685 - val_accuracy: 0.8650\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9758 - val_loss: 0.3732 - val_accuracy: 0.9110\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.3829 - val_accuracy: 0.9090\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.3117 - val_accuracy: 0.9140\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.4870 - val_accuracy: 0.9060\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.4489 - val_accuracy: 0.8920\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9845 - val_loss: 0.3933 - val_accuracy: 0.8970\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 0.4523 - val_accuracy: 0.9040\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9888 - val_loss: 0.4245 - val_accuracy: 0.9220\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.3959 - val_accuracy: 0.9160\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.4244 - val_accuracy: 0.9160\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 0.5452 - val_accuracy: 0.9130\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.4079 - val_accuracy: 0.8970\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9715 - val_loss: 0.9896 - val_accuracy: 0.8250\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8608 - val_loss: 0.9223 - val_accuracy: 0.7920\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9280 - val_loss: 0.6934 - val_accuracy: 0.8370\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9663 - val_loss: 0.6352 - val_accuracy: 0.8460\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9750 - val_loss: 0.5802 - val_accuracy: 0.8760\n",
      "Epoch 81/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9788 - val_loss: 0.4558 - val_accuracy: 0.8850\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.4314 - val_accuracy: 0.8860\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9923 - val_loss: 0.5215 - val_accuracy: 0.8680\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.4361 - val_accuracy: 0.8840\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.4973 - val_accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.4786 - val_accuracy: 0.8920\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.5295 - val_accuracy: 0.8880\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.4273 - val_accuracy: 0.8810\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9800 - val_loss: 0.6928 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9830 - val_loss: 0.8053 - val_accuracy: 0.8800\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9613 - val_loss: 1.1959 - val_accuracy: 0.8230\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8173 - accuracy: 0.8275 - val_loss: 1.3652 - val_accuracy: 0.7100\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.8855 - val_loss: 1.0343 - val_accuracy: 0.7920\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9498 - val_loss: 0.9064 - val_accuracy: 0.8050\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 0.6556 - val_accuracy: 0.8490\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 0.7288 - val_accuracy: 0.8440\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.5894 - val_accuracy: 0.8560\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.6159 - val_accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.6150 - val_accuracy: 0.8620\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.6993 - val_accuracy: 0.8540\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8798 - val_loss: 0.3879 - val_accuracy: 0.8930\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8990 - val_loss: 0.2641 - val_accuracy: 0.9470\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9353 - val_loss: 0.1868 - val_accuracy: 0.9460\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9538 - val_loss: 0.1215 - val_accuracy: 0.9660\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.9315 - val_loss: 0.1799 - val_accuracy: 0.9630\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9608 - val_loss: 0.1404 - val_accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9755 - val_loss: 0.1063 - val_accuracy: 0.9730\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0813 - val_accuracy: 0.9830\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9853 - val_loss: 0.0890 - val_accuracy: 0.9770\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9853 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.0730 - val_accuracy: 0.9810\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9850 - val_loss: 0.0600 - val_accuracy: 0.9830\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.0648 - val_accuracy: 0.9850\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9868 - val_loss: 0.0530 - val_accuracy: 0.9870\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.1232 - val_accuracy: 0.9730\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9868 - val_loss: 0.1785 - val_accuracy: 0.9650\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9700 - val_loss: 0.1659 - val_accuracy: 0.9640\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9580 - val_loss: 0.9079 - val_accuracy: 0.8400\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.8705 - val_loss: 0.5461 - val_accuracy: 0.8620\n",
      "Epoch 21/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.9248 - val_loss: 0.3249 - val_accuracy: 0.9240\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9533 - val_loss: 0.2392 - val_accuracy: 0.9530\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9770 - val_loss: 0.2742 - val_accuracy: 0.9530\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9805 - val_loss: 0.1678 - val_accuracy: 0.9650\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9808 - val_loss: 0.1993 - val_accuracy: 0.9680\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9865 - val_loss: 0.3476 - val_accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9823 - val_loss: 0.2856 - val_accuracy: 0.9510\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9783 - val_loss: 0.2063 - val_accuracy: 0.9650\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9828 - val_loss: 0.2182 - val_accuracy: 0.9650\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9815 - val_loss: 0.1597 - val_accuracy: 0.9690\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 0.1631 - val_accuracy: 0.9740\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9895 - val_loss: 0.1535 - val_accuracy: 0.9710\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9850 - val_loss: 0.1409 - val_accuracy: 0.9680\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.1486 - val_accuracy: 0.9740\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.1656 - val_accuracy: 0.9770\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.1810 - val_accuracy: 0.9720\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.1975 - val_accuracy: 0.9730\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.1792 - val_accuracy: 0.9720\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.1929 - val_accuracy: 0.9720\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.1759 - val_accuracy: 0.9730\n",
      "Epoch 41/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.1679 - val_accuracy: 0.9770\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.1818 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.1681 - val_accuracy: 0.9700\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9893 - val_loss: 0.3255 - val_accuracy: 0.9530\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.8393 - val_loss: 0.9191 - val_accuracy: 0.7610\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.8428 - val_loss: 0.7943 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.9153 - val_loss: 0.4258 - val_accuracy: 0.8890\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8955 - val_loss: 0.6684 - val_accuracy: 0.8450\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9383 - val_loss: 0.3799 - val_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9605 - val_loss: 0.4544 - val_accuracy: 0.8810\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9708 - val_loss: 0.3067 - val_accuracy: 0.9160\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.2855 - val_accuracy: 0.9240\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.2986 - val_accuracy: 0.9200\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.2609 - val_accuracy: 0.9340\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.2713 - val_accuracy: 0.9280\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.6283 - val_accuracy: 0.8900\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9670 - val_loss: 0.4288 - val_accuracy: 0.8960\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9715 - val_loss: 0.4181 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9780 - val_loss: 0.3291 - val_accuracy: 0.9130\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9873 - val_loss: 0.8000 - val_accuracy: 0.9120\n",
      "Epoch 61/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9625 - val_loss: 0.6415 - val_accuracy: 0.9090\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9745 - val_loss: 0.5446 - val_accuracy: 0.9070\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9683 - val_loss: 0.4887 - val_accuracy: 0.9010\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9290 - val_loss: 0.7016 - val_accuracy: 0.8570\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9635 - val_loss: 0.5274 - val_accuracy: 0.8980\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.4439 - val_accuracy: 0.8960\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.3848 - val_accuracy: 0.9280\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.4279 - val_accuracy: 0.9280\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.4150 - val_accuracy: 0.9270\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.3542 - val_accuracy: 0.9270\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.3687 - val_accuracy: 0.9340\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.3471 - val_accuracy: 0.9330\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.3397 - val_accuracy: 0.9390\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.3576 - val_accuracy: 0.9350\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.4083 - val_accuracy: 0.9160\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 0.6222 - val_accuracy: 0.8990\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.9318 - val_loss: 1.0722 - val_accuracy: 0.7580\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8975 - val_loss: 0.8808 - val_accuracy: 0.8520\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9575 - val_loss: 0.5646 - val_accuracy: 0.8820\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9750 - val_loss: 0.5367 - val_accuracy: 0.8850\n",
      "Epoch 81/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.4433 - val_accuracy: 0.9050\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9853 - val_loss: 0.5301 - val_accuracy: 0.9100\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.9785 - val_loss: 0.7072 - val_accuracy: 0.9040\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.9785 - val_loss: 0.6266 - val_accuracy: 0.8980\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9855 - val_loss: 0.4186 - val_accuracy: 0.9160\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9533 - val_loss: 0.8464 - val_accuracy: 0.8490\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9610 - val_loss: 0.7384 - val_accuracy: 0.8590\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9748 - val_loss: 0.7527 - val_accuracy: 0.8680\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.5524 - val_accuracy: 0.9020\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.5062 - val_accuracy: 0.9170\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.4547 - val_accuracy: 0.9210\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.4563 - val_accuracy: 0.9200\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.4426 - val_accuracy: 0.9240\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.4351 - val_accuracy: 0.9230\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.4258 - val_accuracy: 0.9150\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.4016 - val_accuracy: 0.9220\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.4231 - val_accuracy: 0.9270\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.3788 - val_accuracy: 0.9280\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.3897 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.3785 - val_accuracy: 0.9230\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.8068 - accuracy: 0.8560 - val_loss: 0.6832 - val_accuracy: 0.8230\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8708 - val_loss: 0.3506 - val_accuracy: 0.8900\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.9253 - val_loss: 0.2785 - val_accuracy: 0.9250\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9585 - val_loss: 0.1224 - val_accuracy: 0.9560\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9585 - val_loss: 0.0940 - val_accuracy: 0.9690\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 0.0443 - val_accuracy: 0.9870\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0463 - val_accuracy: 0.9840\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0385 - val_accuracy: 0.9910\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.0304 - val_accuracy: 0.9920\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0272 - val_accuracy: 0.9930\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9770 - val_loss: 0.1505 - val_accuracy: 0.9640\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9493 - val_loss: 0.2688 - val_accuracy: 0.9240\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.9223 - val_loss: 0.1853 - val_accuracy: 0.9480\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9660 - val_loss: 0.0796 - val_accuracy: 0.9680\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9845 - val_loss: 0.0512 - val_accuracy: 0.9830\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.0405 - val_accuracy: 0.9880\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 0.0366 - val_accuracy: 0.9920\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.0314 - val_accuracy: 0.9900\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9880\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0426 - val_accuracy: 0.9880\n",
      "Epoch 21/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0351 - val_accuracy: 0.9880\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0598 - val_accuracy: 0.9820\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9640 - val_loss: 0.2154 - val_accuracy: 0.9270\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9293 - val_loss: 0.3016 - val_accuracy: 0.9170\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9595 - val_loss: 0.1989 - val_accuracy: 0.9370\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9788 - val_loss: 0.1149 - val_accuracy: 0.9590\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 0.0770 - val_accuracy: 0.9700\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.0703 - val_accuracy: 0.9720\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.1493 - val_accuracy: 0.9720\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9775 - val_loss: 0.4609 - val_accuracy: 0.9520\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9783 - val_loss: 0.0700 - val_accuracy: 0.9790\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.0487 - val_accuracy: 0.9840\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.0495 - val_accuracy: 0.9820\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0469 - val_accuracy: 0.9860\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 0.0475 - val_accuracy: 0.9850\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0512 - val_accuracy: 0.9810\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0458 - val_accuracy: 0.9870\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.0537 - val_accuracy: 0.9830\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0479 - val_accuracy: 0.9840\n",
      "Epoch 41/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0450 - val_accuracy: 0.9890\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0499 - val_accuracy: 0.9880\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.0910 - val_accuracy: 0.9780\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.2626 - val_accuracy: 0.9540\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.8943 - val_loss: 2.6758 - val_accuracy: 0.7240\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.8688 - val_loss: 1.1748 - val_accuracy: 0.8590\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 1.3332 - accuracy: 0.9105 - val_loss: 0.9292 - val_accuracy: 0.9080\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9593 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 0.2146 - val_accuracy: 0.9360\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.1631 - val_accuracy: 0.9510\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9865 - val_loss: 0.1671 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.1617 - val_accuracy: 0.9610\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 0.1717 - val_accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.1370 - val_accuracy: 0.9670\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.1081 - val_accuracy: 0.9710\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.1447 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.1027 - val_accuracy: 0.9710\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.1072 - val_accuracy: 0.9700\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1055 - val_accuracy: 0.9720\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.1070 - val_accuracy: 0.9720\n",
      "Epoch 61/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1071 - val_accuracy: 0.9710\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1047 - val_accuracy: 0.9720\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1036 - val_accuracy: 0.9710\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1043 - val_accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1017 - val_accuracy: 0.9730\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.1030 - val_accuracy: 0.9710\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1078 - val_accuracy: 0.9700\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.1059 - val_accuracy: 0.9730\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.1018 - val_accuracy: 0.9730\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1046 - val_accuracy: 0.9700\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 0.7651 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.8628 - val_loss: 0.5406 - val_accuracy: 0.8420\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9300 - val_loss: 0.2596 - val_accuracy: 0.9280\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9633 - val_loss: 0.2900 - val_accuracy: 0.9200\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9565 - val_loss: 0.3249 - val_accuracy: 0.9240\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9643 - val_loss: 0.3721 - val_accuracy: 0.9220\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9790 - val_loss: 0.2367 - val_accuracy: 0.9340\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9838 - val_loss: 0.2412 - val_accuracy: 0.9440\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9893 - val_loss: 0.2371 - val_accuracy: 0.9480\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.2048 - val_accuracy: 0.9550\n",
      "Epoch 81/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9863 - val_loss: 0.2239 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.2111 - val_accuracy: 0.9540\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.2117 - val_accuracy: 0.9580\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.2086 - val_accuracy: 0.9580\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.2121 - val_accuracy: 0.9580\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.2110 - val_accuracy: 0.9570\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.2146 - val_accuracy: 0.9580\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.2082 - val_accuracy: 0.9570\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.1982 - val_accuracy: 0.9600\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.2024 - val_accuracy: 0.9540\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.2209 - val_accuracy: 0.9530\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9830 - val_loss: 0.4254 - val_accuracy: 0.9030\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.9030 - val_loss: 0.9129 - val_accuracy: 0.8290\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8940 - val_loss: 0.6707 - val_accuracy: 0.8630\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 0.5269 - val_accuracy: 0.8870\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9640 - val_loss: 0.4182 - val_accuracy: 0.9100\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9663 - val_loss: 0.3317 - val_accuracy: 0.9170\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9805 - val_loss: 0.2551 - val_accuracy: 0.9250\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.2687 - val_accuracy: 0.9350\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9860 - val_loss: 0.2291 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "# class PrintDot(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         if epoch % 100 == 0: print('')\n",
    "#         print('.', end='')\n",
    "\n",
    "# EPOCHS = 1000\n",
    "\n",
    "# history = model.fit(\n",
    "#   train, train_df['label'],\n",
    "#   epochs=EPOCHS, validation_split = 0.1, verbose=0,\n",
    "#   callbacks=[PrintDot()])\n",
    "\n",
    "\n",
    "\n",
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "models = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "    model.fit(train.loc[train_index,:]\n",
    "              , train_df.loc[train_index,'label']\n",
    "              , epochs=100\n",
    "              , validation_data=(train.loc[test_index,:],train_df.loc[test_index,'label'])) # validation_split=0.1,\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15cf18a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification\n\u001b[1;32m      2\u001b[0m classification\u001b[38;5;241m.\u001b[39msetup(data\u001b[38;5;241m=\u001b[39mtrain,target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from pycaret import classification\n",
    "# classification.setup(data=train,target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdc27c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014944076538085938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bfa9259fa14e53b2dafbd0d6c53548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector = get_mfcc_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "deaf394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_mel,columns=[f'mel_{i}' for i in range(384)])\n",
    "vector = pd.DataFrame(vector,columns=[f'mfcc_{i}' for i in range(128)])\n",
    "test = pd.concat([test,vector],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eed601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x2d67d5460>,\n",
       " <keras.engine.sequential.Sequential at 0x2d67d5460>,\n",
       " <keras.engine.sequential.Sequential at 0x2d67d5460>,\n",
       " <keras.engine.sequential.Sequential at 0x2d67d5460>,\n",
       " <keras.engine.sequential.Sequential at 0x2d67d5460>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb0cecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1881"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [i.predict(test) for i in models]\n",
    "preds = [np.argmax(i) for i in np.array(preds).mean(axis=0)]\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2cd30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['label'] = [np.argmax(i) for i in models[4].predict(test)]\n",
    "submission.to_csv('./baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
