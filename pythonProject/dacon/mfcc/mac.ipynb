{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a7d5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import librosa\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5116fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5001 non-null   object\n",
      " 1   path    5001 non-null   object\n",
      " 2   label   5001 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "train_df.info()\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "# valid_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f56f59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':128, # Melspectrogram 벡터를 추출할 개수\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "248c9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eb416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5001 non-null   object\n",
      " 1   path    5001 non-null   object\n",
      " 2   label   5001 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010677099227905273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5001,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074db9cfd345494a899206dfa855dbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004724979400634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48de70b59a8c4871ad4b05c5cc4d6b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "train_df.info()\n",
    "# train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=CFG['SEED'])\n",
    "\n",
    "def speech_file_to_array_fn(df):\n",
    "    feature = []\n",
    "    for path in tqdm(df['path']):\n",
    "        # path = '/content/drive/MyDrive/hi/sound01' + path[1:] \n",
    "        speech_array, _ = librosa.load(path, sr=CFG['SR'])\n",
    "        feature.append(1000*speech_array**3)\n",
    "    return feature\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# valid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_x = speech_file_to_array_fn(train_df)\n",
    "test_x = speech_file_to_array_fn(test_df)\n",
    "# valid_x = speech_file_to_array_fn(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1000*librosa.load(train_df['path'][1020], sr=CFG['SR'])[0]**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1893dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y, processor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_values = self.processor(self.x[idx], sampling_rate=CFG['SR'], return_tensors=\"pt\", padding=True).input_values\n",
    "        if self.y is not None:\n",
    "            return input_values.squeeze(), self.y[idx]\n",
    "        else:\n",
    "            return input_values.squeeze()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence([torch.tensor(xi) for xi in x], batch_first=True)\n",
    "    y = pad_sequence([torch.tensor([yi]) for yi in y], batch_first=True)  # Convert scalar targets to 1D tensors\n",
    "    return x, y\n",
    "\n",
    "def create_data_loader(dataset, batch_size, shuffle, collate_fn, num_workers=0):\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      collate_fn=collate_fn,\n",
    "                      num_workers=num_workers\n",
    "                      )\n",
    "\n",
    "train_dataset = CustomDataSet(train_x, train_df['label'], processor)\n",
    "test_dataset = CustomDataSet(test_x, y=None, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()\n",
    "\n",
    "# 0: angry\n",
    "# 1: fear\n",
    "# 2: sad\n",
    "# 3: disgust\n",
    "# 4: neutral\n",
    "# 5: happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df33ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# path = train_df['path'][0]\n",
    "        \n",
    "# y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "# y = list(y)\n",
    "# y.extend([0 for _ in range(80000-len(y))])\n",
    "# features.append(y)\n",
    "\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8d67353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebff07281a84a809fab340ffe05d782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29c2462a1c14228a779e3a7553c20ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_mel(df):\n",
    "    features = []\n",
    "    for i in tqdm(df['path']):\n",
    "        # i = '/content/drive/MyDrive/hi/sound01'+i[1:]\n",
    "        data, sr = librosa.load(i, sr=CFG['SR'])\n",
    "        data = 1000*data**3\n",
    "        n_fft = 2048\n",
    "        win_length = 2048\n",
    "        hop_length = 1024\n",
    "        n_mels = 128\n",
    " \n",
    "        D = np.abs(librosa.stft(data, n_fft=n_fft, win_length = win_length, hop_length=hop_length))\n",
    "        mel = librosa.feature.melspectrogram(S=D, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "        m_mel = mel.mean(axis=1)\n",
    "        features.append(m_mel)\n",
    "    return np.array(features)\n",
    "\n",
    "train_mel = get_feature_mel(train_df)\n",
    "# valid_mel = get_feature_mel(valid_df)\n",
    "test_mel = get_feature_mel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fca1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90945173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_mel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dad8418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3c90aff8bd4f8689d11beee20f6edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726926d7a8194cb8a74224bae578d952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mfcc_feature(df):\n",
    "    features = []\n",
    "#     for path in tqdm(df['path']):\n",
    "        \n",
    "#         y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "#         y = list(y)\n",
    "#         y.extend([0 for _ in range(80100-len(y))])\n",
    "#         features.append(y)\n",
    "    for path in tqdm(df['path']):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "        # y = 1000*y**3\n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "        y_feature = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature.append(np.mean(e))\n",
    "        features.append(y_feature)\n",
    "    return features\n",
    "    # return pd.DataFrame(features,columns=['freq'])\n",
    "\n",
    "vector = get_mfcc_feature(train_df)\n",
    "test_mfcc = get_mfcc_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['label'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca \n",
    "\n",
    "# pd.DataFrameFrame(vector.iloc[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=600)\n",
    "# pca.fit(vector)\n",
    "# target = pd.DataFrame(pca.transform(vector))\n",
    "# target.to_csv('./origin_600_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# max([len(i) for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(pca.transform(test))\n",
    "# test.to_csv('./test_600_pca.csv')\n",
    "\n",
    "# print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./origin_600_pca.csv')\n",
    "conc = pd.DataFrame([list(reversed(list(target.iloc[i,:]))) for i in range(len(target))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5006ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = conc.rename(columns={i:f'pca_{i}' for i in range(600)})\n",
    "target = target.rename(columns={f'{i}':f'pca_{i}' for i in range(600)}).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat([target,conc])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ec09ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_0</th>\n",
       "      <th>mel_1</th>\n",
       "      <th>mel_2</th>\n",
       "      <th>mel_3</th>\n",
       "      <th>mel_4</th>\n",
       "      <th>mel_5</th>\n",
       "      <th>mel_6</th>\n",
       "      <th>mel_7</th>\n",
       "      <th>mel_8</th>\n",
       "      <th>mel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_118</th>\n",
       "      <th>mfcc_119</th>\n",
       "      <th>mfcc_120</th>\n",
       "      <th>mfcc_121</th>\n",
       "      <th>mfcc_122</th>\n",
       "      <th>mfcc_123</th>\n",
       "      <th>mfcc_124</th>\n",
       "      <th>mfcc_125</th>\n",
       "      <th>mfcc_126</th>\n",
       "      <th>mfcc_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013719</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015964</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475243</td>\n",
       "      <td>0.129531</td>\n",
       "      <td>-0.105115</td>\n",
       "      <td>-0.443991</td>\n",
       "      <td>-0.567216</td>\n",
       "      <td>-0.303936</td>\n",
       "      <td>0.407998</td>\n",
       "      <td>0.501475</td>\n",
       "      <td>-0.109036</td>\n",
       "      <td>-0.058342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629086</td>\n",
       "      <td>0.514676</td>\n",
       "      <td>-0.314312</td>\n",
       "      <td>-0.197818</td>\n",
       "      <td>-0.422195</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>-0.217671</td>\n",
       "      <td>0.523408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.070081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.567651</td>\n",
       "      <td>0.380975</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0.497681</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>1.292413</td>\n",
       "      <td>1.174476</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.448215</td>\n",
       "      <td>0.628672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282975</td>\n",
       "      <td>-0.356842</td>\n",
       "      <td>-0.286293</td>\n",
       "      <td>-0.212861</td>\n",
       "      <td>-0.013879</td>\n",
       "      <td>-0.709901</td>\n",
       "      <td>-0.594326</td>\n",
       "      <td>-0.343695</td>\n",
       "      <td>-0.338751</td>\n",
       "      <td>-0.171855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622868</td>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.411688</td>\n",
       "      <td>0.631594</td>\n",
       "      <td>0.584484</td>\n",
       "      <td>0.391578</td>\n",
       "      <td>0.358792</td>\n",
       "      <td>0.512780</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.189386</td>\n",
       "      <td>-0.311290</td>\n",
       "      <td>-0.363777</td>\n",
       "      <td>-0.499418</td>\n",
       "      <td>-1.088192</td>\n",
       "      <td>-0.685789</td>\n",
       "      <td>0.120570</td>\n",
       "      <td>-0.686173</td>\n",
       "      <td>-0.157101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.222057</td>\n",
       "      <td>3.299814</td>\n",
       "      <td>4.119013</td>\n",
       "      <td>4.295127</td>\n",
       "      <td>3.677306</td>\n",
       "      <td>6.946488</td>\n",
       "      <td>6.592564</td>\n",
       "      <td>5.046597</td>\n",
       "      <td>2.378346</td>\n",
       "      <td>2.362655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.996369</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>-0.338776</td>\n",
       "      <td>-1.020306</td>\n",
       "      <td>-1.039265</td>\n",
       "      <td>-0.053770</td>\n",
       "      <td>0.154234</td>\n",
       "      <td>0.168259</td>\n",
       "      <td>-0.575030</td>\n",
       "      <td>-1.013335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.071441</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>0.120894</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.096072</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.149688</td>\n",
       "      <td>0.169614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.064578</td>\n",
       "      <td>0.330306</td>\n",
       "      <td>-0.484907</td>\n",
       "      <td>0.141396</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>-0.244010</td>\n",
       "      <td>0.037485</td>\n",
       "      <td>-0.131850</td>\n",
       "      <td>-0.035452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>104.478737</td>\n",
       "      <td>57.853981</td>\n",
       "      <td>33.674690</td>\n",
       "      <td>22.962410</td>\n",
       "      <td>18.590714</td>\n",
       "      <td>19.335785</td>\n",
       "      <td>18.104355</td>\n",
       "      <td>16.781382</td>\n",
       "      <td>17.089344</td>\n",
       "      <td>21.422354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731323</td>\n",
       "      <td>-0.307702</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>-0.328093</td>\n",
       "      <td>-0.237218</td>\n",
       "      <td>-0.570983</td>\n",
       "      <td>0.324473</td>\n",
       "      <td>-0.349720</td>\n",
       "      <td>-0.755602</td>\n",
       "      <td>-0.222972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.249757</td>\n",
       "      <td>0.187390</td>\n",
       "      <td>0.139185</td>\n",
       "      <td>0.187498</td>\n",
       "      <td>0.285357</td>\n",
       "      <td>0.494518</td>\n",
       "      <td>0.362228</td>\n",
       "      <td>0.236297</td>\n",
       "      <td>0.224831</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083660</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>-0.375393</td>\n",
       "      <td>-0.750303</td>\n",
       "      <td>-0.261566</td>\n",
       "      <td>-0.420591</td>\n",
       "      <td>0.519029</td>\n",
       "      <td>0.504589</td>\n",
       "      <td>-0.008825</td>\n",
       "      <td>-0.609881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.029698</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.050390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>-0.581784</td>\n",
       "      <td>-0.564808</td>\n",
       "      <td>-0.924709</td>\n",
       "      <td>-0.827351</td>\n",
       "      <td>-0.884314</td>\n",
       "      <td>-0.117483</td>\n",
       "      <td>-0.039797</td>\n",
       "      <td>0.120997</td>\n",
       "      <td>-0.864221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.181355</td>\n",
       "      <td>0.143773</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.275388</td>\n",
       "      <td>0.527902</td>\n",
       "      <td>0.282875</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.262390</td>\n",
       "      <td>0.315066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.360060</td>\n",
       "      <td>-0.264331</td>\n",
       "      <td>-0.179536</td>\n",
       "      <td>0.057327</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>-0.065777</td>\n",
       "      <td>0.188723</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>-0.324510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mel_0      mel_1      mel_2      mel_3      mel_4      mel_5  \\\n",
       "0       0.013719   0.010585   0.011365   0.015147   0.015964   0.012583   \n",
       "1       0.024698   0.017155   0.015430   0.017026   0.020601   0.027584   \n",
       "2       0.567651   0.380975   0.426005   0.497681   0.656522   1.292413   \n",
       "3       0.622868   0.436759   0.338462   0.411688   0.631594   0.584484   \n",
       "4       3.222057   3.299814   4.119013   4.295127   3.677306   6.946488   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4996    0.071441   0.051095   0.074915   0.120894   0.138325   0.085271   \n",
       "4997  104.478737  57.853981  33.674690  22.962410  18.590714  19.335785   \n",
       "4998    0.249757   0.187390   0.139185   0.187498   0.285357   0.494518   \n",
       "4999    0.029698   0.022480   0.024308   0.032744   0.044098   0.030326   \n",
       "5000    0.181355   0.143773   0.133854   0.187058   0.275388   0.527902   \n",
       "\n",
       "          mel_6      mel_7      mel_8      mel_9  ...  mfcc_118  mfcc_119  \\\n",
       "0      0.014782   0.022000   0.022887   0.021157  ... -0.475243  0.129531   \n",
       "1      0.037012   0.027860   0.029919   0.027653  ...  0.629086  0.514676   \n",
       "2      1.174476   0.579839   0.448215   0.628672  ... -0.282975 -0.356842   \n",
       "3      0.391578   0.358792   0.512780   0.648389  ...  0.205021  0.189386   \n",
       "4      6.592564   5.046597   2.378346   2.362655  ... -0.996369  0.035772   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "4996   0.096072   0.140013   0.149688   0.169614  ...  0.023185  0.064578   \n",
       "4997  18.104355  16.781382  17.089344  21.422354  ...  0.731323 -0.307702   \n",
       "4998   0.362228   0.236297   0.224831   0.261364  ... -0.083660  0.774606   \n",
       "4999   0.027065   0.034531   0.035271   0.050390  ...  0.015787 -0.581784   \n",
       "5000   0.282875   0.167886   0.262390   0.315066  ... -0.245682 -0.360060   \n",
       "\n",
       "      mfcc_120  mfcc_121  mfcc_122  mfcc_123  mfcc_124  mfcc_125  mfcc_126  \\\n",
       "0    -0.105115 -0.443991 -0.567216 -0.303936  0.407998  0.501475 -0.109036   \n",
       "1    -0.314312 -0.197818 -0.422195  0.004201 -0.217671  0.523408  0.020408   \n",
       "2    -0.286293 -0.212861 -0.013879 -0.709901 -0.594326 -0.343695 -0.338751   \n",
       "3    -0.311290 -0.363777 -0.499418 -1.088192 -0.685789  0.120570 -0.686173   \n",
       "4    -0.338776 -1.020306 -1.039265 -0.053770  0.154234  0.168259 -0.575030   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996  0.330306 -0.484907  0.141396  0.035094 -0.244010  0.037485 -0.131850   \n",
       "4997  0.357692 -0.328093 -0.237218 -0.570983  0.324473 -0.349720 -0.755602   \n",
       "4998 -0.375393 -0.750303 -0.261566 -0.420591  0.519029  0.504589 -0.008825   \n",
       "4999 -0.564808 -0.924709 -0.827351 -0.884314 -0.117483 -0.039797  0.120997   \n",
       "5000 -0.264331 -0.179536  0.057327  0.015065 -0.065777  0.188723  0.310501   \n",
       "\n",
       "      mfcc_127  \n",
       "0    -0.058342  \n",
       "1     0.070081  \n",
       "2    -0.171855  \n",
       "3    -0.157101  \n",
       "4    -1.013335  \n",
       "...        ...  \n",
       "4996 -0.035452  \n",
       "4997 -0.222972  \n",
       "4998 -0.609881  \n",
       "4999 -0.864221  \n",
       "5000 -0.324510  \n",
       "\n",
       "[5001 rows x 256 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = pd.DataFrame(vector,columns=[f'mfcc_{i}' for i in range(128)])\n",
    "train = pd.DataFrame(train_mel,columns=[f'mel_{i}' for i in range(128)])\n",
    "# train = train.rename(columns={f'{i}':f'mel_{i}' for i in range(128)})\n",
    "train = pd.concat([train,vector],axis=1)\n",
    "# train = pd.concat([train,tp],axis=1)\n",
    "# del(tp)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b57fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02bfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=[len(train.keys())]),\n",
    "        # layers.MaxPooling1D(pool_size=2,strides=1, padding='valid'),\n",
    "        layers.Dense(512),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(6,activation='softmax')\n",
    "        ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a8ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,686\n",
      "Trainable params: 167,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6964f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# skf = sklearn.model_selection.StratifiedKFold(n_splits=10)\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "383d4efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0901 - accuracy: 0.5605 - val_loss: 1.2498 - val_accuracy: 0.5130\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0435 - accuracy: 0.5857 - val_loss: 1.1464 - val_accuracy: 0.5550\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0224 - accuracy: 0.5932 - val_loss: 1.0994 - val_accuracy: 0.5790\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0018 - accuracy: 0.6060 - val_loss: 1.0659 - val_accuracy: 0.5850\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9878 - accuracy: 0.5987 - val_loss: 1.0489 - val_accuracy: 0.5810\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9558 - accuracy: 0.6263 - val_loss: 1.0118 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9567 - accuracy: 0.6248 - val_loss: 1.0452 - val_accuracy: 0.6040\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9434 - accuracy: 0.6285 - val_loss: 0.9663 - val_accuracy: 0.6110\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9123 - accuracy: 0.6430 - val_loss: 0.9311 - val_accuracy: 0.6270\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9094 - accuracy: 0.6405 - val_loss: 0.9407 - val_accuracy: 0.6210\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9018 - accuracy: 0.6453 - val_loss: 0.9864 - val_accuracy: 0.6150\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8908 - accuracy: 0.6530 - val_loss: 0.8676 - val_accuracy: 0.6640\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8880 - accuracy: 0.6485 - val_loss: 0.9293 - val_accuracy: 0.6170\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8841 - accuracy: 0.6593 - val_loss: 0.8813 - val_accuracy: 0.6610\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8598 - accuracy: 0.6658 - val_loss: 0.9555 - val_accuracy: 0.6330\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8502 - accuracy: 0.6665 - val_loss: 0.8342 - val_accuracy: 0.6710\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8287 - accuracy: 0.6825 - val_loss: 0.9172 - val_accuracy: 0.6480\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8403 - accuracy: 0.6700 - val_loss: 0.9175 - val_accuracy: 0.6520\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8429 - accuracy: 0.6660 - val_loss: 0.9489 - val_accuracy: 0.6420\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8358 - accuracy: 0.6733 - val_loss: 0.8231 - val_accuracy: 0.6750\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8075 - accuracy: 0.6913 - val_loss: 0.7835 - val_accuracy: 0.7020\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8158 - accuracy: 0.6867 - val_loss: 0.8206 - val_accuracy: 0.6740\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8081 - accuracy: 0.6810 - val_loss: 0.7961 - val_accuracy: 0.6920\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7922 - accuracy: 0.6913 - val_loss: 0.7902 - val_accuracy: 0.6880\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7755 - accuracy: 0.7078 - val_loss: 0.8004 - val_accuracy: 0.6820\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7499 - accuracy: 0.7100 - val_loss: 0.7582 - val_accuracy: 0.7190\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7685 - accuracy: 0.7028 - val_loss: 0.7554 - val_accuracy: 0.6950\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7241 - accuracy: 0.7128 - val_loss: 0.7520 - val_accuracy: 0.7010\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7531 - accuracy: 0.7082 - val_loss: 0.7651 - val_accuracy: 0.6920\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7574 - accuracy: 0.7082 - val_loss: 0.7625 - val_accuracy: 0.6990\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7383 - accuracy: 0.7157 - val_loss: 0.7012 - val_accuracy: 0.7250\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6956 - accuracy: 0.7350 - val_loss: 0.6567 - val_accuracy: 0.7450\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7075 - accuracy: 0.7262 - val_loss: 0.7350 - val_accuracy: 0.7210\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7035 - accuracy: 0.7303 - val_loss: 0.8147 - val_accuracy: 0.6960\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7163 - accuracy: 0.7218 - val_loss: 0.7676 - val_accuracy: 0.7030\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6884 - accuracy: 0.7385 - val_loss: 0.7305 - val_accuracy: 0.7120\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6896 - accuracy: 0.7380 - val_loss: 0.6143 - val_accuracy: 0.7570\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7023 - accuracy: 0.7375 - val_loss: 0.6249 - val_accuracy: 0.7560\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6663 - accuracy: 0.7470 - val_loss: 0.7662 - val_accuracy: 0.7100\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6504 - accuracy: 0.7483 - val_loss: 0.6185 - val_accuracy: 0.7570\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6481 - accuracy: 0.7465 - val_loss: 0.6491 - val_accuracy: 0.7530\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6646 - accuracy: 0.7450 - val_loss: 0.6061 - val_accuracy: 0.7750\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6264 - accuracy: 0.7588 - val_loss: 0.6417 - val_accuracy: 0.7470\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6145 - accuracy: 0.7613 - val_loss: 0.5836 - val_accuracy: 0.7610\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6283 - accuracy: 0.7550 - val_loss: 0.6348 - val_accuracy: 0.7520\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6222 - accuracy: 0.7598 - val_loss: 0.6325 - val_accuracy: 0.7550\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6273 - accuracy: 0.7600 - val_loss: 0.6442 - val_accuracy: 0.7560\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5968 - accuracy: 0.7657 - val_loss: 0.5653 - val_accuracy: 0.7860\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5729 - accuracy: 0.7872 - val_loss: 0.5217 - val_accuracy: 0.8170\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5903 - accuracy: 0.7747 - val_loss: 0.6017 - val_accuracy: 0.7800\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.9805 - accuracy: 0.6651 - val_loss: 0.7412 - val_accuracy: 0.7010\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.8867 - accuracy: 0.6708 - val_loss: 0.7495 - val_accuracy: 0.7010\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7875 - accuracy: 0.7031 - val_loss: 0.7742 - val_accuracy: 0.7080\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7811 - accuracy: 0.7043 - val_loss: 0.7707 - val_accuracy: 0.7090\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7626 - accuracy: 0.7163 - val_loss: 0.8315 - val_accuracy: 0.6830\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7838 - accuracy: 0.7023 - val_loss: 0.7472 - val_accuracy: 0.7120\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7414 - accuracy: 0.7173 - val_loss: 0.8300 - val_accuracy: 0.6830\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7396 - accuracy: 0.7203 - val_loss: 0.8950 - val_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7339 - accuracy: 0.7206 - val_loss: 0.9338 - val_accuracy: 0.6550\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7822 - accuracy: 0.7058 - val_loss: 0.8906 - val_accuracy: 0.6640\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8064 - accuracy: 0.7031 - val_loss: 0.9265 - val_accuracy: 0.6650\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7050 - accuracy: 0.7296 - val_loss: 1.1705 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7965 - accuracy: 0.6886 - val_loss: 1.0095 - val_accuracy: 0.6210\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7254 - accuracy: 0.7233 - val_loss: 0.9375 - val_accuracy: 0.6460\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7170 - accuracy: 0.7246 - val_loss: 1.0334 - val_accuracy: 0.6310\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6640 - accuracy: 0.7513 - val_loss: 1.0197 - val_accuracy: 0.6290\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7075 - accuracy: 0.7251 - val_loss: 1.0091 - val_accuracy: 0.6390\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6587 - accuracy: 0.7388 - val_loss: 1.0006 - val_accuracy: 0.6270\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7341 - val_loss: 1.1065 - val_accuracy: 0.6280\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6336 - accuracy: 0.7561 - val_loss: 1.2683 - val_accuracy: 0.5950\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6771 - accuracy: 0.7436 - val_loss: 1.1988 - val_accuracy: 0.5700\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7580 - accuracy: 0.7133 - val_loss: 1.2056 - val_accuracy: 0.6070\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6353 - accuracy: 0.7633 - val_loss: 1.0729 - val_accuracy: 0.6110\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6628 - accuracy: 0.7448 - val_loss: 1.0951 - val_accuracy: 0.6170\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6059 - accuracy: 0.7713 - val_loss: 1.1377 - val_accuracy: 0.6070\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6111 - accuracy: 0.7646 - val_loss: 1.1562 - val_accuracy: 0.6130\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7623 - accuracy: 0.7136 - val_loss: 1.1350 - val_accuracy: 0.5930\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6161 - accuracy: 0.7648 - val_loss: 1.1816 - val_accuracy: 0.6180\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6390 - accuracy: 0.7556 - val_loss: 1.1256 - val_accuracy: 0.6180\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5631 - accuracy: 0.7838 - val_loss: 1.2405 - val_accuracy: 0.6170\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6595 - accuracy: 0.7488 - val_loss: 1.2384 - val_accuracy: 0.6030\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6541 - accuracy: 0.7566 - val_loss: 1.1640 - val_accuracy: 0.6080\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.7653 - val_loss: 1.3048 - val_accuracy: 0.5840\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5748 - accuracy: 0.7786 - val_loss: 1.2398 - val_accuracy: 0.6030\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7793 - val_loss: 1.1935 - val_accuracy: 0.5920\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.7713 - val_loss: 1.3523 - val_accuracy: 0.5900\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5708 - accuracy: 0.7798 - val_loss: 1.2424 - val_accuracy: 0.5940\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5415 - accuracy: 0.7873 - val_loss: 1.4270 - val_accuracy: 0.5660\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5622 - accuracy: 0.7856 - val_loss: 1.4214 - val_accuracy: 0.5860\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5403 - accuracy: 0.7886 - val_loss: 1.3275 - val_accuracy: 0.5880\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6554 - accuracy: 0.7533 - val_loss: 1.3751 - val_accuracy: 0.5840\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7198 - accuracy: 0.7213 - val_loss: 1.3806 - val_accuracy: 0.5610\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6888 - accuracy: 0.7356 - val_loss: 1.3499 - val_accuracy: 0.5480\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6991 - accuracy: 0.7318 - val_loss: 1.2806 - val_accuracy: 0.5920\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6228 - accuracy: 0.7613 - val_loss: 1.6215 - val_accuracy: 0.5530\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7508 - val_loss: 1.2982 - val_accuracy: 0.5800\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6837 - accuracy: 0.7341 - val_loss: 1.3980 - val_accuracy: 0.5650\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6110 - accuracy: 0.7641 - val_loss: 1.3559 - val_accuracy: 0.5670\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7246 - accuracy: 0.7118 - val_loss: 1.5381 - val_accuracy: 0.5470\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6448 - accuracy: 0.7483 - val_loss: 1.4578 - val_accuracy: 0.5590\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.9207 - accuracy: 0.6556 - val_loss: 0.6536 - val_accuracy: 0.7560\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8325 - accuracy: 0.6956 - val_loss: 0.6701 - val_accuracy: 0.7540\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7506 - accuracy: 0.7093 - val_loss: 0.6648 - val_accuracy: 0.7420\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7451 - accuracy: 0.7108 - val_loss: 0.6764 - val_accuracy: 0.7370\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7009 - accuracy: 0.7281 - val_loss: 0.7351 - val_accuracy: 0.7140\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7215 - accuracy: 0.7266 - val_loss: 0.7110 - val_accuracy: 0.7210\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6537 - accuracy: 0.7526 - val_loss: 0.6797 - val_accuracy: 0.7450\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6533 - accuracy: 0.7541 - val_loss: 0.7202 - val_accuracy: 0.7360\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6674 - accuracy: 0.7456 - val_loss: 0.7246 - val_accuracy: 0.7230\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6397 - accuracy: 0.7556 - val_loss: 0.7952 - val_accuracy: 0.7070\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.7473 - val_loss: 0.8376 - val_accuracy: 0.6990\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6162 - accuracy: 0.7698 - val_loss: 0.7935 - val_accuracy: 0.6880\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6874 - accuracy: 0.7376 - val_loss: 0.7880 - val_accuracy: 0.7010\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6624 - accuracy: 0.7421 - val_loss: 0.7766 - val_accuracy: 0.7130\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5971 - accuracy: 0.7688 - val_loss: 0.7954 - val_accuracy: 0.7070\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6625 - accuracy: 0.7463 - val_loss: 0.8624 - val_accuracy: 0.6760\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6042 - accuracy: 0.7683 - val_loss: 0.7802 - val_accuracy: 0.7090\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6076 - accuracy: 0.7671 - val_loss: 0.9227 - val_accuracy: 0.6750\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5731 - accuracy: 0.7833 - val_loss: 1.0199 - val_accuracy: 0.6580\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5965 - accuracy: 0.7646 - val_loss: 0.8645 - val_accuracy: 0.6890\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5684 - accuracy: 0.7791 - val_loss: 0.9467 - val_accuracy: 0.6760\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5875 - accuracy: 0.7701 - val_loss: 0.9926 - val_accuracy: 0.6590\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.7966 - val_loss: 0.9981 - val_accuracy: 0.6770\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5771 - accuracy: 0.7793 - val_loss: 0.9604 - val_accuracy: 0.6790\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.8025 - val_loss: 0.9267 - val_accuracy: 0.6930\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5823 - accuracy: 0.7763 - val_loss: 0.9789 - val_accuracy: 0.6470\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5785 - accuracy: 0.7761 - val_loss: 1.0372 - val_accuracy: 0.6650\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5245 - accuracy: 0.8003 - val_loss: 1.0137 - val_accuracy: 0.6710\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7848 - val_loss: 1.1387 - val_accuracy: 0.6610\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5436 - accuracy: 0.7893 - val_loss: 1.1647 - val_accuracy: 0.6380\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6772 - accuracy: 0.7468 - val_loss: 1.1348 - val_accuracy: 0.6240\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5876 - accuracy: 0.7718 - val_loss: 1.0491 - val_accuracy: 0.6620\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.8013 - val_loss: 1.1099 - val_accuracy: 0.6500\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5098 - accuracy: 0.8078 - val_loss: 1.0618 - val_accuracy: 0.6340\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.7661 - val_loss: 1.1738 - val_accuracy: 0.6220\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5569 - accuracy: 0.7833 - val_loss: 1.1398 - val_accuracy: 0.6240\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.7711 - accuracy: 0.7198 - val_loss: 1.1331 - val_accuracy: 0.6010\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5693 - accuracy: 0.7843 - val_loss: 1.1049 - val_accuracy: 0.6460\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5335 - accuracy: 0.7946 - val_loss: 1.2180 - val_accuracy: 0.6220\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5298 - accuracy: 0.7968 - val_loss: 1.2144 - val_accuracy: 0.5970\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7958 - val_loss: 1.2890 - val_accuracy: 0.6150\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5480 - accuracy: 0.7866 - val_loss: 1.2786 - val_accuracy: 0.6090\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6251 - accuracy: 0.7708 - val_loss: 1.2586 - val_accuracy: 0.5950\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7886 - val_loss: 1.1763 - val_accuracy: 0.6260\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.7918 - val_loss: 1.1354 - val_accuracy: 0.6400\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4965 - accuracy: 0.8065 - val_loss: 1.2303 - val_accuracy: 0.6300\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7823 - val_loss: 1.6357 - val_accuracy: 0.5900\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5610 - accuracy: 0.7843 - val_loss: 1.2767 - val_accuracy: 0.6130\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5438 - accuracy: 0.7963 - val_loss: 1.2784 - val_accuracy: 0.6300\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.8133 - val_loss: 1.6022 - val_accuracy: 0.6130\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8062 - accuracy: 0.7198 - val_loss: 0.5388 - val_accuracy: 0.8010\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6758 - accuracy: 0.7511 - val_loss: 0.5359 - val_accuracy: 0.7890\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6103 - accuracy: 0.7701 - val_loss: 0.4967 - val_accuracy: 0.8010\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5766 - accuracy: 0.7843 - val_loss: 0.5576 - val_accuracy: 0.7950\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.7831 - val_loss: 0.6734 - val_accuracy: 0.7410\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6698 - accuracy: 0.7483 - val_loss: 0.5853 - val_accuracy: 0.7820\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5993 - accuracy: 0.7676 - val_loss: 0.6141 - val_accuracy: 0.7650\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6631 - accuracy: 0.7448 - val_loss: 0.5808 - val_accuracy: 0.7850\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5531 - accuracy: 0.7898 - val_loss: 0.6461 - val_accuracy: 0.7450\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5605 - accuracy: 0.7871 - val_loss: 0.5821 - val_accuracy: 0.7780\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5695 - accuracy: 0.7878 - val_loss: 0.7450 - val_accuracy: 0.7390\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.7408 - val_loss: 0.6723 - val_accuracy: 0.7540\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.7888 - val_loss: 0.6923 - val_accuracy: 0.7580\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5924 - accuracy: 0.7781 - val_loss: 0.6189 - val_accuracy: 0.7560\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7916 - val_loss: 0.6660 - val_accuracy: 0.7590\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7858 - val_loss: 0.7369 - val_accuracy: 0.7250\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6948 - accuracy: 0.7373 - val_loss: 0.7327 - val_accuracy: 0.7210\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7686 - val_loss: 0.7365 - val_accuracy: 0.7320\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5568 - accuracy: 0.7843 - val_loss: 0.7422 - val_accuracy: 0.7210\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5536 - accuracy: 0.7798 - val_loss: 0.7660 - val_accuracy: 0.7300\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5503 - accuracy: 0.7856 - val_loss: 0.8213 - val_accuracy: 0.7030\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.8542 - accuracy: 0.7086 - val_loss: 0.9053 - val_accuracy: 0.6690\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8077 - accuracy: 0.7056 - val_loss: 0.8547 - val_accuracy: 0.7060\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6245 - accuracy: 0.7568 - val_loss: 0.8497 - val_accuracy: 0.7040\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5853 - accuracy: 0.7758 - val_loss: 0.8874 - val_accuracy: 0.6770\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5685 - accuracy: 0.7776 - val_loss: 0.8863 - val_accuracy: 0.6830\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6004 - accuracy: 0.7633 - val_loss: 0.9161 - val_accuracy: 0.6820\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5811 - accuracy: 0.7731 - val_loss: 0.9825 - val_accuracy: 0.6750\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5722 - accuracy: 0.7766 - val_loss: 0.9348 - val_accuracy: 0.6810\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5523 - accuracy: 0.7873 - val_loss: 0.8803 - val_accuracy: 0.7100\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5393 - accuracy: 0.7921 - val_loss: 0.9202 - val_accuracy: 0.6800\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5542 - accuracy: 0.7863 - val_loss: 1.0157 - val_accuracy: 0.6820\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5697 - accuracy: 0.7773 - val_loss: 0.9528 - val_accuracy: 0.6870\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.8070 - val_loss: 0.9685 - val_accuracy: 0.6850\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5169 - accuracy: 0.7983 - val_loss: 0.9595 - val_accuracy: 0.6860\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5164 - accuracy: 0.8043 - val_loss: 1.0065 - val_accuracy: 0.6700\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6159 - accuracy: 0.7658 - val_loss: 1.0092 - val_accuracy: 0.6700\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5460 - accuracy: 0.7921 - val_loss: 1.1062 - val_accuracy: 0.6710\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4835 - accuracy: 0.8145 - val_loss: 0.9691 - val_accuracy: 0.6800\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.8075 - val_loss: 1.1080 - val_accuracy: 0.6690\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.7993 - val_loss: 1.1756 - val_accuracy: 0.6640\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5702 - accuracy: 0.7776 - val_loss: 0.9696 - val_accuracy: 0.6870\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4798 - accuracy: 0.8160 - val_loss: 1.0888 - val_accuracy: 0.6670\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.8000 - val_loss: 1.0469 - val_accuracy: 0.6770\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4831 - accuracy: 0.8075 - val_loss: 1.0629 - val_accuracy: 0.6850\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.8260 - val_loss: 1.0054 - val_accuracy: 0.6880\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.8085 - val_loss: 1.1592 - val_accuracy: 0.6730\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5152 - accuracy: 0.7991 - val_loss: 1.0784 - val_accuracy: 0.6700\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.8088 - val_loss: 1.1535 - val_accuracy: 0.6500\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6023 - accuracy: 0.7751 - val_loss: 1.1231 - val_accuracy: 0.6580\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6931 - accuracy: 0.7516 - val_loss: 0.6080 - val_accuracy: 0.7810\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6255 - accuracy: 0.7641 - val_loss: 0.5462 - val_accuracy: 0.7850\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.5705 - accuracy: 0.7816 - val_loss: 0.4570 - val_accuracy: 0.8240\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5596 - accuracy: 0.7898 - val_loss: 0.4386 - val_accuracy: 0.8300\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7943 - val_loss: 0.5443 - val_accuracy: 0.7870\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7990\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7976 - val_loss: 0.5358 - val_accuracy: 0.7970\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5057 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.8070\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.8063 - val_loss: 0.5351 - val_accuracy: 0.7880\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.8020 - val_loss: 0.6104 - val_accuracy: 0.7550\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.8088 - val_loss: 0.5215 - val_accuracy: 0.8080\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.8158 - val_loss: 0.6194 - val_accuracy: 0.7670\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5186 - accuracy: 0.7938 - val_loss: 0.6875 - val_accuracy: 0.7470\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5176 - accuracy: 0.8003 - val_loss: 0.5809 - val_accuracy: 0.7750\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.8195 - val_loss: 0.5908 - val_accuracy: 0.7690\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4519 - accuracy: 0.8250 - val_loss: 0.6021 - val_accuracy: 0.7750\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.8358 - val_loss: 0.6449 - val_accuracy: 0.7600\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4816 - accuracy: 0.8095 - val_loss: 0.7051 - val_accuracy: 0.7380\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7961 - val_loss: 0.6664 - val_accuracy: 0.7560\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5572 - accuracy: 0.7866 - val_loss: 0.6338 - val_accuracy: 0.7450\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4964 - accuracy: 0.8075 - val_loss: 0.7250 - val_accuracy: 0.7250\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.8243 - val_loss: 0.6919 - val_accuracy: 0.7360\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.8013 - val_loss: 0.7310 - val_accuracy: 0.7350\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4695 - accuracy: 0.8178 - val_loss: 0.7615 - val_accuracy: 0.7290\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4773 - accuracy: 0.8188 - val_loss: 0.7888 - val_accuracy: 0.7380\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4469 - accuracy: 0.8290 - val_loss: 0.7976 - val_accuracy: 0.7170\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.6152 - accuracy: 0.7631 - val_loss: 0.9987 - val_accuracy: 0.6640\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4903 - accuracy: 0.8068 - val_loss: 0.8086 - val_accuracy: 0.7170\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5132 - accuracy: 0.7966 - val_loss: 0.8142 - val_accuracy: 0.7260\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4725 - accuracy: 0.8158 - val_loss: 0.8000 - val_accuracy: 0.7170\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4293 - accuracy: 0.8303 - val_loss: 0.8817 - val_accuracy: 0.6970\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4719 - accuracy: 0.8128 - val_loss: 1.0356 - val_accuracy: 0.6890\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.8103 - val_loss: 0.8894 - val_accuracy: 0.7240\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5145 - accuracy: 0.8063 - val_loss: 0.9601 - val_accuracy: 0.6970\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.8338 - val_loss: 0.9760 - val_accuracy: 0.6910\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8015 - val_loss: 0.9735 - val_accuracy: 0.6870\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.8165 - val_loss: 0.9677 - val_accuracy: 0.6840\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.8268 - val_loss: 1.0111 - val_accuracy: 0.6950\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.8318 - val_loss: 0.9392 - val_accuracy: 0.6980\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8425 - val_loss: 0.9035 - val_accuracy: 0.7220\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.8288 - val_loss: 1.0180 - val_accuracy: 0.6780\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.8300 - val_loss: 1.1343 - val_accuracy: 0.6710\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.8268 - val_loss: 1.0443 - val_accuracy: 0.7050\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4307 - accuracy: 0.8290 - val_loss: 1.1087 - val_accuracy: 0.6800\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8408 - val_loss: 1.1208 - val_accuracy: 0.6880\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.6118 - accuracy: 0.7848 - val_loss: 1.0902 - val_accuracy: 0.6700\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.5562 - accuracy: 0.8038 - val_loss: 1.0572 - val_accuracy: 0.6890\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8385 - val_loss: 1.0898 - val_accuracy: 0.6780\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.3912 - accuracy: 0.8410 - val_loss: 1.1022 - val_accuracy: 0.6860\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8370 - val_loss: 1.1324 - val_accuracy: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# class PrintDot(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         if epoch % 100 == 0: print('')\n",
    "#         print('.', end='')\n",
    "\n",
    "# EPOCHS = 1000\n",
    "\n",
    "# history = model.fit(\n",
    "#   train, train_df['label'],\n",
    "#   epochs=EPOCHS, validation_split = 0.1, verbose=0,\n",
    "#   callbacks=[PrintDot()])\n",
    "\n",
    "\n",
    "\n",
    "skf = sklearn.model_selection.KFold(n_splits=5)\n",
    "models = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, train_df['label'])):\n",
    "    model.fit(train.loc[train_index,:]\n",
    "              , train_df.loc[train_index,'label']\n",
    "              , epochs=50\n",
    "              , validation_data=(train.loc[test_index,:],train_df.loc[test_index,'label'])) # validation_split=0.1,\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc27c46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification\n\u001b[1;32m      2\u001b[0m classification\u001b[38;5;241m.\u001b[39msetup(data\u001b[38;5;241m=\u001b[39mtrain,target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classification' from 'pycaret' (/Users/junho/miniforge3/envs/ml_dl/lib/python3.8/site-packages/pycaret/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from pycaret import classification\n",
    "# classification.setup(data=train,target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deaf394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_mel,columns=[f'mel_{i}' for i in range(64)])\n",
    "vector = pd.DataFrame(test_mfcc,columns=[f'mfcc_{i}' for i in range(64)])\n",
    "test = pd.concat([test,vector],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eed601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>,\n",
       " <keras.engine.sequential.Sequential at 0x1c6c1780160>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb0cecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step\n",
      "59/59 [==============================] - 0s 4ms/step\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "59/59 [==============================] - 1s 9ms/step\n",
      "59/59 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = [i.predict(test) for i in models]\n",
    "preds = [np.argmax(i) for i in np.array(preds).mean(axis=0)]\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f59b40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b42d8314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_0</th>\n",
       "      <th>mel_1</th>\n",
       "      <th>mel_2</th>\n",
       "      <th>mel_3</th>\n",
       "      <th>mel_4</th>\n",
       "      <th>mel_5</th>\n",
       "      <th>mel_6</th>\n",
       "      <th>mel_7</th>\n",
       "      <th>mel_8</th>\n",
       "      <th>mel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_118</th>\n",
       "      <th>mfcc_119</th>\n",
       "      <th>mfcc_120</th>\n",
       "      <th>mfcc_121</th>\n",
       "      <th>mfcc_122</th>\n",
       "      <th>mfcc_123</th>\n",
       "      <th>mfcc_124</th>\n",
       "      <th>mfcc_125</th>\n",
       "      <th>mfcc_126</th>\n",
       "      <th>mfcc_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013719</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015964</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475243</td>\n",
       "      <td>0.129531</td>\n",
       "      <td>-0.105115</td>\n",
       "      <td>-0.443991</td>\n",
       "      <td>-0.567216</td>\n",
       "      <td>-0.303936</td>\n",
       "      <td>0.407998</td>\n",
       "      <td>0.501475</td>\n",
       "      <td>-0.109036</td>\n",
       "      <td>-0.058342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629086</td>\n",
       "      <td>0.514676</td>\n",
       "      <td>-0.314312</td>\n",
       "      <td>-0.197818</td>\n",
       "      <td>-0.422195</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>-0.217671</td>\n",
       "      <td>0.523408</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.070081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.567651</td>\n",
       "      <td>0.380975</td>\n",
       "      <td>0.426005</td>\n",
       "      <td>0.497681</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>1.292413</td>\n",
       "      <td>1.174476</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.448215</td>\n",
       "      <td>0.628672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282975</td>\n",
       "      <td>-0.356842</td>\n",
       "      <td>-0.286293</td>\n",
       "      <td>-0.212861</td>\n",
       "      <td>-0.013879</td>\n",
       "      <td>-0.709901</td>\n",
       "      <td>-0.594326</td>\n",
       "      <td>-0.343695</td>\n",
       "      <td>-0.338751</td>\n",
       "      <td>-0.171855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622868</td>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.411688</td>\n",
       "      <td>0.631594</td>\n",
       "      <td>0.584484</td>\n",
       "      <td>0.391578</td>\n",
       "      <td>0.358792</td>\n",
       "      <td>0.512780</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.189386</td>\n",
       "      <td>-0.311290</td>\n",
       "      <td>-0.363777</td>\n",
       "      <td>-0.499418</td>\n",
       "      <td>-1.088192</td>\n",
       "      <td>-0.685789</td>\n",
       "      <td>0.120570</td>\n",
       "      <td>-0.686173</td>\n",
       "      <td>-0.157101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.222057</td>\n",
       "      <td>3.299814</td>\n",
       "      <td>4.119013</td>\n",
       "      <td>4.295127</td>\n",
       "      <td>3.677306</td>\n",
       "      <td>6.946488</td>\n",
       "      <td>6.592564</td>\n",
       "      <td>5.046597</td>\n",
       "      <td>2.378346</td>\n",
       "      <td>2.362655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.996369</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>-0.338776</td>\n",
       "      <td>-1.020306</td>\n",
       "      <td>-1.039265</td>\n",
       "      <td>-0.053770</td>\n",
       "      <td>0.154234</td>\n",
       "      <td>0.168259</td>\n",
       "      <td>-0.575030</td>\n",
       "      <td>-1.013335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.071441</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>0.120894</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.096072</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.149688</td>\n",
       "      <td>0.169614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.064578</td>\n",
       "      <td>0.330306</td>\n",
       "      <td>-0.484907</td>\n",
       "      <td>0.141396</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>-0.244010</td>\n",
       "      <td>0.037485</td>\n",
       "      <td>-0.131850</td>\n",
       "      <td>-0.035452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>104.478737</td>\n",
       "      <td>57.853981</td>\n",
       "      <td>33.674690</td>\n",
       "      <td>22.962410</td>\n",
       "      <td>18.590714</td>\n",
       "      <td>19.335785</td>\n",
       "      <td>18.104355</td>\n",
       "      <td>16.781382</td>\n",
       "      <td>17.089344</td>\n",
       "      <td>21.422354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731323</td>\n",
       "      <td>-0.307702</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>-0.328093</td>\n",
       "      <td>-0.237218</td>\n",
       "      <td>-0.570983</td>\n",
       "      <td>0.324473</td>\n",
       "      <td>-0.349720</td>\n",
       "      <td>-0.755602</td>\n",
       "      <td>-0.222972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.249757</td>\n",
       "      <td>0.187390</td>\n",
       "      <td>0.139185</td>\n",
       "      <td>0.187498</td>\n",
       "      <td>0.285357</td>\n",
       "      <td>0.494518</td>\n",
       "      <td>0.362228</td>\n",
       "      <td>0.236297</td>\n",
       "      <td>0.224831</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083660</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>-0.375393</td>\n",
       "      <td>-0.750303</td>\n",
       "      <td>-0.261566</td>\n",
       "      <td>-0.420591</td>\n",
       "      <td>0.519029</td>\n",
       "      <td>0.504589</td>\n",
       "      <td>-0.008825</td>\n",
       "      <td>-0.609881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.029698</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.050390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>-0.581784</td>\n",
       "      <td>-0.564808</td>\n",
       "      <td>-0.924709</td>\n",
       "      <td>-0.827351</td>\n",
       "      <td>-0.884314</td>\n",
       "      <td>-0.117483</td>\n",
       "      <td>-0.039797</td>\n",
       "      <td>0.120997</td>\n",
       "      <td>-0.864221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.181355</td>\n",
       "      <td>0.143773</td>\n",
       "      <td>0.133854</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.275388</td>\n",
       "      <td>0.527902</td>\n",
       "      <td>0.282875</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.262390</td>\n",
       "      <td>0.315066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.360060</td>\n",
       "      <td>-0.264331</td>\n",
       "      <td>-0.179536</td>\n",
       "      <td>0.057327</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>-0.065777</td>\n",
       "      <td>0.188723</td>\n",
       "      <td>0.310501</td>\n",
       "      <td>-0.324510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mel_0      mel_1      mel_2      mel_3      mel_4      mel_5  \\\n",
       "0       0.013719   0.010585   0.011365   0.015147   0.015964   0.012583   \n",
       "1       0.024698   0.017155   0.015430   0.017026   0.020601   0.027584   \n",
       "2       0.567651   0.380975   0.426005   0.497681   0.656522   1.292413   \n",
       "3       0.622868   0.436759   0.338462   0.411688   0.631594   0.584484   \n",
       "4       3.222057   3.299814   4.119013   4.295127   3.677306   6.946488   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "4996    0.071441   0.051095   0.074915   0.120894   0.138325   0.085271   \n",
       "4997  104.478737  57.853981  33.674690  22.962410  18.590714  19.335785   \n",
       "4998    0.249757   0.187390   0.139185   0.187498   0.285357   0.494518   \n",
       "4999    0.029698   0.022480   0.024308   0.032744   0.044098   0.030326   \n",
       "5000    0.181355   0.143773   0.133854   0.187058   0.275388   0.527902   \n",
       "\n",
       "          mel_6      mel_7      mel_8      mel_9  ...  mfcc_118  mfcc_119  \\\n",
       "0      0.014782   0.022000   0.022887   0.021157  ... -0.475243  0.129531   \n",
       "1      0.037012   0.027860   0.029919   0.027653  ...  0.629086  0.514676   \n",
       "2      1.174476   0.579839   0.448215   0.628672  ... -0.282975 -0.356842   \n",
       "3      0.391578   0.358792   0.512780   0.648389  ...  0.205021  0.189386   \n",
       "4      6.592564   5.046597   2.378346   2.362655  ... -0.996369  0.035772   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "4996   0.096072   0.140013   0.149688   0.169614  ...  0.023185  0.064578   \n",
       "4997  18.104355  16.781382  17.089344  21.422354  ...  0.731323 -0.307702   \n",
       "4998   0.362228   0.236297   0.224831   0.261364  ... -0.083660  0.774606   \n",
       "4999   0.027065   0.034531   0.035271   0.050390  ...  0.015787 -0.581784   \n",
       "5000   0.282875   0.167886   0.262390   0.315066  ... -0.245682 -0.360060   \n",
       "\n",
       "      mfcc_120  mfcc_121  mfcc_122  mfcc_123  mfcc_124  mfcc_125  mfcc_126  \\\n",
       "0    -0.105115 -0.443991 -0.567216 -0.303936  0.407998  0.501475 -0.109036   \n",
       "1    -0.314312 -0.197818 -0.422195  0.004201 -0.217671  0.523408  0.020408   \n",
       "2    -0.286293 -0.212861 -0.013879 -0.709901 -0.594326 -0.343695 -0.338751   \n",
       "3    -0.311290 -0.363777 -0.499418 -1.088192 -0.685789  0.120570 -0.686173   \n",
       "4    -0.338776 -1.020306 -1.039265 -0.053770  0.154234  0.168259 -0.575030   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4996  0.330306 -0.484907  0.141396  0.035094 -0.244010  0.037485 -0.131850   \n",
       "4997  0.357692 -0.328093 -0.237218 -0.570983  0.324473 -0.349720 -0.755602   \n",
       "4998 -0.375393 -0.750303 -0.261566 -0.420591  0.519029  0.504589 -0.008825   \n",
       "4999 -0.564808 -0.924709 -0.827351 -0.884314 -0.117483 -0.039797  0.120997   \n",
       "5000 -0.264331 -0.179536  0.057327  0.015065 -0.065777  0.188723  0.310501   \n",
       "\n",
       "      mfcc_127  \n",
       "0    -0.058342  \n",
       "1     0.070081  \n",
       "2    -0.171855  \n",
       "3    -0.157101  \n",
       "4    -1.013335  \n",
       "...        ...  \n",
       "4996 -0.035452  \n",
       "4997 -0.222972  \n",
       "4998 -0.609881  \n",
       "4999 -0.864221  \n",
       "5000 -0.324510  \n",
       "\n",
       "[5001 rows x 256 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2890e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = pd.read_csv('./train.csv')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "307d4efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_13620_row8_col1, #T_13620_row12_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_13620\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_13620_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_13620_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_13620_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_13620_row0_col1\" class=\"data row0 col1\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_13620_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_13620_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_13620_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_13620_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_13620_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_13620_row3_col1\" class=\"data row3 col1\" >(5001, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_13620_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_13620_row4_col1\" class=\"data row4 col1\" >(4901, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_13620_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_13620_row5_col1\" class=\"data row5 col1\" >(3900, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_13620_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_13620_row6_col1\" class=\"data row6 col1\" >(1001, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_13620_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_13620_row7_col1\" class=\"data row7 col1\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_13620_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_13620_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_13620_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_13620_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_13620_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_13620_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_13620_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_13620_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_13620_row12_col0\" class=\"data row12 col0\" >Remove outliers</td>\n",
       "      <td id=\"T_13620_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_13620_row13_col0\" class=\"data row13 col0\" >Outliers threshold</td>\n",
       "      <td id=\"T_13620_row13_col1\" class=\"data row13 col1\" >0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_13620_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_13620_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_13620_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_13620_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_13620_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_13620_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_13620_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_13620_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_13620_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_13620_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_13620_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_13620_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13620_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_13620_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_13620_row20_col1\" class=\"data row20 col1\" >efd8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c706c996a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x1c706df4fd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret import classification\n",
    "classification.setup(data=train,\n",
    "                     target='label',\n",
    "                     # fold_strategy='kfold',\n",
    "                     train_size=0.8,\n",
    "                     session_id=77,\n",
    "                     remove_outliers=True,\n",
    "                     outliers_method='iforest',\n",
    "                     outliers_threshold=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71d55352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f4333 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f4333_row0_col0, #T_f4333_row1_col0, #T_f4333_row1_col1, #T_f4333_row1_col2, #T_f4333_row1_col3, #T_f4333_row1_col4, #T_f4333_row1_col5, #T_f4333_row1_col6, #T_f4333_row1_col7, #T_f4333_row2_col0, #T_f4333_row2_col1, #T_f4333_row2_col2, #T_f4333_row2_col3, #T_f4333_row2_col4, #T_f4333_row2_col5, #T_f4333_row2_col6, #T_f4333_row2_col7, #T_f4333_row3_col0, #T_f4333_row3_col1, #T_f4333_row3_col2, #T_f4333_row3_col3, #T_f4333_row3_col4, #T_f4333_row3_col5, #T_f4333_row3_col6, #T_f4333_row3_col7, #T_f4333_row4_col0, #T_f4333_row4_col1, #T_f4333_row4_col2, #T_f4333_row4_col3, #T_f4333_row4_col4, #T_f4333_row4_col5, #T_f4333_row4_col6, #T_f4333_row4_col7, #T_f4333_row5_col0, #T_f4333_row5_col1, #T_f4333_row5_col2, #T_f4333_row5_col3, #T_f4333_row5_col4, #T_f4333_row5_col5, #T_f4333_row5_col6, #T_f4333_row5_col7, #T_f4333_row6_col0, #T_f4333_row6_col1, #T_f4333_row6_col2, #T_f4333_row6_col3, #T_f4333_row6_col4, #T_f4333_row6_col5, #T_f4333_row6_col6, #T_f4333_row6_col7, #T_f4333_row7_col0, #T_f4333_row7_col1, #T_f4333_row7_col2, #T_f4333_row7_col3, #T_f4333_row7_col4, #T_f4333_row7_col5, #T_f4333_row7_col6, #T_f4333_row7_col7, #T_f4333_row8_col0, #T_f4333_row8_col1, #T_f4333_row8_col2, #T_f4333_row8_col3, #T_f4333_row8_col4, #T_f4333_row8_col5, #T_f4333_row8_col6, #T_f4333_row8_col7, #T_f4333_row9_col0, #T_f4333_row9_col1, #T_f4333_row9_col2, #T_f4333_row9_col3, #T_f4333_row9_col4, #T_f4333_row9_col5, #T_f4333_row9_col6, #T_f4333_row9_col7, #T_f4333_row10_col0, #T_f4333_row10_col1, #T_f4333_row10_col2, #T_f4333_row10_col3, #T_f4333_row10_col4, #T_f4333_row10_col5, #T_f4333_row10_col6, #T_f4333_row10_col7, #T_f4333_row11_col0, #T_f4333_row11_col1, #T_f4333_row11_col2, #T_f4333_row11_col3, #T_f4333_row11_col4, #T_f4333_row11_col5, #T_f4333_row11_col6, #T_f4333_row11_col7, #T_f4333_row12_col0, #T_f4333_row12_col1, #T_f4333_row12_col2, #T_f4333_row12_col3, #T_f4333_row12_col4, #T_f4333_row12_col5, #T_f4333_row12_col6, #T_f4333_row12_col7, #T_f4333_row13_col0, #T_f4333_row13_col1, #T_f4333_row13_col2, #T_f4333_row13_col3, #T_f4333_row13_col4, #T_f4333_row13_col5, #T_f4333_row13_col6, #T_f4333_row13_col7, #T_f4333_row14_col0, #T_f4333_row14_col1, #T_f4333_row14_col2, #T_f4333_row14_col3, #T_f4333_row14_col4, #T_f4333_row14_col5, #T_f4333_row14_col6, #T_f4333_row14_col7, #T_f4333_row15_col0, #T_f4333_row15_col1, #T_f4333_row15_col2, #T_f4333_row15_col3, #T_f4333_row15_col4, #T_f4333_row15_col5, #T_f4333_row15_col6, #T_f4333_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f4333_row0_col1, #T_f4333_row0_col2, #T_f4333_row0_col3, #T_f4333_row0_col4, #T_f4333_row0_col5, #T_f4333_row0_col6, #T_f4333_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f4333_row0_col8, #T_f4333_row1_col8, #T_f4333_row2_col8, #T_f4333_row3_col8, #T_f4333_row4_col8, #T_f4333_row5_col8, #T_f4333_row6_col8, #T_f4333_row7_col8, #T_f4333_row9_col8, #T_f4333_row10_col8, #T_f4333_row11_col8, #T_f4333_row12_col8, #T_f4333_row13_col8, #T_f4333_row14_col8, #T_f4333_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_f4333_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f4333\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f4333_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f4333_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f4333_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_f4333_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_f4333_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_f4333_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_f4333_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_f4333_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_f4333_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "      <td id=\"T_f4333_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_f4333_row0_col1\" class=\"data row0 col1\" >0.4880</td>\n",
       "      <td id=\"T_f4333_row0_col2\" class=\"data row0 col2\" >0.8210</td>\n",
       "      <td id=\"T_f4333_row0_col3\" class=\"data row0 col3\" >0.4880</td>\n",
       "      <td id=\"T_f4333_row0_col4\" class=\"data row0 col4\" >0.4795</td>\n",
       "      <td id=\"T_f4333_row0_col5\" class=\"data row0 col5\" >0.4748</td>\n",
       "      <td id=\"T_f4333_row0_col6\" class=\"data row0 col6\" >0.3855</td>\n",
       "      <td id=\"T_f4333_row0_col7\" class=\"data row0 col7\" >0.3883</td>\n",
       "      <td id=\"T_f4333_row0_col8\" class=\"data row0 col8\" >112.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_f4333_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_f4333_row1_col1\" class=\"data row1 col1\" >0.4698</td>\n",
       "      <td id=\"T_f4333_row1_col2\" class=\"data row1 col2\" >0.8072</td>\n",
       "      <td id=\"T_f4333_row1_col3\" class=\"data row1 col3\" >0.4698</td>\n",
       "      <td id=\"T_f4333_row1_col4\" class=\"data row1 col4\" >0.4641</td>\n",
       "      <td id=\"T_f4333_row1_col5\" class=\"data row1 col5\" >0.4637</td>\n",
       "      <td id=\"T_f4333_row1_col6\" class=\"data row1 col6\" >0.3634</td>\n",
       "      <td id=\"T_f4333_row1_col7\" class=\"data row1 col7\" >0.3644</td>\n",
       "      <td id=\"T_f4333_row1_col8\" class=\"data row1 col8\" >4.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "      <td id=\"T_f4333_row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_f4333_row2_col1\" class=\"data row2 col1\" >0.4685</td>\n",
       "      <td id=\"T_f4333_row2_col2\" class=\"data row2 col2\" >0.8020</td>\n",
       "      <td id=\"T_f4333_row2_col3\" class=\"data row2 col3\" >0.4685</td>\n",
       "      <td id=\"T_f4333_row2_col4\" class=\"data row2 col4\" >0.4603</td>\n",
       "      <td id=\"T_f4333_row2_col5\" class=\"data row2 col5\" >0.4603</td>\n",
       "      <td id=\"T_f4333_row2_col6\" class=\"data row2 col6\" >0.3621</td>\n",
       "      <td id=\"T_f4333_row2_col7\" class=\"data row2 col7\" >0.3635</td>\n",
       "      <td id=\"T_f4333_row2_col8\" class=\"data row2 col8\" >25.1760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_f4333_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_f4333_row3_col1\" class=\"data row3 col1\" >0.4398</td>\n",
       "      <td id=\"T_f4333_row3_col2\" class=\"data row3 col2\" >0.7822</td>\n",
       "      <td id=\"T_f4333_row3_col3\" class=\"data row3 col3\" >0.4398</td>\n",
       "      <td id=\"T_f4333_row3_col4\" class=\"data row3 col4\" >0.4336</td>\n",
       "      <td id=\"T_f4333_row3_col5\" class=\"data row3 col5\" >0.4298</td>\n",
       "      <td id=\"T_f4333_row3_col6\" class=\"data row3 col6\" >0.3276</td>\n",
       "      <td id=\"T_f4333_row3_col7\" class=\"data row3 col7\" >0.3296</td>\n",
       "      <td id=\"T_f4333_row3_col8\" class=\"data row3 col8\" >52.4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "      <td id=\"T_f4333_row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_f4333_row4_col1\" class=\"data row4 col1\" >0.4345</td>\n",
       "      <td id=\"T_f4333_row4_col2\" class=\"data row4 col2\" >0.7782</td>\n",
       "      <td id=\"T_f4333_row4_col3\" class=\"data row4 col3\" >0.4345</td>\n",
       "      <td id=\"T_f4333_row4_col4\" class=\"data row4 col4\" >0.4196</td>\n",
       "      <td id=\"T_f4333_row4_col5\" class=\"data row4 col5\" >0.4095</td>\n",
       "      <td id=\"T_f4333_row4_col6\" class=\"data row4 col6\" >0.3222</td>\n",
       "      <td id=\"T_f4333_row4_col7\" class=\"data row4 col7\" >0.3274</td>\n",
       "      <td id=\"T_f4333_row4_col8\" class=\"data row4 col8\" >1.6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_f4333_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_f4333_row5_col1\" class=\"data row5 col1\" >0.4330</td>\n",
       "      <td id=\"T_f4333_row5_col2\" class=\"data row5 col2\" >0.7765</td>\n",
       "      <td id=\"T_f4333_row5_col3\" class=\"data row5 col3\" >0.4330</td>\n",
       "      <td id=\"T_f4333_row5_col4\" class=\"data row5 col4\" >0.4141</td>\n",
       "      <td id=\"T_f4333_row5_col5\" class=\"data row5 col5\" >0.4035</td>\n",
       "      <td id=\"T_f4333_row5_col6\" class=\"data row5 col6\" >0.3205</td>\n",
       "      <td id=\"T_f4333_row5_col7\" class=\"data row5 col7\" >0.3265</td>\n",
       "      <td id=\"T_f4333_row5_col8\" class=\"data row5 col8\" >1.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row6\" class=\"row_heading level0 row6\" >lda</th>\n",
       "      <td id=\"T_f4333_row6_col0\" class=\"data row6 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_f4333_row6_col1\" class=\"data row6 col1\" >0.4295</td>\n",
       "      <td id=\"T_f4333_row6_col2\" class=\"data row6 col2\" >0.7640</td>\n",
       "      <td id=\"T_f4333_row6_col3\" class=\"data row6 col3\" >0.4295</td>\n",
       "      <td id=\"T_f4333_row6_col4\" class=\"data row6 col4\" >0.4375</td>\n",
       "      <td id=\"T_f4333_row6_col5\" class=\"data row6 col5\" >0.4276</td>\n",
       "      <td id=\"T_f4333_row6_col6\" class=\"data row6 col6\" >0.3151</td>\n",
       "      <td id=\"T_f4333_row6_col7\" class=\"data row6 col7\" >0.3167</td>\n",
       "      <td id=\"T_f4333_row6_col8\" class=\"data row6 col8\" >1.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n",
       "      <td id=\"T_f4333_row7_col0\" class=\"data row7 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_f4333_row7_col1\" class=\"data row7 col1\" >0.4252</td>\n",
       "      <td id=\"T_f4333_row7_col2\" class=\"data row7 col2\" >0.7576</td>\n",
       "      <td id=\"T_f4333_row7_col3\" class=\"data row7 col3\" >0.4252</td>\n",
       "      <td id=\"T_f4333_row7_col4\" class=\"data row7 col4\" >0.4273</td>\n",
       "      <td id=\"T_f4333_row7_col5\" class=\"data row7 col5\" >0.4239</td>\n",
       "      <td id=\"T_f4333_row7_col6\" class=\"data row7 col6\" >0.3099</td>\n",
       "      <td id=\"T_f4333_row7_col7\" class=\"data row7 col7\" >0.3106</td>\n",
       "      <td id=\"T_f4333_row7_col8\" class=\"data row7 col8\" >1.8840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_f4333_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_f4333_row8_col1\" class=\"data row8 col1\" >0.4152</td>\n",
       "      <td id=\"T_f4333_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_f4333_row8_col3\" class=\"data row8 col3\" >0.4152</td>\n",
       "      <td id=\"T_f4333_row8_col4\" class=\"data row8 col4\" >0.4134</td>\n",
       "      <td id=\"T_f4333_row8_col5\" class=\"data row8 col5\" >0.4055</td>\n",
       "      <td id=\"T_f4333_row8_col6\" class=\"data row8 col6\" >0.2971</td>\n",
       "      <td id=\"T_f4333_row8_col7\" class=\"data row8 col7\" >0.3002</td>\n",
       "      <td id=\"T_f4333_row8_col8\" class=\"data row8 col8\" >0.5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row9\" class=\"row_heading level0 row9\" >qda</th>\n",
       "      <td id=\"T_f4333_row9_col0\" class=\"data row9 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_f4333_row9_col1\" class=\"data row9 col1\" >0.3985</td>\n",
       "      <td id=\"T_f4333_row9_col2\" class=\"data row9 col2\" >0.6962</td>\n",
       "      <td id=\"T_f4333_row9_col3\" class=\"data row9 col3\" >0.3985</td>\n",
       "      <td id=\"T_f4333_row9_col4\" class=\"data row9 col4\" >0.3933</td>\n",
       "      <td id=\"T_f4333_row9_col5\" class=\"data row9 col5\" >0.3490</td>\n",
       "      <td id=\"T_f4333_row9_col6\" class=\"data row9 col6\" >0.2788</td>\n",
       "      <td id=\"T_f4333_row9_col7\" class=\"data row9 col7\" >0.2878</td>\n",
       "      <td id=\"T_f4333_row9_col8\" class=\"data row9 col8\" >0.5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row10\" class=\"row_heading level0 row10\" >knn</th>\n",
       "      <td id=\"T_f4333_row10_col0\" class=\"data row10 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_f4333_row10_col1\" class=\"data row10 col1\" >0.3798</td>\n",
       "      <td id=\"T_f4333_row10_col2\" class=\"data row10 col2\" >0.7112</td>\n",
       "      <td id=\"T_f4333_row10_col3\" class=\"data row10 col3\" >0.3798</td>\n",
       "      <td id=\"T_f4333_row10_col4\" class=\"data row10 col4\" >0.3699</td>\n",
       "      <td id=\"T_f4333_row10_col5\" class=\"data row10 col5\" >0.3712</td>\n",
       "      <td id=\"T_f4333_row10_col6\" class=\"data row10 col6\" >0.2544</td>\n",
       "      <td id=\"T_f4333_row10_col7\" class=\"data row10 col7\" >0.2554</td>\n",
       "      <td id=\"T_f4333_row10_col8\" class=\"data row10 col8\" >0.7480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_f4333_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_f4333_row11_col1\" class=\"data row11 col1\" >0.3680</td>\n",
       "      <td id=\"T_f4333_row11_col2\" class=\"data row11 col2\" >0.6685</td>\n",
       "      <td id=\"T_f4333_row11_col3\" class=\"data row11 col3\" >0.3680</td>\n",
       "      <td id=\"T_f4333_row11_col4\" class=\"data row11 col4\" >0.3346</td>\n",
       "      <td id=\"T_f4333_row11_col5\" class=\"data row11 col5\" >0.3374</td>\n",
       "      <td id=\"T_f4333_row11_col6\" class=\"data row11 col6\" >0.2418</td>\n",
       "      <td id=\"T_f4333_row11_col7\" class=\"data row11 col7\" >0.2460</td>\n",
       "      <td id=\"T_f4333_row11_col8\" class=\"data row11 col8\" >2.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_f4333_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_f4333_row12_col1\" class=\"data row12 col1\" >0.3418</td>\n",
       "      <td id=\"T_f4333_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_f4333_row12_col3\" class=\"data row12 col3\" >0.3418</td>\n",
       "      <td id=\"T_f4333_row12_col4\" class=\"data row12 col4\" >0.3904</td>\n",
       "      <td id=\"T_f4333_row12_col5\" class=\"data row12 col5\" >0.2886</td>\n",
       "      <td id=\"T_f4333_row12_col6\" class=\"data row12 col6\" >0.2075</td>\n",
       "      <td id=\"T_f4333_row12_col7\" class=\"data row12 col7\" >0.2328</td>\n",
       "      <td id=\"T_f4333_row12_col8\" class=\"data row12 col8\" >0.6640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_f4333_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_f4333_row13_col1\" class=\"data row13 col1\" >0.3250</td>\n",
       "      <td id=\"T_f4333_row13_col2\" class=\"data row13 col2\" >0.5949</td>\n",
       "      <td id=\"T_f4333_row13_col3\" class=\"data row13 col3\" >0.3250</td>\n",
       "      <td id=\"T_f4333_row13_col4\" class=\"data row13 col4\" >0.3263</td>\n",
       "      <td id=\"T_f4333_row13_col5\" class=\"data row13 col5\" >0.3251</td>\n",
       "      <td id=\"T_f4333_row13_col6\" class=\"data row13 col6\" >0.1895</td>\n",
       "      <td id=\"T_f4333_row13_col7\" class=\"data row13 col7\" >0.1896</td>\n",
       "      <td id=\"T_f4333_row13_col8\" class=\"data row13 col8\" >0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row14\" class=\"row_heading level0 row14\" >nb</th>\n",
       "      <td id=\"T_f4333_row14_col0\" class=\"data row14 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_f4333_row14_col1\" class=\"data row14 col1\" >0.2532</td>\n",
       "      <td id=\"T_f4333_row14_col2\" class=\"data row14 col2\" >0.6615</td>\n",
       "      <td id=\"T_f4333_row14_col3\" class=\"data row14 col3\" >0.2532</td>\n",
       "      <td id=\"T_f4333_row14_col4\" class=\"data row14 col4\" >0.2538</td>\n",
       "      <td id=\"T_f4333_row14_col5\" class=\"data row14 col5\" >0.1926</td>\n",
       "      <td id=\"T_f4333_row14_col6\" class=\"data row14 col6\" >0.1159</td>\n",
       "      <td id=\"T_f4333_row14_col7\" class=\"data row14 col7\" >0.1470</td>\n",
       "      <td id=\"T_f4333_row14_col8\" class=\"data row14 col8\" >0.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4333_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_f4333_row15_col0\" class=\"data row15 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_f4333_row15_col1\" class=\"data row15 col1\" >0.1718</td>\n",
       "      <td id=\"T_f4333_row15_col2\" class=\"data row15 col2\" >0.5000</td>\n",
       "      <td id=\"T_f4333_row15_col3\" class=\"data row15 col3\" >0.1718</td>\n",
       "      <td id=\"T_f4333_row15_col4\" class=\"data row15 col4\" >0.0295</td>\n",
       "      <td id=\"T_f4333_row15_col5\" class=\"data row15 col5\" >0.0503</td>\n",
       "      <td id=\"T_f4333_row15_col6\" class=\"data row15 col6\" >0.0000</td>\n",
       "      <td id=\"T_f4333_row15_col7\" class=\"data row15 col7\" >0.0000</td>\n",
       "      <td id=\"T_f4333_row15_col8\" class=\"data row15 col8\" >0.6680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c6da98ba00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = classification.compare_models(n_select=5,fold=5,sort='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2cd30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['label'] = preds[0] # 0,2,3\n",
    "submission.to_csv('./baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
