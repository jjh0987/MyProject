{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60f020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8719ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "origin = pd.read_csv('./WineQT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c188c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,origin],axis=0).drop('Id',axis=1).drop_duplicates().reset_index(drop=True)\n",
    "train = train.drop('pH',axis=1)\n",
    "train = train.drop('free sulfur dioxide',axis=1)\n",
    "train = train.drop('residual sugar',axis=1)\n",
    "# train = train.drop('chlorides',axis=1)\n",
    "train = train.drop('fixed acidity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8ee3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('pH',axis=1)\n",
    "test = test.drop('free sulfur dioxide',axis=1)\n",
    "test = test.drop('residual sugar',axis=1)\n",
    "# test = test.drop('chlorides',axis=1)\n",
    "test = test.drop('fixed acidity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d00a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.570177</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>-0.038568</td>\n",
       "      <td>-0.317440</td>\n",
       "      <td>-0.212796</td>\n",
       "      <td>-0.282514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>-0.570177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>-0.040451</td>\n",
       "      <td>0.373818</td>\n",
       "      <td>0.293162</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>0.173892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.042140</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.216366</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>-0.182042</td>\n",
       "      <td>-0.080917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>0.078616</td>\n",
       "      <td>-0.040451</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092531</td>\n",
       "      <td>-0.093736</td>\n",
       "      <td>-0.277965</td>\n",
       "      <td>-0.209408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>-0.038568</td>\n",
       "      <td>0.373818</td>\n",
       "      <td>0.216366</td>\n",
       "      <td>0.092531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>-0.408874</td>\n",
       "      <td>-0.162885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>-0.317440</td>\n",
       "      <td>0.293162</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>-0.093736</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>0.321986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>-0.212796</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>-0.182042</td>\n",
       "      <td>-0.277965</td>\n",
       "      <td>-0.408874</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>-0.282514</td>\n",
       "      <td>0.173892</td>\n",
       "      <td>-0.080917</td>\n",
       "      <td>-0.209408</td>\n",
       "      <td>-0.162885</td>\n",
       "      <td>0.321986</td>\n",
       "      <td>0.481907</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      volatile acidity  citric acid  chlorides  \\\n",
       "volatile acidity              1.000000    -0.570177   0.042140   \n",
       "citric acid                  -0.570177     1.000000   0.185083   \n",
       "chlorides                     0.042140     0.185083   1.000000   \n",
       "total sulfur dioxide          0.078616    -0.040451   0.022236   \n",
       "density                      -0.038568     0.373818   0.216366   \n",
       "sulphates                    -0.317440     0.293162   0.232797   \n",
       "alcohol                      -0.212796     0.089312  -0.182042   \n",
       "quality                      -0.282514     0.173892  -0.080917   \n",
       "\n",
       "                      total sulfur dioxide   density  sulphates   alcohol  \\\n",
       "volatile acidity                  0.078616 -0.038568  -0.317440 -0.212796   \n",
       "citric acid                      -0.040451  0.373818   0.293162  0.089312   \n",
       "chlorides                         0.022236  0.216366   0.232797 -0.182042   \n",
       "total sulfur dioxide              1.000000  0.092531  -0.093736 -0.277965   \n",
       "density                           0.092531  1.000000   0.051480 -0.408874   \n",
       "sulphates                        -0.093736  0.051480   1.000000  0.188536   \n",
       "alcohol                          -0.277965 -0.408874   0.188536  1.000000   \n",
       "quality                          -0.209408 -0.162885   0.321986  0.481907   \n",
       "\n",
       "                       quality  \n",
       "volatile acidity     -0.282514  \n",
       "citric acid           0.173892  \n",
       "chlorides            -0.080917  \n",
       "total sulfur dioxide -0.209408  \n",
       "density              -0.162885  \n",
       "sulphates             0.321986  \n",
       "alcohol               0.481907  \n",
       "quality               1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bbc662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1272\n",
       "6    1187\n",
       "7     455\n",
       "4      88\n",
       "8      54\n",
       "3      18\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30e302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[(train.quality > 4) & (train.quality < 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a663a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b563cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['quality'] = [i-3 for i in train['quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20eedc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.quality.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34769911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgb = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3881d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score, f1_score, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from xgboost import XGBClassifier, XGBRFRegressor\n",
    "from lightgbm.sklearn import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae7e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'quality'\n",
    "features = [c for c in train.columns if c not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d8c523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.7794636\ttest: 1.7795273\tbest: 1.7795273 (0)\ttotal: 146ms\tremaining: 36m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:03,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9898773015\n",
      "bestIteration = 1136\n",
      "\n",
      "Shrink model to first 1137 iterations.\n",
      "ACC on fold 0: 0.5100\n",
      "0:\tlearn: 1.7790513\ttest: 1.7796512\tbest: 1.7796512 (0)\ttotal: 2.79ms\tremaining: 41.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:06,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1.058175523\n",
      "bestIteration = 633\n",
      "\n",
      "Shrink model to first 634 iterations.\n",
      "ACC on fold 1: 0.4222\n",
      "0:\tlearn: 1.7795966\ttest: 1.7797694\tbest: 1.7797694 (0)\ttotal: 11.9ms\tremaining: 2m 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:11,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9619797681\n",
      "bestIteration = 1572\n",
      "\n",
      "Shrink model to first 1573 iterations.\n",
      "ACC on fold 2: 0.5366\n",
      "0:\tlearn: 1.7795392\ttest: 1.7798360\tbest: 1.7798360 (0)\ttotal: 2.99ms\tremaining: 44.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:14,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9900417952\n",
      "bestIteration = 870\n",
      "\n",
      "Shrink model to first 871 iterations.\n",
      "ACC on fold 3: 0.4938\n",
      "0:\tlearn: 1.7790959\ttest: 1.7796847\tbest: 1.7796847 (0)\ttotal: 4ms\tremaining: 1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:16,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9855599699\n",
      "bestIteration = 735\n",
      "\n",
      "Shrink model to first 736 iterations.\n",
      "ACC on fold 4: 0.4985\n",
      "0:\tlearn: 1.7791926\ttest: 1.7791734\tbest: 1.7791734 (0)\ttotal: 18.2ms\tremaining: 4m 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:19,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9987020044\n",
      "bestIteration = 703\n",
      "\n",
      "Shrink model to first 704 iterations.\n",
      "ACC on fold 5: 0.5403\n",
      "0:\tlearn: 1.7794913\ttest: 1.7796165\tbest: 1.7796165 (0)\ttotal: 3.06ms\tremaining: 45.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:23,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9799844254\n",
      "bestIteration = 1062\n",
      "\n",
      "Shrink model to first 1063 iterations.\n",
      "ACC on fold 6: 0.5349\n",
      "0:\tlearn: 1.7792332\ttest: 1.7791267\tbest: 1.7791267 (0)\ttotal: 2.9ms\tremaining: 43.4s\n",
      "2000:\tlearn: 0.8085904\ttest: 0.9416494\tbest: 0.9416382 (1993)\ttotal: 5.24s\tremaining: 34.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:29,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9416021299\n",
      "bestIteration = 2011\n",
      "\n",
      "Shrink model to first 2012 iterations.\n",
      "ACC on fold 7: 0.5295\n",
      "0:\tlearn: 1.7791130\ttest: 1.7795697\tbest: 1.7795697 (0)\ttotal: 2.91ms\tremaining: 43.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:32,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1.005293646\n",
      "bestIteration = 1085\n",
      "\n",
      "Shrink model to first 1086 iterations.\n",
      "ACC on fold 8: 0.4995\n",
      "0:\tlearn: 1.7794215\ttest: 1.7797794\tbest: 1.7797794 (0)\ttotal: 3.19ms\tremaining: 47.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:36,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9656782784\n",
      "bestIteration = 1128\n",
      "\n",
      "Shrink model to first 1129 iterations.\n",
      "ACC on fold 9: 0.5732\n",
      "mean AUC across all folds: 0.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 10, random_state = 41, shuffle = True)\n",
    "models = []\n",
    "val_scores = []\n",
    "preds = []\n",
    "\n",
    "params = {\n",
    "'n_estimators':15000,\n",
    "'max_depth':5,\n",
    "'early_stopping_rounds':200,\n",
    "'learning_rate':0.008,\n",
    "'one_hot_max_size':3,\n",
    "'bootstrap_type':\"MVS\",\n",
    "'l2_leaf_reg':2,\n",
    "'random_state':41\n",
    "         }\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(train, train[target]))):\n",
    "    \n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "    \n",
    "#     if include_orig:\n",
    "#         X_train = X_train.append(original[features], ignore_index = True)\n",
    "#         y_train = y_train.append(original[target], ignore_index = True)\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = 2000)\n",
    "    \n",
    "    models.append(model)\n",
    "    # pred = model.predict_proba(X_val)[:,1]\n",
    "    # score = accuracy_score(y_val, model.predict(X_val))\n",
    "    score = cohen_kappa_score(y_val, model.predict(X_val), weights = 'quadratic')\n",
    "\n",
    "    val_scores.append(score)\n",
    "    \n",
    "    print(f'ACC on fold {i}: {score:.4f}')\n",
    "    \n",
    "print(f'mean AUC across all folds: {np.mean(val_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2129a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5138538633673709"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_scores)/len(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7162fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.77134\n",
      "[1000]\tvalidation_0-auc:0.77860\n",
      "[2000]\tvalidation_0-auc:0.77592\n",
      "[2999]\tvalidation_0-auc:0.77432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 0: 0.5244\n",
      "[0]\tvalidation_0-auc:0.71258\n",
      "[1000]\tvalidation_0-auc:0.72808\n",
      "[2000]\tvalidation_0-auc:0.72777\n",
      "[2999]\tvalidation_0-auc:0.72724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 1: 0.4485\n",
      "[0]\tvalidation_0-auc:0.75033\n",
      "[1000]\tvalidation_0-auc:0.78536\n",
      "[2000]\tvalidation_0-auc:0.78545\n",
      "[2999]\tvalidation_0-auc:0.78502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:18,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 2: 0.5303\n",
      "[0]\tvalidation_0-auc:0.74970\n",
      "[1000]\tvalidation_0-auc:0.80272\n",
      "[2000]\tvalidation_0-auc:0.80312\n",
      "[2999]\tvalidation_0-auc:0.80261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:24,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 3: 0.6026\n",
      "[0]\tvalidation_0-auc:0.72843\n",
      "[1000]\tvalidation_0-auc:0.76657\n",
      "[2000]\tvalidation_0-auc:0.76355\n",
      "[2999]\tvalidation_0-auc:0.76397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:31,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 4: 0.5038\n",
      "[0]\tvalidation_0-auc:0.71561\n",
      "[1000]\tvalidation_0-auc:0.75612\n",
      "[2000]\tvalidation_0-auc:0.75535\n",
      "[2999]\tvalidation_0-auc:0.75594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:37,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 5: 0.5242\n",
      "[0]\tvalidation_0-auc:0.75209\n",
      "[1000]\tvalidation_0-auc:0.79862\n",
      "[2000]\tvalidation_0-auc:0.79627\n",
      "[2999]\tvalidation_0-auc:0.79622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:43,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 6: 0.5757\n",
      "[0]\tvalidation_0-auc:0.68404\n",
      "[1000]\tvalidation_0-auc:0.68675\n",
      "[2000]\tvalidation_0-auc:0.68599\n",
      "[2999]\tvalidation_0-auc:0.68640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:49,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 7: 0.3695\n",
      "[0]\tvalidation_0-auc:0.69044\n",
      "[1000]\tvalidation_0-auc:0.73545\n",
      "[2000]\tvalidation_0-auc:0.73231\n",
      "[2999]\tvalidation_0-auc:0.73147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:55,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 8: 0.4925\n",
      "[0]\tvalidation_0-auc:0.72632\n",
      "[1000]\tvalidation_0-auc:0.77537\n",
      "[2000]\tvalidation_0-auc:0.77214\n",
      "[2999]\tvalidation_0-auc:0.77152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:01,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 9: 0.5399\n",
      "mean score across all folds: 0.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "val_scores = []\n",
    "\n",
    "include_orig = True\n",
    "\n",
    "xgb_params = {'n_estimators'     : 3000,\n",
    "              'min_child_weight' : 96,\n",
    "              'max_depth'        : 7,\n",
    "              'learning_rate'    : 0.05,\n",
    "              'subsample'        : 0.95,\n",
    "              'colsample_bytree' : 0.95,\n",
    "              'reg_lambda'       : 1.50,\n",
    "              'reg_alpha'        : 1.50,\n",
    "              'gamma'            : 1.50,\n",
    "              'max_bin'          : 512,\n",
    "              'random_state'     : 41,\n",
    "              'objective'        : 'binary:logistic',\n",
    "              'tree_method'      : 'hist',\n",
    "              'eval_metric'      : 'auc'\n",
    "             }\n",
    "# xgb_params = {'max_depth': 3,\n",
    "#  'learning_rate': 0.09457198987172621,\n",
    "#  'min_child_weight': 9,\n",
    "#  'gamma': 0.3126168664550514,\n",
    "#  'subsample': 0.5585879695479943,\n",
    "#  'colsample_bytree': 0.46793424854801835,\n",
    "#  'reg_alpha': 0.21235299325212031,\n",
    "#  'reg_lambda': 0.4236760707956293,\n",
    "#  'n_estimators': 606}\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(train, train[target]))):\n",
    "    \n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "    \n",
    "#     if include_orig:\n",
    "#         X_train = X_train.append(original[features], ignore_index = True)\n",
    "#         y_train = y_train.append(original[target], ignore_index = True)\n",
    "    \n",
    "    model = XGBClassifier(**xgb_params)\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], verbose = 1000)\n",
    "    \n",
    "    models.append(model)\n",
    "    pred = model.predict_proba(X_val)[:,1]\n",
    "    # score = roc_auc_score(y_val, pred)\n",
    "    score = cohen_kappa_score(y_val, model.predict(X_val), weights = 'quadratic')\n",
    "\n",
    "    val_scores.append(score)\n",
    "    \n",
    "    print(f'score on fold {i}: {score:.4f}')\n",
    "    \n",
    "print(f'mean score across all folds: {np.mean(val_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "571501d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.511139398617669"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_scores)/len(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7816d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    \n",
    "    params_optuna = {\n",
    "        \n",
    "        'scale_pos_weight':trial.suggest_int('scale_pos_weight', 1, 3),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-12, 2, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 5, 25.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 35, 50),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.65, 0.85),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.65),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 4, 9),\n",
    "         'min_child_samples': trial.suggest_int('min_child_samples', 40, 90),\n",
    "         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 90, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 12),\n",
    "        'num_iterations':10000,\n",
    "        'learning_rate':0.005\n",
    "    }\n",
    "    n=10\n",
    "    cv = StratifiedKFold(n,shuffle=True, random_state=42)\n",
    "    all_scores = []\n",
    "    for i,(train_idx,val_idx) in enumerate(cv.split(train[features],train[target])):\n",
    "        X_train, y_train = train.loc[train_idx, features],train.loc[train_idx, target]\n",
    "        X_val, y_val = train.loc[val_idx, features],train.loc[val_idx, target]\n",
    "\n",
    "        model = LGBMClassifier(**params_optuna)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set = [(X_val,y_val)],\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=500)\n",
    "\n",
    "        # y_pred = model.predict_proba(X_val)[:,1]\n",
    "        # score = accuracy_score(y_val,y_pred)\n",
    "        score = cohen_kappa_score(y_val, model.predict(X_val), weights = 'quadratic')\n",
    "\n",
    "        all_scores.append(score)\n",
    "\n",
    "    return np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce07e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:05:55,024]\u001b[0m A new study created in memory with name: no-name-8a823cdc-0c6f-44f6-8106-708b261bc469\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.990125\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.00287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.979342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.05066\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.988847\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.00691\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.96104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.989434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.00741\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8158035892046042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8158035892046042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=61 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.0737154725351e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.0737154725351e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6419894625368731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6419894625368731\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715959395598292, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.715959395598292\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's multi_logloss: 1.00524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:06:08,421]\u001b[0m Trial 0 finished with value: 0.5049632032506187 and parameters: {'scale_pos_weight': 1, 'lambda_l1': 8.0737154725351e-07, 'lambda_l2': 8.715959395598292, 'num_leaves': 38, 'feature_fraction': 0.8158035892046042, 'bagging_fraction': 0.6419894625368731, 'bagging_freq': 6, 'min_child_samples': 61, 'min_data_in_leaf': 93, 'max_depth': 7}. Best is trial 0 with value: 0.5049632032506187.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.00059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.01041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 0.986767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.05797\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 0.997877\n",
      "[1000]\tvalid_0's multi_logloss: 0.981025\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.02177\n",
      "[1000]\tvalid_0's multi_logloss: 1.00561\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 0.976512\n",
      "[1000]\tvalid_0's multi_logloss: 0.951375\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.00659\n",
      "[1000]\tvalid_0's multi_logloss: 0.986039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[500]\tvalid_0's multi_logloss: 1.01472\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7094944820332122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7094944820332122\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=86 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.10829847775778e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.10829847775778e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5687219684416984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5687219684416984\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.659944631805512, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.659944631805512\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's multi_logloss: 1.02087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:06:22,839]\u001b[0m Trial 1 finished with value: 0.5142528873161061 and parameters: {'scale_pos_weight': 3, 'lambda_l1': 8.10829847775778e-06, 'lambda_l2': 22.659944631805512, 'num_leaves': 41, 'feature_fraction': 0.7094944820332122, 'bagging_fraction': 0.5687219684416984, 'bagging_freq': 9, 'min_child_samples': 86, 'min_data_in_leaf': 147, 'max_depth': 6}. Best is trial 1 with value: 0.5142528873161061.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.00015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.01098\n",
      "[1000]\tvalid_0's multi_logloss: 0.993996\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 0.986637\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.06061\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 0.99348\n",
      "[1000]\tvalid_0's multi_logloss: 0.980269\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.02101\n",
      "[1000]\tvalid_0's multi_logloss: 1.00542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 0.977774\n",
      "[1000]\tvalid_0's multi_logloss: 0.95236\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.00545\n",
      "[1000]\tvalid_0's multi_logloss: 0.984757\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[500]\tvalid_0's multi_logloss: 1.01296\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's multi_logloss: 1.02396\n",
      "[1000]\tvalid_0's multi_logloss: 1.01214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:06:36,892]\u001b[0m Trial 2 finished with value: 0.5183678684767494 and parameters: {'scale_pos_weight': 3, 'lambda_l1': 2.709347871768407e-10, 'lambda_l2': 22.427759531748354, 'num_leaves': 49, 'feature_fraction': 0.7986639872431636, 'bagging_fraction': 0.507972238737994, 'bagging_freq': 8, 'min_child_samples': 87, 'min_data_in_leaf': 147, 'max_depth': 6}. Best is trial 2 with value: 0.5183678684767494.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 0.998563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 1.01308\n",
      "[1000]\tvalid_0's multi_logloss: 0.99907\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 0.983981\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 1.0571\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 0.996431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 1.0196\n",
      "[1000]\tvalid_0's multi_logloss: 1.00641\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 0.976395\n",
      "[1000]\tvalid_0's multi_logloss: 0.952138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 1.00413\n",
      "[1000]\tvalid_0's multi_logloss: 0.982924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[500]\tvalid_0's multi_logloss: 1.01149\n",
      "[LightGBM] [Warning] feature_fraction is set=0.70841224542913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70841224542913\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=103, min_child_samples=49 will be ignored. Current value: min_data_in_leaf=103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2821915004393845e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2821915004393845e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.508077466531555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508077466531555\n",
      "[LightGBM] [Warning] lambda_l2 is set=19.11382395037818, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19.11382395037818\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's multi_logloss: 1.01922\n",
      "[1000]\tvalid_0's multi_logloss: 1.00369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:06:52,115]\u001b[0m Trial 3 finished with value: 0.5070257384444687 and parameters: {'scale_pos_weight': 2, 'lambda_l1': 4.2821915004393845e-07, 'lambda_l2': 19.11382395037818, 'num_leaves': 42, 'feature_fraction': 0.70841224542913, 'bagging_fraction': 0.508077466531555, 'bagging_freq': 7, 'min_child_samples': 49, 'min_data_in_leaf': 103, 'max_depth': 11}. Best is trial 2 with value: 0.5183678684767494.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.98987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.998064\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.975386\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.04776\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.989495\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.01036\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.959917\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 0.991822\n",
      "[1000]\tvalid_0's multi_logloss: 0.980186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[500]\tvalid_0's multi_logloss: 1.00795\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6690518542727256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6690518542727256\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=85 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0946593005978178e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0946593005978178e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6200780413092661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6200780413092661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.0880989346708505, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0880989346708505\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's multi_logloss: 1.01152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 16:07:05,712]\u001b[0m Trial 4 finished with value: 0.5110227462699144 and parameters: {'scale_pos_weight': 3, 'lambda_l1': 3.0946593005978178e-12, 'lambda_l2': 5.0880989346708505, 'num_leaves': 44, 'feature_fraction': 0.6690518542727256, 'bagging_fraction': 0.6200780413092661, 'bagging_freq': 6, 'min_child_samples': 85, 'min_data_in_leaf': 134, 'max_depth': 8}. Best is trial 2 with value: 0.5183678684767494.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler = TPESampler())\n",
    "study.optimize(func=lgb_objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450d1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "score on fold 0: 0.4913\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 1: 0.4329\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "score on fold 2: 0.5218\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 3: 0.5850\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "score on fold 4: 0.4993\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 5: 0.5351\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "score on fold 6: 0.5476\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:01,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 7: 0.3931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "score on fold 8: 0.4867\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7986639872431636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7986639872431636\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=147, min_child_samples=87 will be ignored. Current value: min_data_in_leaf=147\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.709347871768407e-10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.709347871768407e-10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.507972238737994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.507972238737994\n",
      "[LightGBM] [Warning] lambda_l2 is set=22.427759531748354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=22.427759531748354\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on fold 9: 0.5765\n",
      "mean score across all folds: 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "val_scores = []\n",
    "\n",
    "params = {'scale_pos_weight': 2,\n",
    " #'lambda_l2': 14.705798704172345,\n",
    " 'num_leaves': 10,\n",
    " 'learning_rate': 0.005,\n",
    " #'feature_fraction': 0.8402041342033796,\n",
    " #'bagging_fraction': 0.5053012488246705,\n",
    " 'bagging_freq': 5,\n",
    " 'min_child_samples': 10,\n",
    " 'min_data_in_leaf': 10,\n",
    " 'max_depth': 10,\n",
    " 'random_state' : 41}\n",
    "params = study.best_params\n",
    "\n",
    "for i, (train_index, val_index) in tqdm(enumerate(kf.split(train, train[target]))):\n",
    "    \n",
    "    X_train, X_val = train[features].loc[train_index], train[features].loc[val_index]\n",
    "    y_train, y_val = train[target][train_index], train[target][val_index]\n",
    "    \n",
    "#     if include_orig:\n",
    "#         X_train = X_train.append(original[features], ignore_index = True)\n",
    "#         y_train = y_train.append(original[target], ignore_index = True)\n",
    "    \n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models.append(model)\n",
    "    # pred = model.predict_proba(X_val)[:,1]\n",
    "    # score = accuracy_score(y_val, model.predict(X_val))\n",
    "    score = cohen_kappa_score(y_val, model.predict(X_val), weights = 'quadratic')\n",
    "\n",
    "    val_scores.append(score)\n",
    "    \n",
    "    print(f'score on fold {i}: {score:.4f}')\n",
    "    \n",
    "print(f'mean score across all folds: {np.mean(val_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d1b6aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5069258752220247"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_scores)/len(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "882c1046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<catboost.core.CatBoostClassifier at 0x1bd8b189ee0>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b19d3a0>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189f70>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189c40>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189fd0>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189e80>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189eb0>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189f10>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b189f40>,\n",
       " <catboost.core.CatBoostClassifier at 0x1bd8b19dca0>,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.95,\n",
       "               enable_categorical=False, eval_metric='auc', gamma=1.5, gpu_id=-1,\n",
       "               importance_type=None, interaction_constraints='',\n",
       "               learning_rate=0.05, max_bin=512, max_delta_step=0, max_depth=7,\n",
       "               min_child_weight=96, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=3000, n_jobs=12, num_parallel_tree=1,\n",
       "               objective='multi:softprob', predictor='auto', random_state=41,\n",
       "               reg_alpha=1.5, reg_lambda=1.5, scale_pos_weight=None,\n",
       "               subsample=0.95, tree_method='hist', validate_parameters=1, ...),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3),\n",
       " LGBMClassifier(bagging_fraction=0.507972238737994, bagging_freq=8,\n",
       "                feature_fraction=0.7986639872431636,\n",
       "                lambda_l1=2.709347871768407e-10, lambda_l2=22.427759531748354,\n",
       "                max_depth=6, min_child_samples=87, min_data_in_leaf=147,\n",
       "                num_leaves=49, scale_pos_weight=3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d998bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 6))\n",
    "cat_imp = np.zeros(len(models[0].feature_importances_))\n",
    "for model in models[:10]:\n",
    "    cat_imp += model.feature_importances_\n",
    "    \n",
    "plt.barh([features[i] for i in np.argsort(cat_imp)], sorted(cat_imp), \n",
    "         color = \"orange\", edgecolor = \"#000000\")\n",
    "\n",
    "plt.title(\"CatBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36303850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 6))\n",
    "xgb_imp = np.zeros(len(models[10].feature_importances_))\n",
    "for model in models[10:20]:\n",
    "    xgb_imp += model.feature_importances_\n",
    "    \n",
    "plt.barh([features[i] for i in np.argsort(xgb_imp)], sorted(xgb_imp), \n",
    "         color = \"purple\", edgecolor = \"#000000\")\n",
    "\n",
    "plt.title(\"XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab810100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 6))\n",
    "lgbm_imp = np.zeros(len(features))\n",
    "for model in models[20:]:\n",
    "    lgbm_imp += model.feature_importances_\n",
    "    \n",
    "plt.barh([features[i] for i in np.argsort(lgbm_imp)], sorted(lgbm_imp), \n",
    "         color = \"blue\", edgecolor = \"#000000\")\n",
    "\n",
    "plt.title(\"LGBM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef8a9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds = []\n",
    "xgb_preds = []\n",
    "lgbm_preds = []\n",
    "\n",
    "for model in models[:5]:\n",
    "    preds = model.predict_proba(test[features])[:,1]\n",
    "    cat_preds.append(preds)\n",
    "    \n",
    "for model in models[5:10]:\n",
    "    preds = model.predict_proba(test[features])[:,1]\n",
    "    xgb_preds.append(preds)\n",
    "    \n",
    "for model in models[10:]:\n",
    "    preds = model.predict_proba(test[features])[:,1]\n",
    "    lgbm_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "827361f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_preds = np.stack(cat_preds).mean(0)\n",
    "xgb_preds = np.stack(xgb_preds).mean(0)\n",
    "lgbm_preds = np.stack(lgbm_preds).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66ec83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Correlation with XGB:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.988278675001155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Correlation with LGBM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8419734668614262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Correlation with LGBM:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8229890706952471"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_df = pd.DataFrame(data = {'id': test.Id, 'Class': cat_preds})\n",
    "xgb_df = pd.DataFrame(data = {'id': test.Id, 'Class': xgb_preds})\n",
    "lgbm_df = pd.DataFrame(data = {'id': test.Id, 'Class': lgbm_preds})\n",
    "\n",
    "print(\"Cat Correlation with XGB:\")\n",
    "display(cat_df.Class.corr(xgb_df.Class))\n",
    "print(\"Cat Correlation with LGBM:\")\n",
    "display(cat_df.Class.corr(lgbm_df.Class))\n",
    "print(\"XGB Correlation with LGBM:\")\n",
    "display(xgb_df.Class.corr(lgbm_df.Class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59440b0b",
   "metadata": {},
   "source": [
    "# Enssemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "925e3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target = [md.predict_proba(test.loc[:,features]) for md in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca0fcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = np.zeros(pred_target[0].shape)\n",
    "row,col = pred_target[0].shape\n",
    "\n",
    "for pr in range(len(pred_target)):\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if pr > 10:\n",
    "                dp[i][j] += 0.34*pred_target[pr][i][j]\n",
    "            else:\n",
    "                dp[i][j] += 0.33*pred_target[pr][i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f851b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_preds = [np.argmax(i) for i in dp]# models[4].predict(test.loc[:,features])\n",
    "# blended_preds = [i[0] for i in models[6].predict(test)]\n",
    "blended_preds = [i+3 for i in blended_preds]\n",
    "submission = pd.DataFrame(data = {'Id': test.Id, 'quality': blended_preds})\n",
    "submission.set_index('Id')\n",
    "submission.to_csv('blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0197a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    650\n",
       "5    580\n",
       "7    142\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./blended.csv')['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8e1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
